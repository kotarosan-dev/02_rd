AIは短歌をどう

詠むか

浦川 通

講談社現代新書 2748



はじめに

短歌を生成する〈短歌AI〉

問題です。 次に並べる短歌のうち、AIがつくったものはどれか当ててみてください。

揺れている構造物があるとする場合に限り地震の揺れは

パン屋では客の好みを聞きながら商品を決め袋に詰める

学校に向かう途中の少女鉄神像の間を列車が抜けた

目が醒めて匂いを嗅いで好きだといい猫になったあとなんとなく死ぬ

街角の影がくっきりふりかかる太陽からの冷たさに耐え

3

はじめに

新しい視点から考える

さて、前ページの問題の答えですが、勘のいい読者の方はすでにお気づきかもしれませ ん。 実はどれも短歌を生成する〈短歌AI> が生成したものです。

いかがでしょう? いかにもAIが生成したような味気ないものから、少し短歌を 「わ かっていそう」なものまで、さまざまあるように感じられませんか。

なぜAIから、これだけ違った表現が生まれてくるのでしょうか。 AIも、短歌を上手 に詠むことができる? そんな問いから出発して、「AIが短歌をつくる」ということに ついて、さまざまな実践を通して考えていこうと思います。

この本では、短歌を生成するAIの仕組みを解説しながら、AIがどのように短歌を学 び、またそれをつくっていくのかを見ていきます。

読者は、AIと短歌それぞれに対して、専門的な知識を持たないものと仮定します。本 書を読み進めれば、「コンピュータが言語を処理するとはどういうことなのか」に始まり、 「AIが短歌をつくる際にはどんなことをしているのか」がわかり、さらには「短歌入門」 的な知識も得られるように努めました。

最初にお断りをしておくと、タイトルでは『AIは短歌をどう詠むか」と謳っています

新聞社の短歌AI

が、この本の目的は〈AIを駆使した短歌のつくり方〉を解説することにはありません。 むしろ、〈AIが短歌をつくる〉という過程を通して〈人が短歌をつくる〉こと、ひいて は〈私たちが毎日扱う言葉〉について、新しい視点から考えることを目指しています。

いま読者の皆さんには、「そもそもAIに短歌をつくることができるの?」「ほんとう にAIに上手い短歌がつくれるの?」といった疑問が浮かんでいるかもしれません。本書 ではAIを通して、「短歌をつくるとは何か」「短歌が上手いとは何か」といった問いにつ いて、改めて考える機会が提供されます。AIに対する疑問が、そのまま私たちの行為に も返ってくるのです。

ここで、なぜ私がこの本を書いているのか、簡単に自己紹介をさせてください。

かつて私は、「メディアアート」の制作をしていました。 メディアアートとは、新たなテ クノロジーを応用して制作される、あるいはテクノロジーそのものをテーマにしたアート のことです。それは、「私たちの日常をつくる技術と私たち自身の関係性」について、モノ をつくるという実践を通して考える行為でした。

そして現在、私の興味は「言葉」に対する技術の応用に向かい、朝日新聞社メディア研

5

はじめに

究開発センターで 「自然言語処理」の研究開発に取り組んでいます。

自然言語処理━ひょっとしたら、聞き慣れない言葉かもしれません。これは、人が日 常で扱う言葉をコンピュータが処理する技術を指します。 人によって書かれる文章や話さ れる会話など、私たちが毎日の生活で交わす 「言葉」 をコンピュータが処理し、例えばそ れを別の言語へ翻訳したり、重要と思われる箇所を要約したり、といった「言葉」にまつ わるさまざまなことをできるようにする技術です。

そしてこの自然言語処理は、人間の言葉を理解し扱う技術として、AI研究の分野とも 深く関わっています。この分野では「機械学習」 と呼ばれる手法が広く用いられており、 大量のデータから学び、特定の課題を解決するAIが開発されています。新聞社には、過 去から現在にわたる多様な出来事を記録した膨大な新聞記事があり、これらは私たちのA 開発に不可欠なデータとなります。実際、メディア研究開発センターでは、そのような 大量のデータを利用して、自動的に記事の見出しを生成するAIなどを開発してきました。 短歌を生成する〈短歌AI〉も、新聞社の中で生まれたAIです。私の個人的な興味か 試作を始めたのちに、100年以上の歴史を持つ「朝日歌壇」を担当する文化部をはじ め、社内外の研究者、さらには歌人といった方々との協力のもとで形づくられ、世の中へ と広げられています。

短歌とAIと人が出会う

私はこれまでに、短歌AIをつくるための学習データを準備したり、短歌AIがより短

うかが

歌らしい内容を生成するにはどうすればよいか、試行を重ねたり、短歌生成の様子を歌人 の方に見せて反応を窺ったり、またそこからAIと人との関係について考える場を提供し たり、「短歌とAIと人」に関わる活動をさまざまに重ねてきました。

本書では、そんな過程の一つ一つから得られた発見や知見を整理し、皆さんにお伝えし ます。

まず序章では、AIがどのように言葉を学習してそれを扱えるようになるのか、AI= 言葉を生成する「言語モデル」の基本的な原理を示します。

続く第1章では、朝日新聞社でのさまざまな取り組みを例に、短歌AIの全体像を眺め ます。

第2章では、五・七・五・七・七のリズムを持つ短歌の「定型」を、AIがどのようにし て身につけるかについて説明します。そして、短歌を詠む」ためには短歌を「読む」の が大事であること(第3章)、言葉を「歌」にするための飛躍について(第4章)解説します。 第5章では、短歌AIと人間とのやりとりを通じて、短歌をつくる現場での人とAIの

7

はじめに

関係を考えていきます。AIの発展の速度は近年とても速く感じられますが、言葉を扱う それを介して、短歌という文化創作について改めて考えていく過程には、普遍性が宿る と信じています。

まるで人のように短歌をつくるAIがある。確かにそれは、人と「似ている」わけです が、AIの方が得意なこと、人間の方が得意なこと、AIにしかできないこと、人間にし かできないこと、そして共通してもっていること･･････が、短歌AIを通して見えてくるで しょう。私はこれを、新たに短歌と私たち人間について考える、良い機会だと捉えていま す。いま、この時代だからこそ生まれる、人が短歌をつくることへの新しい感覚を、この 本の中で表すことができたらと思います。

〈AI〉が短歌を学び、そして〈人間〉と出会う。このさまを見ることで、〈あなた〉が

短歌について知り、それを自分のものとして、新しい歌をつくる。この本が、そんなきっ かけの一つとなればうれしいです。

00

目次

はじめに

序章「言葉」を計算してつくる

情報を処理するということ

「言葉」を数値で表す難しさ

単語の意味を計算する

意識の辞書

文の意味を計算する

文章を生成する「言語モデル」

次にくる言葉を予測する

文章を大量に読んで学ぶ

この記事は実在しません

記事の「見出し」を生成するAI

文の空白を埋める

15

3

第1章

「[穴埋め式] 世界ことわざ辞典」 言葉だけを学習するということ

〈短歌AI〉とは何か

新聞社のつくる〈短歌AI>

メディア研究開発センターというところ

メディアアートから新聞社に

まずは短歌を自分で学んだ

歌人と文化部「朝日歌壇」の協力

短歌 AIができること

歌人から学ぶ短歌AI

言葉のつなぎ方は一つではない

お題を詠む短歌AI

質問に答えると短歌ができる

連歌に参加するAI

51

短歌に出会うためのAI

第2章 型を身につける

「短歌を生成する」とはどういうことか

定型を満たす短歌の生成

「モーラ」を合わせて穴埋めしてみる

「型」を身につけたAIたち

AIに「何を任せるか」という視点

第3章 「詠む」 前に 「読む」

短歌AIの学習データ

擬似的な短歌を学習データにする

「ほんとうの短歌」への第一歩

俵万智さんの歌を学習したAI

俵さんにあって「擬似短歌」にない語彙

105

83

33

永田和宏さんの歌を学習したAI

「何を読んだか」が「何を書くか」になる

覚えること忘れること忘れられないこと

第4章 言葉を飛ばす

言語モデルが言葉を生成するとき

いろいろな言葉のつなぎ方

多様な生成を得る手法

「生成パラメータ」 による調整

確率を「ならす」 か 「尖らせる」か

「当たり前」な短歌を生成する

つまらなさへの固執

「飛んだ」 短歌を生成する

ちょうどよいところへ短歌を着地させる

次の「言葉」をつなぐということ

33

133

第5章 うまく付き合う

「勝ち負け」しかないのだろうか 壁打ち相手になってくれたら

私をうつす鏡になったら

似ている歌を教えてくれたら

人ではないあたたかさ

高度なAIが日常にある「いま」

付き合い方には気をつけて

「付き合い方」をつくる

おわりに

主要参考文献

215 211

183



序章「言葉」を計算してつくる

情報を処理するということ

きた

ころもほ

ぐやま

春過ぎて 夏来るらし白たへの衣干したり天の香具山

はんすう

これは、私が「言葉」 で何かを表現することに興味を持つきっかけとなった短歌です。 万葉集に収められている一首として、 持統天皇(645-702) が詠んだこの歌を目にした のは中学生の頃、国語の資料集に載っていたものだったかと思います。

読んですぐ、夏の映像が鮮やかに浮かんだのを覚えています。 その後、大人になってか らも何度も反芻している「言葉」です。こんなに短い、そしてなんでもないような風景を 描写したなかに、一千年以上も前の人間が感じた繊細な日常の一瞬が保存されている。そ れを、未来の子供である自分が解凍して味わえる。これが、今でも不思議に感じられます。

そんな力を人間にもたらしている「言葉」ですが、これをAIが扱う過程では、いった いどんなことが起きているのでしょうか。本論に入る前に、まず序章でコンピュータと言 葉について考えてみたいと思います。 なお、自然言語処理における専門的な知識を、なる べく簡単に説明しようと努力したつもりですが、なかには難しい考え方が出てくるかもし

れません。そういった際は、適宜読み飛ばしていただいてかまいません。 第1章以降で

<感じ〉を掴んでいただいた上で、読み返すということもできるでしょう。

さて、コンピュータは、すべての情報を「数値」で表している。と、聞いたことがある かもしれません。 「そんな根本的なところから始めるんですか」「いや初めて聞きました。 でもそれがAIと短歌に関係ありますか」そんな声が聞こえてくるような気もします。 しかし、この本でこれから書いていく「AIが言葉を計算して短歌をつくること」を考え るためにも、まずこのコンピュータの基本的な原理から見ていこうと思います。

コンピュータの基本的な処理とデータ表現の根底には二進法(「バイナリ」といいます)が あります。数字や文字を「0」 と 「1」 の組み合わせによって表し、それらを加えたりつ なげたりといった命令も、「0」と「1」の組み合わせによって表現します。 画像や音声、 映像といった複雑な情報も、最終的には二進法の数として表現され、処理されます。 画像データを例に考えてみます。 デジタル画像は「ピクセル」と呼ばれる小さな点の集 まりで構成されており、各ピクセルは特定のある色を表現します。これらの色は、一般的 にRGB (Red赤、 Green緑、 Blue青) という光の三原色の組み合わせで表されます。 ある ピクセルのR(赤)の値が大きく、 そのほかの値が小さければ、そのピクセルは赤い点とし て表示されます。 そしてこの色を持った点が集まって、 画像がつくられるのです。 例え

。

17

序章

「言葉」 を計算してつくる

ば、りんごとバナナを収めたデジタル画像があった時、りんごの部分のピクセルは赤色を 表す (R,G, B) = (255,0,0)といった値を持ち、バナナの部分には黄色を表す (R,G,B) = (255,255,0)といった数値を持つピクセルが割り当てられます。そしてこれらの数値を 二進法で表し (255であれば二進法で11111111)、処理するのです。

音声データも同様です。音の振幅を数値で表し、それを時系列で並べたものとして表現 します。これにより、コンピュータはあらゆる画像や音を正確に再現し、保存し、処理す ることができます。

このように、今ではあまりにも生活に溶け込みすぎてしまって意識することもありませ んが、コンピュータはあらゆる情報を数値として扱っています。そしてこの原理は、「言 葉」をコンピュータで処理して何かを表現する、「言葉を計算してつくる」ときにも根底で はつながっています。 すなわち、言葉もコンピュータが処理をするためには、それを数値 として扱う必要があるのです。

「言葉」を数値で表す難しさ

あらゆる情報を数値として扱うコンピュータでは、言葉も数値として扱いたい。しかし そこには、画像や音声とは性質の違う「言葉」だけが持つ難しさがあります。

例えば、画像をより赤くしたいといった処理を行う場合、各ピクセルの赤色を表す数値 を上げれば、とりあえずは実現されるでしょう。音声をより大きくしたいといった場合も、 音の振幅を表す数値を大きくしたら、ひとまずは達成されそうです(もちろん、実際にはもっ と複雑な処理がそこでは行われているでしょう)。

しかし、言葉を扱う場合には、単純な数値の操作が効果を発揮することはほとんどあり ません。例えば、「あ」 は0、「S」は1、「う」は2、というように、世界中のあらゆる文 字を数値として表現するコンピュータがあるとします。ここで、このAIと短歌に関する 本は、とても面白いという文を処理したいとしましょう。このとき、この文の表す感情 的なニュアンスを理解したり(これはポジティブな文である)、続く内容を生成したり(これを読 んで、私も短歌をつくってみたくなった……)、異なる言語へ翻訳したり (This book about Al and tanka is very interesting) するには、 文字を表す数値を単に足したり引いたりしても実現できそうに ないことは、想像に難くないでしょう。

これは、言葉が文字という記号によって表され、その奥に複雑な意味や文脈を持ち、か つそれらが人間によって経験的につくられてきたためと言えます。画像や音声が物理的な 現象として捉えられるのと比較しても、その違いは明らかでしょう。そんな性質を持つ言 葉の処理は、記号に対する直接的な操作や物理法則に従うものではなく、記号に割り当て

199

序章 「言葉」 を計算してつくる

られた数値の単純な演算では、それを表現することはできません。

単語の意味を計算する

コンピュータおよびその内部で実現されるAIが言葉を効果的に処理するためには、言 葉の持っている「意味」や「文脈」を反映した数値表現を獲得する必要があるのです。 近年のAIは「ニューラルネットワーク」と呼ばれる機構を用いて構築されることが一 般的です。ニューラルネットワークは、人間の脳の神経細胞(ニューロン)が情報を伝達す 仕組みに触発されたもので、入力されるデータが表す複雑なパターンや特徴を学習する ことで、新たに与えられるデータの特徴を捉える能力を身につけていきます。 「言葉」の ような複雑な情報を処理したいという時、ニューラルネットワークは非常に効果的な道具 となり、以降で見ていくような「言葉を計算してつくる」ためのさまざまな処理を可能に しています。

「春」「夏」「白」「山」。これらはただの「単語」です。しかし、これを一つ一つ目にする だけでも、私たちはいろいろなことを感じるのではないでしょうか(「春」は暖かい、「夏」 は 暑い、「白」は清潔な感じがする、「山」より海が好きだ……………)。 さらに、 これらの単語を一まとめに して捉えると、「春と夏はどちらも季節を表す言葉だ」とか、「春、夏、山はどれも自然を

「春」 1,0,0

「夏」: 0, 1, 0

0, 0, 1

表現する一方で、白は色の名前であって、少し印象としては遠い」 とか、単語どうしが持 つつながりも漠然と感じられるかもしれません。

このように、ただ文字という記号が並ぶことで表現される「単語」 ですが、その奥には文 字の連なりを超えた意味が込められている、私たちにはそんなふうに見えているでしょう。 この一見単純そうで複雑な「単語」を、AIではどのように表現するのでしょうか。 AIはテキストデータを処理する際、入力される単語をベクトル(Sくつかの数値をまとめ て一つの表現にしたもの)として表現します。 ベクトル化することで、単語間の距離の計算と いった数学的な演算が可能になり、またニューラルネットワークが単語の持つ特徴を学習 できるようになります。

単語をベクトル化する手法のうち、最も素朴な方法に「onelhotベクトル(ワンホ ットベクトル)」があります。例えば、「春」「夏」「白」の三つの単語があるとしましょう。 この時、 one-hotベクトルは各単語を次のように表現します。

123

21

序章 「言葉」 を計算してつくる

(0, 1, 0)

白

0.0.1

図0-1

「春」 「夏」 「白」 をベクトルで表現する

春

(1, 0, 0)

このように、考えたい単語の数(ここでは三つで す)を次元数の個数とするベクトルを用意し、 そのうち一つだけを 「1」、それ以外を「0」と することで、 one-hotベクトルが得られま す。これにより、三つの異なる単語を3次元の空 間上で表現することができます(図0-1)。 とて もシンプルな考え方です。 単語を数値として表す ことができました。

しかし、この方法には単語どうしの関係性を表 現できない、といった欠点があります。例えば、 「春」と「夏」は両方とも季節を表す単語ですが、 one-hotベクトルでは「春」と「夏」の距離 が、「春」と「白」の距離と同じになります。 同じ く季節を表す「春」のベクトルと「夏」のベクト ルの距離よりも、より関連の薄い「春」と「白」

の距離の方が遠くあって欲しいわけですが、 one-hotベクトルではすべての単語間 の距離は一定です。ここで例えば「春と夏はどちらも季節を意味する語である」といった 関係を表現することはできません。

こうした問題を解決するために、語の間の関係性を考慮しながらベクトルをつくる方法 が考案されてきました。その一つとして、前出のニューラルネットワークを用いて単語べ クトルを計算する「word2vec(ワードツーベック)」があります。この手法は、「分布 仮説」と呼ばれる考えに基づいています。

分布仮説は、イギリスの言語学者J・R・ファース(1890-1960)らによって提 唱された仮説で、「単語の意味は文脈 (その単語の周辺にある単語)によってつくられる」と いうものです。この仮説に従えば、似た文脈に現れる単語は、意味も似ていると考えると とができます。確かに、果物を表す単語である「りんご」と「バナナ」はどちらも、「スー パーで(りんご・バナナ)を買った」「(りんご・バナナの皮を剥く」というように、似 文脈に現れる=周辺に登場する語も似ている、といえます。

word2vecでは、ニューラルネットワークがこの分布仮説に基づいて単語ベクト ルを学習するわけですが、その学習は「文脈 (周囲の単語) からその中心にある単語を予測 「する」ことで行われます。

23

序章 「言葉」 を計算してつくる

王一男

王

一男+女

女王

図0-2 「男」 「王」 「女」 「女王」 を単語の意味を考慮した

ベクトルにする

例えば、「今日の天気は晴れです」とい 文があったとしましょう。ここでwor d2vecのモデルは「今日の[ は晴 れです」 の空欄に当てはまる単語(この場 合は「天気」)を予測します。 この学習によ り、モデルは単語の意味を捉えた単語ベク トルを獲得していくのです。意味の似た単 語は空間内で近い位置に置かれ、これによ 単語どうしの類似度を計算することが可 能となります。さらに面白い点として、w ord2vecで得られる単語ベクトルに よって「意味の演算」とも言える処理が可 能になることが知られています。 例えば、 「王」「男」+「女」というベクトル演算 の結果から、「女王」に近いベクトルが得 られます(図0-2)。

意識の辞書

onelhotベクトルの素朴な表現方法から見れば、これは大きな進歩に感じられる

でしょう。単語をベクトルとして表現し、ニューラルネットワークでそれらの関係性を学 習することで、AIは文字の連なりを超えた言葉の意味を数値化しているのです。

私は2017年に、「意識の辞書」という作品を制作・展示しました。

これは、word2vecを用いて、〝特定の個人が持つ意識の流れ”を収めた辞書をつ くることを目指した作品です。 具体的には、ある一人の作家が書いた文章から単語ベクト ルを学習し、”その作家の作品の中で意味の近い単語を並べた"辞書になっています。 展示では「文豪編Ⅰ 夏目漱石」と題して、夏目漱石の遺した文章を学習することで、 彼の思考を辞書という形で捉え直そうと試みました(図0-3)。

この辞書で「人生」という単語を引くと、「意義」 や 「散文」 といった単語が周囲に並ん でいるのがわかります。 また、 「恋愛」を引けば、「罪悪」 「意味」 「問題」といった言葉が 近くに配置されているのを見つけることができます。 ただページをめくるだけで漱石の内 面に迫ることができる、そんな辞書になっています。

単語の意味的な距離を定量的に把握して、 結果をもとに単語を配列することで、こ

25

25

序章

「言葉」を計算してつくる

E

した金はかくしてって 取られ、またって消費されてし まった。

A-13

押していた。

に続け

だのを

いう努力も心もなしに、天然自然 自分を してしまった。

必要 【6901-2

大して注意を払う必要もないので、

42-44

恋愛 [名詞] 4600-1

最近意とし うま

れた一種 家の心を

意味 [名詞] 4601-1

聞いた。

少し経ったら、ま

力を見た。

はちっと女大学でも読めば軽いの 近頃は恋愛小説ばかり読んで まことにるって

せる [4

このことによっ も しよう

で となるのです。

なるかも分らない。

この意味においてイズムは会社の決

比較すべきものである。

挙げる ・

事実 【名】 4602-2

へ出て来 挙げるように

野

今日の告白をして、

04-23

相談が襲った。

もの

イルの間に丸め込ん なお した。

持ち運びに相

について、問い けたのはこれが

れもこの時に限って自分が生き ている事実を満足に自覚するのだ ろう。

11

ってあの

は本人の希望に

[22]4306-13

と思うと、突然えら して急に る。 飛び

自分はその

かまたは自

と判断に苦しんだ。

出所があるの

687-23

要点

自分だけでは、父から

必要があった。

移る事があ

488-40

こうと、 ている。

どこまでも下手に出る手

しているらしく見えた。

600-40

問題 [名詞] 1600-2

事柄 【名】 4604-15

もう少し

586-14

白いと今でも人が記憶しているよう な事件はないでしょうか

もず物を見るべき点

々に教えてくれたのでありま す。

矛盾 【名】 4987-11

材料 [名詞] 4605-12 なかなかもって再掲 めるだけの材料などはにし も合せておりません。

した画面の一字で賞 を埋めて考え

A-16

りの者に渡して、必

受け取って出てみると、 使っていない。

(18328

はないの

[名詞] 499814 いずれにしても先生のいう いとして かった。

全 [] 4606-14 なるほどそんな切り詰めた生活をす ある人に比べたら、私は全員にかけて、 だったかも知れません。

衣食 [名詞] 4607-1 そうしてその手にどうかみんな 考えているような食の口の事が 書いてあればいいと念じた。

開放 [名詞] 4999-42 自分のしようと

6-11 当てて見ないだって区役所へ行 きゃ、 すぐる事だが、ちょいと そのために聞いて見るんだよ。

参考

は

けった。

47001

X13025

意識の辞書

A Dictionary of Consciousness

図 0-3 夏目漱石の思考を単語 で並べた 「意識の辞書」

ht

の、

るだけ

たね

のだ。

た。

か

ては

考えた

26

れまでにない辞書を構成しています。 文の意味を計算する

すると、いつの間にか、うす日がさし始めたと見えて、幅の狭い光の帯が高い天井 の明り取りから、茫と斜めにさしている。 能勢の父親は、丁度その光の帯の中にい た。 周囲では、すべての物が動いている。眼のとどく所でも、とどかない所でも 動いている。そうしてまたその運動が、声とも音ともつかないものになって、この大 きな建物の中を霧のように蔽っている。

これは、芥川龍之介の『父』という作品に現れる「文」の集まりです。 これも私の言葉

(芥川龍之介 「父』)

27

序章 「言葉」 を計算してつくる

です。

に対する原体験の一つとなったもので、読んでいるうちに、映像、音、そして空気までが、 まるでその場にいるかのように感じられます。

文は、単語が集まってつくられるものです。 そしてそれは、単語単体よりもはるかに複 雑な情報を伝えています。さて、このような「文」をAIが扱うには、どのようにすれば よいでしょうか。

単語の意味を数値化する「単語ベクトル」を見てきましたが、この概念を「文」に当て はめることで「文ベクトル」を考えることができます。 文ベクトルは、文が表す内容をベ クトルで表現します。 この計算方法には、例えば文を構成する単語の単語ベクトルを組み 合わせる単純な方法から、文の組み合わせを用いてニューラルネットワークがその関係性 を捉えた文ベクトルを学習するといった手法まで、さまざまなものが提案されています。

それら文ベクトルの計算によって、文の特徴を表現する文ベクトルを得ることができま す。例えば「今日の天気は晴れです。」 「明日も晴れるでしょう。」「短歌をつくるのは難し い。」と三つの文があったとしましょう。これらの文ベクトルを計算することで、天気に ついて表現した最初の二つの文は似ていると判断され、短歌について表現した最後の文と の距離は遠くなる、といった、文の意味するところを考慮した表現を得ることができるの

文ベクトルは、さまざまな場面で応用することができます。例えば、SNS投稿の感情 分析や、ある商品に対するレビュー文のポジティブ・ネガティブ判定では、文の内容を数 値で表現する文ベクトルがそれらの処理に効果を発揮します。ほかにも、質問応答システ ムにおいて、利用者の質問とデータベース内の文の類似度を計算し、関連する回答を効率 よく見つけ出すために用いることが可能です。

単語から文へと複雑さを増していく言葉についても、それらを数値の集合体であるベク トルに変換することで、コンピュータは効果的に処理する能力を獲得します。

文章を生成する「言語モデル」

突然、誰かがあなたに 「猿も木から?」と問いかけたら、ほとんど反射的に「落ちる」 という言葉が浮かびませんか。 「石の上にも?」と問われたら 「三年」ですし、「一寸先 は?」「闇」です。このように、私たちには自然と出てきてしまう言葉の続きとも言える ものがあります。

さらには、ことわざのような慣用的な表現でなくても、例えば「今日の天気は」という 文の断片に対して、私たちは「晴れです」 や 「雨です」といった具体的な続きを予測でき ます。このように、私たちには与えられた文脈からそれに続く言葉を想像する、 文章を生

29

序章 「言葉」 を計算してつくる

成するための能力が自然と備わっています。

そしてこの「文章生成」能力は、人間だけの特権ではありません。AIは、大量のテキ ストデータから言葉のつながりが表すパターンを学習することで、人間のように文章を生 成する能力を身につけています。 そうした文章を生成することのできるAIを「言語モデ 「ル」と呼びます。

この「言語モデル」は、その名の通り、私たちの普段使う言葉をモデル化したもの つまり、実際の言語と似るようにつくられた 「模型」 です。 そしてこの模型の中では、確 率の考え方を使って言葉を扱っています。 言語モデルは、入力された文章の文脈に基づい て、次にくる可能性のある言葉を予測することができるのです。

次にくる言葉を予測する

「今日の天気は」というフレーズを言語モデルに入力した場合、このモデルは入力された 内容から、続く可能性のある言葉を予測します。

「今日の天気は」に続く言葉・・・・・・例えばそれは「晴れ」「曇り」 「雨」 「暑い」「寒い」とい った、天気に関する語になるでしょう。あるいは「昨日より寒い)」「あの日のことを思い 出させる)」といった、天気とは直接関係はないけれど、後に続きそうな言葉かもしれませ

0.200

0.175

0.150

0.125

0.100

0.075

〈確率〉

0.050

0.025

0.000

晴れ 曇り

雨

あい 快 < 言葉 >

良い

どう

図0-4 「今日の天気は」の次にくる言葉と確率

す。 語モデル」なのです。 に高い確率が割り振られているのがわかりま た(図0-4)。やはり、天気に関連する言葉 順に「晴れ」「曇り」 「、」との結果を得まし と、次にくる言葉の候補として、確率の高い 成してみます。 「今日の天気は」と入力する 実際に、手元にある言語モデルで文章を生 ような過程を経て文章を生成できるのが「言 あろう確率=生成確率」を計算します。この された文章の次にくる言葉として出現するで ん。このような「言葉」のそれぞれに「入力

-5)。ここでは、「あいにくの」という表現 で予測され、「曇」 「天気」と続きます(図0 してみます。 すると、「雨」が最も高い確率 次に、「今日の天気はあいにくの」と入力

31 序章 「言葉」を計算してつくる

確率 0.7 0.6 0.5 0.4 0.3 0.2 0.1 1. 0.0 雨天気予報 青 あい < 言葉 > よう

図0-5 「今日の天気はあいにくの」の次にくる言葉と確率

〈確率 0.30 0.25 0.20 0.15 0.10 0.05 0.00 良い 良く 寒良かったいい 暖気持ち 晴れ <言葉>

図0-6 「今日の天気はとっても」の次にくる言葉と確率

32

0.10

0.08

〈確率〉

0.06

0.04

0.02

0.00

<言葉> 晴れ良い 晴 良かった 曇 良く

快

雨よかった

図0-7 「今日の天気は意外にも」の次にくる言葉と確率

が「雨」の予測を高める要因となっているこ とが明らかです。

では、「今日の天気はとっても」と入れる と、どうなるでしょうか。 「良い」「良く」「寒」 「良かった」「SS」 という結果が計算されま した(図0-6)。この場合、「とっても」とい う言葉がポジティブな影響を与え、その結果 が予測候補に反映されています。

もう少し複雑な文脈を持った入力について も見てみましょう。 例えば「今日の天気は意 外にも」と入れてみます。 すると、候補の上 位に「晴れ」 「曇」 「雨」のいずれをも含む結 果が計算されます(図0-7)。確かに、「意外 にも」と言われたところで、それ以前の文脈 がわからなければ、「意外」がどんな天気な のかはわからず、この後になんと続ければよ

33

33

序章 「言葉」を計算してつくる

0.10-

0.08

〈確率>

0.06-

0.04

0.02-

0.00-

〈言葉> 良い良く良かった晴れよかった 快晴良い

図08 「昨日まで雨だったが、 今日の天気は意外にも」 の

次にくる言葉と確率

瑗

いものか、迷ってしまいます。

そこで「昨日まで雨だったが、今日の天 気は意外にも」という文を入力してみまし ょう。すると、 「良い」 「良かった」「晴れ」 という語が上位にきて、先ほどの「曇」「雨」 という語がなくなりました(図0-8)。 こ のような、論理的とも言える文脈にも対応 しながら、言語モデルは次にくる言葉の確 率を計算すること=「言語のモデル化」が できていることがわかります。

また逆に、「今日の天気は」の後に「うど ん」だとか「階段」だとか「魚」だとか、 文脈からの流れが不自然となる、その後に 続かなさそうな言葉に対しては、低い確率 が計算される、ということが言えます。

しかし、言葉はもっと自由なものだと考

文章を大量に読んで学ぶ

える人もいるでしょう。「今日の天気はうどん日和だ」 や 「今日の天気は階段の影をくっ きりと見せている」「今日の天気は魚の腹のような銀色だ」といった表現がいくらでも可 能であるのも、確かに語の連なりがつくる文章の持つ一つの特徴です。これは、言葉が持 つ表現の可能性を示すものとして、創作においては特に重要となるでしょう。そうした、 入力される文脈からあえて「ジャンプ」 飛躍した生成についても、後の章で詳しく触れ ていきます。

ある晴れた日。知り合いに「今日の天気は晴れですね」と言われたら、あなたは「そう ですね」と素直に相槌を打つでしょう。一方、「晴れですね天気は今日の」と言われたら、 いかがでしょう。耳慣れない表現に気持ち悪さを覚えて、なんと返答しようか躊躇してし まうかもしれません。どちらも同じ意味を持ちながら、一方はごく自然に、もう一方はと ても不自然に感じられます。

日常生活で何気なく交わされる言葉ですが、その背後には今日まで続く人間のやり取り の積み重ねがあり、そこには自然な言葉のつながりといったものが存在しています。AI も人間のように言葉を扱うためには、この「言葉のつながりの自然さ」を計算できなくて

35

序章 「言葉」を計算してつくる

はなりません。 そしてその自然さを獲得するために、私たちの言葉の後ろに膨大な時間が 流れているのと同じように、AIにも大量の言葉を学習させる必要があるのです。

こうして流し込む大量のテキストデータは「コーパス」と呼ばれ、言語モデルの開発に 欠かせない存在となっています。もっとも、コーパスはAIの開発にとどまらず広く言語 研究のために活用されており、その歴史も古いです。

世界初の大規模なコーパスとしてよく知られたものに、1964年にアメリカのブラウ 大学で作成された「ブラウンコーパス」があります。このコーパスでは、文学作品、新 聞、学術論文など、さまざまなジャンルから100万語を超える英語テキストを集めてい ます。日本語においても、書籍はもちろんのことブログやネット掲示板に法律まで含めた 1億430万語のデータからなる「現代日本語書き言葉均衡コーパス」や、話し言葉を言 い直しや言い淀みも含め詳細に記録した「日本語話し言葉コーパス」などがあります。 最 近では、インターネットから収集された膨大な記事からなる、非常に巨大なコーパスが言 語モデル開発に用いられています。 さらに、そうした巨大なコーパスから、学習のノイズ となるデータを取り除く研究も進められています。これらのコーパスは、人が実際に残し た言葉を集めているので、言葉の自然な使われ方や、そのなかにある知識を表現する貴重 なデータと言えます。

ょう。

人間によって書かれた・話された言葉を集めたコーパスを学習することで、言語モデル は人間らしい自然な言葉のつながりを獲得し、またそれを再現できるようになります。 A Iの言語能力は、私たちが今まさに話し、書いている言葉がつくっているとも言えるでし

この記事は実在しません

入力 細川 近治

朝日新聞社メディア研究開発センターでは、2020年に「#この記事は実在しません」 という言語モデルのデモンストレーションを公開しています (https://cl.asahi.com/api_data/gpt2demo.html)。これは人名や都市名、書籍名などの入力から、言語モデルがそれらに対する説 明文を生成するというものです。例えば「細川近治」という入力から、次の文章が生成 されます。

細川 近治(ほそかわきんじ、1948年5月9日)は、日本の科学技術評論家、 東京理科 大学教授。 石川県金沢市生まれ。 金沢美術工芸大学卒業。 朝日新聞社に入り、科学写真 部、科学部記者を経て東京理科大学教授に就任。 1998年『宇宙船地球号を降りたコウ

37

序章 「言葉」を計算してつくる

モリ』を出版、 芸術選奨文部大臣賞受賞。

いかがでしょう。まるで本当にいそうな人物の情報を生成している、と感じられるので はないでしょうか。他にも、いくつか例を見てみましょう。

入力 サンディノスの崖

入力 引導局

生成 サンボディノスの崖(サンボディノスのがけ)は、ナポリのサン・ボディノス・クラブの 崖である。この崖は、ナポリの中心であるランゴン・ディ・ムルシア近くの絶壁上にあ る。海抜は約6メートル。崖上の建造物には、サン・ボディノスの家の紋章があしらわれ ている。

生成 引局(ひきどうきょく)は、日本の総務省に置かれる大臣官房の一つで、各種許認可 等の行政事務を処理する。2020年(令和3年)7月1日現在の配置、情報通信技術に関 する企画立案等を行う「企画院」と、情報技術の効果的な利活用を推進する「戦路室」に分 かれて業務を行う。

が聴こえてくる』

入力 生成

が聴こえてくる』は、1984年1月9日から同年3月28日までフジテレビ系 列局で放送されていたフジテレビ製作の情報番組である。当時話題になっていた男女の恋 愛に関するトーク番組。司会は、当時アイドルだった森高千里が、毎回のように男女間の 関係や本音を突っ込んで問いかけていた(男女の会話がそのままではありえない関係だっ たとして、森高も多少ハラハラさせられたことがあったと語っていた)。また、番組中で の男女の会話のシーンは、通常のトーク番組と比べてかなりズレており、また、同時間帯 で放送されていた『スチュワーデス・ストーリー』 や 『FNS SOUL』 に比べると、明 らかに男女の会話のテンションが違っていた。

ChatGPTのような最近のモデルの生成と比べると細かい点に矛盾などが感じられま すが、2020年当時でもこれだけの文章を生成することができていました。しかしなぜ、 こうして未知のものに対する情報を生成することができるのでしょうか。

実はこの言語モデルは、「フリー百科事典 ウィキペディア日本語版」の記事を「コーパ ス」として学習することでつくったものです。 ウィキペディア日本語版の記事は「タイト

39

序章 「言葉」 を計算してつくる

ル」が先頭にあり、それに続いてその内容を説明する文章が続きます。ですから、例えば 「人名」らしいタイトルであればその人に関する説明文を、 「地名」のようなタイトルであ ればその場所について紹介する文章を生成します。入力された文脈に合う「学習したコー パスとして自然、つまり日本語ウィキペディアらしい自然さを持ったテキスト」 を生成す ることができるのです。

記事の「見出し」を生成するAI

先ほど見たように、言語モデルは「人によって書かれたり話されたりした言葉を集めた コーパスを学習することで、入力に与えられた文章の続きを生成することができる機械」 と考えられる訳ですが、さまざまな言語表現やタスクに特化した学習を行うことで、より その問題に対して賢く振る舞うことが可能となります。

皆さんもこれまでに、インターネットで自分の書いた日本語を他の言語に翻訳したり、 SNSに流れるコメントを日本語に翻訳して読んだことがあるかもしれません。その背後 にも言語モデルが動いていて、異なる言語の対訳を集めたコーパスを学習することで翻訳 文を生成しています。

朝日新聞社メディア研究開発センターで開発している自動要約生成API 「TSUNA

10

(ツナ)」では、入力された文章をうまく要約しながら 「見出し」を生成する言語モデルを 作成しています。この言語モデルは、記事と見出しのペアを学習データとして、入力され る文章をどのように要約して短いテキストにするかを学んでいます。

例えば、「この度、新刊 『歌になる公共空間』が発刊されました。ベテランから新鋭まで 多彩な歌人が、青春を過ごした図書館や足繁く通う文化会館、日常の散歩コースである公 園など、思い入れのある〈公共の場〉を題材に短歌を綴っています。このアンソロジーは、 私たちの日常に溶け込む公共的な空間に対する新たな視点を提供し、読者に〈社会に開かれ 場所〉とその中にいる〈私〉の関係を再考させるものです。......」という記事を与えてや ると(架空の記事です)、次のような複数の異なる見出しや要約文を生成することができます。

・新刊『歌になる公共空間』

・「歌になる公共空間」 日常に溶け込む公共的な空間に新視点

・この度、新刊『歌になる公共空間』が発刊された。日常に溶け込む公共的な空間に対す る新たな視点を提供し、読者との関係を再考させる。

新聞記事の見出しや要約文は、それが紙面に載るのか、スマートフォンに表示されるの

41 序章 「言葉」を計算してつくる

文の空白を埋める

か、はたまた電光掲示板に流れるのか、によって適切な長さが異なります。 このような載 るべき場所に応じた文字列の長さも考慮しながら、自動で記事の見出しを生成することが できるのです。

これまで、「文章を生成する」 言語モデルについて見てきましたが、 (空欄)を 「埋める」 言語モデルも存在します。これは、ちょうど穴埋めドリルのように、文章中にあ [ ■部分を、前後の文脈を考慮して推測することのできるモデルです。

このモデルも、大量のデータを学習することで部分を埋める言葉を計算する能力 を獲得しています。またそれが、まるで知識を持っているかのように振る舞うというのも、 面白い点として挙げられるでしょう。

先ほどのword2vecにも似ているように感じられるかもしれませんが、このモデ ルはさらに複雑なニューラルネットワークの構造を持ち、より長い文脈を扱うことができ ます。また、例えば「アマゾン」のような、それが森林を表すのか、それともオンライン ショッピングサービスを指すのか、 複数の意味を持つ単語に対しても、前後の文脈から適 切に表現を得ることができます。さらには、単語にとどまらず、 文全体の意味を捉えるこ

()

0.6

0.2

0.0

東京 大阪 京都 北京 都 名古屋 横浜 首都 新宿 上野 <青葉

図09 「日本の首都はである」のに入る言葉と確率

とも可能です。

ここで、このモデルに「日本の首都は [

である」という文章を入力してみます。この ■部分は事実上「東京」なわけですが、 実際のモデルも100%に近い確率で「東京」 という語を候補に挙げ、 これを知識として持 っている(ように見える)ことがわかります(図 069)0

ここで面白いのは、「大阪」「京都」、はた また「北京」といった地名にも、わずかなが ら確率が与えられている点です。 言語モデル はその仕組み上、モデルが持っている語のす べてに対する確率を計算することができま す。つまり、言語モデルの生成のさせ方によ っては「間違い」を生んでしまう場合も十分 にありうる、ということがここからわかるで

45

序章「言葉」を計算してつくる

〈確率

0.05

0.00

夢 間違い 無理誤り 妄想 当然 反対 コンセプト AI それ

(言葉)

図0-10 「短歌をAIで学ぼうというのはである」のに

入る言葉と確率

しょう。またそれは、私たちにとっては 「東京」でしかない答えであったとしても、 言語モデルにとっては「大阪」となる世界 がとても小さな可能性として見えている、 と言うこともできるかもしれません。 ほかにも、何か文章を入れてみたいと思 います。この本の内容にちなんで、 「短歌 をAIで学ぼうというのは[ □である」 という入力ではどうでしょう。 「夢」「間違 S」 「無理」「誤り」 「妄想」 「反対」 ......辛 辣とも言えるような言葉が並んでしまいま した(図0-10)。「学ぼうというのは」とい う表現で、ネガティブな語を誘っていると も考えられますが・・・・・・ (試しに「短歌をAIで 学ぶのは である」とすると、「初めて」 「初」 「異例」という言葉が並びました)。

0.25

〈確率

0.20

0.15

0.10

0.05

0.00

男 人 方 子

女娘 私ママ 奴 <言葉>

図0-11 「あのは医者である」のに入る言葉と確率

-

「あの[

職業と性別は結びつくべきものではありま 章で扱っています。 ているのがわかります(図0-12)。本来、 さてここで、「あの いった女性を表す言葉に高い確率が振られ 1)、「看護師」の方では「彼女」 「娘」と 者では「男」に高い確率が与えられ(図0 の文章を入れてみます。結果を見ると、医 は看護師である」という二つ 役割や使い手との関係についても、あとの ょうか。そういったAIがあるからこその があるからこそできた表現とも言えるでし 言うことができるかもしれません。モデル るのも、言語モデルが生成したおかげ、と られるような言葉をいまここに堂々と書け 一方で、一見この本の主張とは逆に感じ □は医者である」

45 序章 「言葉」 を計算してつくる

0.16

0.14

0.12

0.10

0.08

0.06

〈確率>

0.04

0.02

0.00

彼女子娘の先生男女

(言葉)

図0-12 「あのは看護師である」のに入る言葉と確率

せんが、言語モデルがジェンダーバイアスを 持っているかのように見えてきます。 このように、言語モデルは学習データに潜 んでいるバイアスを再現することがあり、近 年ではそれを補正するための手法も研究され ています。

「穴埋めにどんな言葉が入りそうか」という 形式は、ちょうど私たちもクイズなどでその 人の知識量を測るために用いることがありま す。 それをうまくこなす言語モデルが賢く見 えるのは、当然のことかもしれません。 しかしそれはまた、言語モデルを形づくる データの持つ偏見までを露わにするものでも ありました。言語モデルの生成する言葉の背 後には、さまざまなバイアスを抱えた私たち の社会がある、と考えることもできます。そ

うした言語モデルの振る舞いを見ると、私たちも「そこにどんな言葉が入るか」を考える 時にはあらゆる可能性を考慮して、分け隔てのないたくさんの候補を持てるようになりた い、と思えてきます。

「[穴埋め式] 世界ことわざ辞典」

私たちは以前、この前後の文脈から空白を埋める言語モデルを使って、 「[穴埋め式]世 界ことわざ辞典」という作品をつくったことがあります。これは「日本語を学習した言語 モデルに、海外のことわざの穴埋め問題を解かせることで、新たなことわざを生成する」 というものでした。

例えば「美しいものが美しいのではない、好きなものが美しいのである」という、イタリ アのことわざがあります(あるそうです)。 これを「美しいものが美しいのではない、 なものが美しいのである」として、日本語を学習したモデルで穴埋めをします。 すると、 「ダメ」や「もっとも」といった言葉がそこへ収められ、新たなことわざが生まれていき ます。

・美しいものが美しいのではない、だめなものが美しいのである

47

章 「言葉」を計算してつくる

.

美しいものが美しいのではない、 ・美しいものが美しいのではない、 美しいものが美しいのではない、 ・美しいものが美しいのではない、

ダメなものが美しいのである すてきなものが美しいのである もっともなものが美しいのである きれいなものが美しいのである

・美しいものが美しいのではない、 ・美しいものが美しいのではない、まれなものが美しいのである

しあわせなものが美しいのである

・美しいものが美しいのではない、たしかなものが美しいのである

・美しいものが美しいのではない、ただなものが美しいのである ・美しいものが美しいのではない、おしゃれなものが美しいのである ・美しいものが美しいのではない、バカなものが美しいのである ・美しいものが美しいのではない、ましなものが美しいのである ・美しいものが美しいのではない、まじめなものが美しいのである ・美しいものが美しいのではない、結構なものが美しいのである

・美しいものが美しいのではない、正直なものが美しいのである

ことわざは、誰か一人の優れた作家によってつくられるといった性質のものではありま

89

せん。文化や習慣を同じくする集団の中で自然と発生し、伝わるものだと言えるでしょう。 日本語のデータを学習した、日本語の自然な表現を再現する言語モデルが、初めて見るで あろう海外のことわざでどのような穴埋めをするかによって、日本語話者が形成する世界 が持つ価値観の表出を見ることができるのではないか、と思ってつくった作品です。

言葉だけを学習するということ

AIは私たちの言葉を学習することで、単語や文の意味を考慮した表現を獲得したり、 文脈に合わせた文章の続きを生成したり、さらには翻訳や穴埋めといった問題を解いたり することができるのがわかりました。しかし、これらのAIは言葉だけを学習してつくら れています。したがって、こうしたAIが言葉を処理している時、文字という記号とその 奥にある実世界との結びつきを、私たちのように理解しているわけではありません。 例えば、「気持ちのいい雨」というフレーズをAIに読ませたとしても、AIにとって これは単に「気持ち」 「の」 「SS」「雨」という言葉の列にすぎません。AIはこの言葉 から、私たちであれば感じ取れるかもしれない、晴れた空の下できらきらと輝いている雨 粒の視覚的イメージや、雨に濡れた道路の独特な匂いを感じることはできません。

このような、記号と実世界の実体やそれにともなう経験・感覚がどのように結びつくか

49 序章 「言葉」を計算してつくる

という問題を「記号接地問題」と呼びます。この問題は、AIが言葉の字面のみによって 表される意味や文脈を扱うだけでなく、実世界にある実物との対応やその感覚までを身に つけるという意味で、AIに身体性を与える問題とも言えるでしょう。 例えば、 言葉とそ れに紐づく画像を同時に学習することによって、AIは言葉と視覚の結びつきを得ること ができ、部分的に私たちの感覚を模倣することが可能となります。

言葉から言葉つむがずテーブルにアボカドの種芽吹くのを待つ

俵万智

これは俵万智さんの歌集『アボカドの種』に収められている一首です。 陶芸家である富 本憲吉の「模様より模様を造るべからず」という言葉と、水耕栽培しているアボカドから 着想を得て生まれた歌ということですが、歌集のあとがきではまさに言葉から言葉を生成 するAIとの対比についても言及されています。

言語モデルが生成する言葉とは異なり、人間の言葉には常に言葉を超えた何かが息づい ているということを、この歌から静かに感じ取ることができます。次の章からはいよいよ 〈短歌AI〉について書いていきますが、私たちの歌も決して「言葉だけ」から生まれる ものではないと、いつも心に留めておきたいものです。

第1章 〈短歌AI〉とは何か

新聞社のつくる 〈短歌AI〉

「新聞」という言葉から、皆さんはどのようなことを連想されるでしょう。

それは新聞紙そのものだったり開くとあの独特な匂いがする)、 早朝の配達員だったり (バ イクの音が聞こえる)、はたまたスーツを着た記者だったり(ひょっとしたらタバコをくゆらせてい るかもしれない)と、どこか懐かしい、とまではいかないまでも、「新しくはない」 雰囲気の モノやコトが多く思い浮かぶのではないかと思います。 実際、新聞は古く、それなりに長 い歴史を持っています。 国内初の日本語による日刊紙の登場は明治3年ということですし、 その前身であるとされる瓦版を考えれば、江戸時代にまで遡ることができます。

さかのぼ

一方、「AI」は多くの人にとって、どこか未来的なものを想起させる言葉ではないでし ょうか。実際はAIの研究も、コンピュータが登場して以来の長い歴史を持っていますが、 それは発展を繰り返し、最近では生成AIに社会の大きな関心が集まっています。多くの 人にとってそれは、これから実現される未来をつくる革新的な技術の一つ、と捉えられて いるでしょう。

ここからは、その「新聞」と「AI」という、まるで対照的な二つの交差点である、新 聞社がつくった〈短歌AI〉の話をしていきます。新聞社がなぜAIを? それもなぜ短

52

しょう。

歌のAIを?と疑問に思われているかもしれません。しかし、短歌AIは新聞社だか らこそ、つくることのできたAIです。 過去から現在まで続く、長い時間のなかで社会を つないできた新聞社におけるAIとは、またその中にある〈短歌AI>とは何であるか、 この章ではその全体像を説明します。

メディア研究開発センターというところ

私が所属する朝日新聞社メディア事業本部メディア研究開発センター、通称「M研」は、 2021年4月に発足した研究開発組織です。ウェブサイトには「人工知能を始めとする 先端メディア技術と、新聞社ならではの豊富なテキストや写真、音声などの資源を活用し、 社内外の問題解決を目指すとともに、自然言語処理や画像処理をはじめとした先端技術の 研究・開発を進めていきます」と書いてあるのですが、これはつまり〈新しいテクノロジー と新聞社ならではのデータを掛け合わせて、新たなモノをつくる場所であると言えるで

「新聞社ならではのデータ」と書きましたが、 過去の記事をはじめとしたたくさんのデー タの蓄積があるのが、新聞社の面白いところです。 朝日新聞社は設立が明治22年と150 年近く前に遡るわけですが、現在ではそのうちの直近約30年、1000万ほどの記事がデ

53

第1章

<短歌 AI> とは何か

ジタルデータ化されています。30年の間に日本や世界で起きた出来事について、記事執筆 の専門家である記者が残したテキストや写真を保有しているのです。そしてこれらのデー タは日々社内で生まれ続け、今後も増え続けていくことでしょう。新聞社は、その時代時 代の社会につながるデータが生産される場所である、と言えます。

そしてこのデータは、AIをはじめとするテクノロジーを応用する際に、たいへん重要 な資源となります。 実際、序章でも紹介した自動要約生成API 「TSUNA」 では30年 分の記事と見出しのペアを学習データとして、入力された文章を的確にまとめて見出しを 生成する言語モデルを学習しています。また、文章の校正を支援する「Typoless (タイポレス)」では、記者が記事を執筆する際に生まれる編集履歴を学習データとして、日 本語の誤りを検知し修正候補を提示するAIを作成しています。

そのほかにも、紙面の画像から記事を自動でテキストデータ化する紙面復刻や、記者の 取材テープなどを自動で文字起こしする技術、記事に関連する情報を視覚的に表現するデ ータビジュアライゼーションといったテーマにも取り組んでいます。M研は、「新聞社だ からこそできる研究開発」の実践の場と言えるでしょう。

新聞とAI、一見古いものと新しいものとの奇異な取り合わせのようにも見えますが、 実はそれぞれが相互に影響し合い、これまでにない 「新しい何か」をつくることのできる、

非常にいい相性を持っているのです。

.TSUNA

・Typoless

自動要約生成API 「TSUNA (Text SUmmarizatioN Application)」 は、 入力されたテキスト を言語モデルによって要約し、編集業務で利用できる見出しや要約文を生成するものです。 TSUNAの大きな特徴として、生成する見出しや要約文の長さをコントロールできる という点があります。これは、新聞紙面やパソコン、スマートフォンなど、記事が掲載さ れるメディアによって文字数制限が異なるため、実用上必要な技術として開発されたもの です。さらに、利用する状況に合わせ、同時に複数の候補を生成することもできます。生 成された複数の見出しから、利用者が取捨選択した上でより良い見出しに修正をする、な どのシチュエーションでの利用が考えられます。

Typolessは、文章の校正を支援するAIサービスです。新聞の膨大な校正履歴 を学習させたAIは文脈を解釈し、「てにをは」などの助詞の誤りをはじめ、誤字・脱字・ 衍字がある箇所を検出した上で、どのような修正をすればよいかを提示します。

55

第1章 <短歌 AI> とは何か

また、新聞社の校閲ルールが詰め込まれており、誤りやすい日本語・漢字・慣用句・専 門用語などの修正候補を提示することもできます。いままさに書いている文章にもきっと どこかに間違いが潜んでいるかと思うのですが、 これを明らかにしてくれるAIとして、 社内外で活用が進んでいます。

メディアアートから新聞社に

そんな新聞社の研究開発組織で 〈短歌AI〉をつくることになる私について、「はじめ に」で簡単に説明しましたが、開発の背景としてここでもう少し詳しく書いておこうと思 います。

私はいま、〈短歌AI〉の研究開発と短歌の実作のどちらもやっている人間、というこ とになります。しかし、そういった人は、私の知るところ〈短歌AI〉をつくり始めた2 020年当時(まだChatGPTも公開されていません)には少なく、また、それを「仕事」 としてやっている立場の人間というのは、いなかったように思います。なぜそうなったか、 ということを説明するには、私が新聞社に来る前のことからお話しした方がいいかもしれ ません。

私は、今でさえ「AIをつくる」といったことに取り組んでいるので「元来理系の人間

56

だ」と思われがちです。しかし、もともとは国語の教科書や授業が好きで、次の時間割り

算数だと思うと、どこか心が少し曇ってしまうような、そんな子供でした。「言葉」そ のものやそれによって表されるものに惹かれるところがあったのでしょう。当然、将来 もいわゆる文系に進むものと思っていました。しかし、高校生の頃に出会ったメディアア ートをきっかけに、考えが変わります。

メディアアートは本来、メディアやそれを形成する技術を題材にした作品をつくる芸術、 ということだと思います。そういった性質から、例えばそれはビデオであったり、インタ ーネットであったり、各時代で利用可能な、あるいは社会に大きな影響を与える新しいテ クノロジーに触発され、常に形を変えているようなところがあります。

私が高校生の頃の日本のメディアアートは、特にセンサーやコンピュータによって音や 光(映像)を制御する分野、という雰囲気がありました。具体的な作家名を挙げると、池 田亮司、徳井直生、澤井妙治、黒川良一などで、人の手のみではつくることのできない音 や映像を具現化していた人たちです。その、これまでに体験したことのない新しい刺激に 取り憑かれていたのが1歳頃でした。ちょうど、自分の進路を文系と理系のどちらか一つ に決めなければいけないという頃です。そこで私は、「これから面白いものをつくるには、 コンピュータを動かしている裏にきっとある、数学みたいなこと?もわかっておいた方が

57

第1章 <短歌 AI> とは何か

いいかもしれない」と、ぼんやりした理由から理系へ進むことになります。

その後、大学では応用数学を専攻して、そのまま大学院に在籍していた頃、 Qosmo (コズモ)というメディアアートや広告のためのアプリケーションを制作する会社に入りま す。ここは、先ほど名前を挙げた徳井さん、澤井さんらが中心となってつくられた会社で、 そこからしばらくはプログラマという肩書きで「プログラムを書いて、ものをつくる」こ とを仕事にするようになりました。

最初に担当した仕事は、あるホテルのロビーにインストールした照明システムの開発で、 人や音に反応するセンサーと連動して色や明滅のパターンが変化する、100本以上のL EDを制御するプログラムを書くというものでした。 その後も、加速度センサーを使って 車の動きに連動して音を生成するアプリケーションや、人の体の動きを映像や音へと変換 するシステム、特殊なパターンが浮かび上がる洋服など、いろいろなものを対象とした、 コンピュータによる表現を続けていきます。

しかし、もともと国語が好きだったような子供です。 コンピュータを扱って映像や音を つくる、といったことをしながらも、だんだんと「言葉」に興味が向かいます。そこで、 自然言語処理に関連した作品制作や広告制作に取り掛かるようになり、序章で説明した 「意識の辞書」をつくったのもこの頃です。 そして30歳を少し過ぎた頃、「ここで一度、言

葉とテクノロジーということに、もう少し集中して向き合ってもいいかもしれない」と思 い始めます。

ちょうどその頃、メディア研究開発センターの前身である「朝日新聞社メディアラボ」 が、自然言語処理分野の研究員を募集しているとの求人を目にしました。新聞社に研究開 発組織があるということ自体、私もその頃はあまりよくわかっていなかったわけですが、 新聞記事という「言葉」を日々生産している新聞社、そしてかつては二葉亭四迷や夏目漱 石、石川啄木といった文芸にも関わる人たちがいた朝日新聞社の求人です。 「これだ」と思 い、応募することになります。

運良く転職が決まると、先ほど紹介したTSUNAのような業務改善につながる研究開 発に加えて、これまで仕事にしてきたような「テクノロジーの創造的な応用」も課題の一 つとしてもらうことができました。ここで私は、「言葉」における原体験の一つである 「短歌」について少し考えてみようと、「短歌を生成するAI」 を試作してみることになる のです。それは、ちょうどメディアアートをやっていた頃と変わらない取り組みでした。 「AI」という新しいテクノロジーを用いて、「言葉」を「短歌」という枠組みの中で考え ていく、そしてそれらと「人」との関係を模索していく、そんな実践の始まりです。

59

第1章

<短歌 AI> とは何か

まずは短歌を自分で学んだ

このような経緯で「短歌を生成するAIをつくってみようか」と思ったものの、それま で短歌をつくった経験は自分自身、ありませんでした。 短歌に触れたことのない人間が、 それを生成するAIをつくるというのは、その過程や結果を自身で評価したりする際に見 通しが立てづらい上に、取り扱うべき課題といったものも、実際の短歌の作歌とは離れた 想像上だけのものになってしまいます。「文化に対するリスペクト」と言ってしまったら 少し簡単に聞こえてしまうかもしれませんが、短歌をAIによって生成するということに ついての、文化や歴史といった文脈も加味した肌感覚が必要であると考えました。

そこで私はまず「短歌をつくるとはいったいどういうことか」について考えられるよう にするため、短歌の入門書をとにかく買い集める、ということから始めます。

実際に読んだ本を列挙してみます。 永田和宏『新版 作歌のヒント』、木下龍也『天才に よる凡人のための短歌教室」、佐佐木幸綱監修 『知識ゼロからの短歌入門』、東直子 『短歌 の不思議』 岡井隆 「今はじめる人のための短歌入門』など。 これらを読んでいくうちに、 短歌のつくり方、基本的なルールはもちろんのこと、より具体的な表現の方法に至るまで を知識として獲得していきます。

短歌の入門本には、「現代の歌人がどういった歌を詠んでいるのか」が多く紹介されて

います。 そこで、「いいな」と思った歌人の歌集を、少しでも気になるものがあれば買い 集めていき、少しでも気になる歌があれば付箋を貼って、それらを読み返す、といったこ とを続けていきます。そうやってたくさんの実作者の考えや歌に触れるうちに、「これは 自分でもつくれるんじゃないか」と、AIをつくるだけでなく、自分も作歌を始めること になります。

つまり、AIをつくりながら自分自身も短歌を学ぶ、ということを始めたのがこの頃で した。毎日一首は短歌をつくるように決めて、毎朝仕事を始める前や、週末には近所の喫 茶店に長居をしながら、スマートフォンのメモ帳に自分でつくった短歌を溜めていきます。 そんなふうにしていくと、今度は自分のつくった歌をほかの人、できれば短歌について 「わかっている」人に見てもらいたくなるものです。 そこで、まずは新聞歌壇へ投稿する と(自社の歌壇への投稿は控えるように、ということもあり、当時の上長の了解をとって他紙の歌壇、東京 新聞の「東京歌壇」 東直子欄に主に送っていました)、いくつかつくったものが紙面に掲載される ようになりました。またそこからいわゆる短歌誌主催の新人賞へ応募を始めると、選考を 通って雑誌に載ったり、箸にも棒にもかからなかったり、という経験を重ねていきます。 短歌をつくる楽しさ、またそれに反応が得られるうれしさ、そして時には思うようにつく れないもどかしさを日々感じていくようになりました。

61

第1章 <短歌 AI> とは何か

歌人と文化部 「朝日歌壇」の協力

そしてある程度、短歌という文化に触れることができた、と思うのと並行して、短歌 を生成するAIも徐々に形ができていきます。

なおあき

最初につくったモデルはとてもシンプルで、五・七・五の上の句を与えると七・七の下 のらしきものを生成するというものでした。入力に従って短歌が自動で生成されていく 様子に、人手でつくるのとは違う感触があるのはもちろんのこと、独特の楽しさやおかし さがありました。このモデルをM研のチーム内で共有するとともに、東北大学の乾 健太郎 教授や東京工業大学の岡崎直観教授といった社外の研究者の方々の協力を得ながら論文に する、つまり言語生成研究の文脈に連なる一つの取り組みとしてこれを置き、また仕組み を他の人にも説明できる形にすることに着手していって、次に説明する最初の〈短歌AI> がだんだんとできていきます。

そして、ちょうど同じ頃に、初代選者に石川啄木を持ち、100年以上続く新聞歌壇で ある「朝日歌壇」を担当する文化部が、 テクノロジーを使った企画を考えたいとのことで、 まだデモンストレーションの段階であった〈短歌AI>を紹介します。 そこから、紙面で の展開やイベント企画を考えよう、と話は進んでいき、短歌AIを取り巻く世界は少しず

535

62

短歌AIができること

つ大きくなっていきます。 これらについては、後の章でより詳しくお話ししましょう。

短歌AIをつくりはじめた当初に私が考えていたのは、「短歌を自動で生成するなんて、 歌人や短歌を愛する人には嫌がられたり、怒られたりするのではないか」ということでし た。しかし、これはどうも杞憂だったようです。歌壇の担当者をはじめとした社内の人々、 実際に短歌をつくる歌人の方々、そしてそれに興味を持っていただいた読者の皆さんなど、 短歌に関わるさまざまな立場の人とのつながりの中で、それまで朧げだった〈AIが短歌 をつくることの意味や意義といったことが見えてきて、〈人間が短歌をつくる〉という行 為についてまでも、改めて捉え直していく試みとなっていくのです。

短歌について知り、それを鑑賞して、つくりながら考えていたのは、「いい短歌をつくる ことは簡単ではない」という当たり前のことでした。一方で、その表現の自由さも感じて いきます。

短歌の創作というのは、当然ながら「こうすれば必ずいい歌ができる」という一つの決 まったルールが存在して、誰もがそこへ向けて技を競うような行為ではありません。むし ろ、制約は持ちながらも、そのなかでいかに自由で新しいことができるか、という行為で

63

第1章 <短歌AI> とは何か

あり、短歌の歴史はその積み重ねであるようにも感じます。

そしてその短歌の積もる層に、「AIによって生成されたもの」が薄くでも存在している というのも、また一つの形なのではないかと思い至ります。

そんなふうにしてできた〈短歌AI〉は、「与えられた入力をもとに、それに続く短歌 を生成する」というモデルです。 これは、今まで紹介してきた言語モデルと同じ仕組みで、 続く言葉を「短歌の形」で生成するというものです。

入力揺れている

生成 構造物があるとする場合に限り地震の揺れは

入力揺れている光の中で

生成見る夢は過去の出来事あるいは想起

入力揺れている光の中で車たち

生成 人間が歩くようにも見える

歌人から学ぶ短歌AI

これが、実際の生成です。 いかがでしょうか、「揺れている」といった入力に対して、確

みそひとも

かに五・七・五・七・七音、三十一文字の「短歌らしきもの」が生成できているように見 えます。

入力が異なれば、生成される内容もそれに合わせて変化しているのが見て取れるでしょ う。「揺れている」では「構造物があるとする場合に限り地震の揺れは」と、地震に関す 説明的な内容を生成しています。 続いての例では、「揺れている光の中で」と、少し詩的 にも感じられる内容を入れています(何をもって「詩的」かはさておき)。すると、「夢」「過去」 「想起」といった、詩的とも言えそうな語を引き連れて「短歌らしきもの」が生成されま した。さらに最後の例に至っては、「車たち」が「人間が歩くようにも見える」と比喩的な 表現にまで展開しています。

このように、入力された内容の表す文脈に従って三十一文字の生成を行うのが〈短歌A I〉です。このモデルが、どのようにして「短歌の形」、三十一文字の短歌をつくるか、 については第2章で詳しく説明します。

いま見た〈短歌AI〉の生成は、「構造物があるとする場合に限り地震の揺れは」だと

65

第1章 <短歌 AI> とは何か

99

か、「あるいは想起」だとか、どうも無機質というか、硬い表現のものが多いでしょう。 しかし、その後、歌人の俵万智さんや永田和宏さんの協力を得て、お二人の短歌を学習デ ータにした短歌AIをつくってみると、大きな変化が生まれます。歌人の方々の協力に関 する経緯や詳細は後の章に譲るとして、ここではそれぞれの歌人のデータを学習したAI の生成例を見てみましょう。

入力 「寒いね」と話しかければ「寒いね」と

(「寒いね」と話しかければ「寒いね」と答える人のいるあたたかさ/俵万智 第一歌集 『サラダ記念日』) 生成 言われたような言の葉がある

(俵さんのデータを学習した短歌AIの生成)

入力 足元をゆっくりと陽は廻りゆく

(足元をゆっくりと陽は廻りゆく冬の陽射しのはかなきゆうべ/永田和宏 第五歌集 『華氏』)

生成闇の底にさびしき花が

(永田さんのデータを学習した短歌AIの生成)

67

40

いかがでしょうか。どちらも、先ほどの味気ない生成とは違って、どこか「らしさ」を 摑んでいるように感じられませんか。 この学習データの変化による生成内容への影響につ いては第3章で紹介し、そこから見えてくる、私たちが「読む」ことと「詠む」ことにつ いても考えてみます。

言葉のつなぎ方は一つではない

これまでお見せした例では、一つの入力に対して一つの生成がありました。しかし、短 歌AIの生成は入力に対して必ず一つに決まるものではなく、言葉のつなぎ方を変えるこ とが可能です。どういうことかというと、ある一つの入力に対して、異なる生成を得るこ とができるのです。 実際の例を見てみます。

入力「この味がいいね」と君が言ったから

(「この味がいいね」と君が言ったから七月六日はサラダ記念日/俵万智 第一歌集 『サラダ記念日』) 生成1 この店はまず成り立っている

生成2 俺もそれを言う理由がある

第

第1章 <短歌 AI> とは何か

お題を詠む短歌AI

生成は、どうも当たり前すぎると言いますか、入力として与えられた「『この味がいい ね』と君が言ったから」 が表現する文脈に沿いすぎています。 一方で生成2 では、「俺も それを言う理由がある」と、入力で与えられた文脈から若干の「飛躍」 が感じられます。 これは、言語モデルから創作を考える際の重要な点として、なぜこのようなことができる のか、そしてここから私たちの作歌についてどんなことが言えるのか、第4章で取り上げ ます。

ところで短歌AIは、その生成の「速さ」も大きな特徴の一つです。 例えばここまでで 紹介したモデルは、約1秒の間に100首を生成することができます。このように人間と 大きく違った作歌をする短歌AIですが、 「速さ」だけではない私たちとの違いがきっと ほかにもあるでしょう。人との「違い」を見ながら、私たちがこの短歌AIを使ってどん なことができるか、どのような付き合い方が可能か、といったことについて、第5章で扱 います。

前項で見た短歌AIは、「与えられた入力(短歌の断片)をもとに、それに続く内容を生 成する」というものでした。しかし、それとは少し違った形で短歌を生成するAIもつく

っています。その一つに「与えられたお題で短歌を生成するAI」があります。これは、

「キーワード」と「テーマ」を入力として与えて、その内容をふまえた短歌を生成するとい モデルです。

まずは、実際の入力と生成を見てみます。

キーワード ダンス

テーマ 心地好い、楽しい、仲良し、すこやか、瞬間

書き出し いつまでも

生成 いつまでも穏やかでいてくれるので一緒にダンスするときもそう

ここでは、「ダンス」という語を、その生成内容に必ず含む 「キーワード」として設定し ています。そして、「テーマ」として、生成に含めたい語と関連する語の集合を定義してい ます。すると、このテーマの語群に近い言葉が、生成される内容に含まれるようになるの です。上の例では「心地好い、楽しい、仲良し、すこやか、瞬間」といった語を与えてい ます。最後に、「書き出し」として「いつまでも」を指定しています。

69 第1章 <短歌 AI> とは何か

結果、得られた短歌は「いつまでも穏やかでいてくれるので一緒にダンスするときもそ う」と、確かに「いつまでも」で始まり、 「ダンス」という語を含み、テーマに指定した 語と似た雰囲気を持つ言葉「穏やか、一緒に」を持った内容になっています。

このモデルは、2022年の夏に俵万智さんを迎えて開催したイベント「俵万智×AI 恋の歌会」で用いたモデルです。 イベントでは「恋」にまつわる短歌を生成するというお 題があったのですが、ここで生成したのが次の歌です。

あたらしい恋の思いによるとこの恋にはスマホが存在しない

ここでは、キーワードに「スマホ」を設定し、テーマに恋愛にまつわる語 「恋愛、青春、 嫉妬、片思い、憧れ」を入力しています。いまの日常生活において、スマートフォンは人 とコミュニケーションを取るのに欠かせないものになっています。当然、恋人といった大 事な人とのやり取りにも利用されることが多いでしょう。そんな現代的なツールを題材に

恋愛の歌の生成を期待したのですが、ここでは「スマホ」をあえて「存在しない」と することで、普遍的な人とのつながりを感じさせる内容が得られました。実際に、お題に 即した歌が生成されているのがおわかりいただけるでしょう。

70

与えられたお題に沿って短歌を詠むことを「題詠」と言います。ここで紹介した短歌 A Iは、この題詠を自動で行う言語モデルと言えるでしょう。 「題詠」への取り組み方には 人によってさまざまな形があるかと思いますが、ここでは簡単に、キーワードとテーマを 指定することでの短歌生成を試みています。結果、先ほどの入力された続きをつくるAI とは違った形での、短歌の生成を見ることができました。

質問に答えると短歌ができる

さらに、このモデルは広告キャンペーンでも応用されました。2022年の秋に私たち は、Dentsu Craft Tokyo (現Think & Craft)、 Dentsu Lab Tokyo と協力して、普段言えない気持 ちを花と歌(短歌)に込めて届けるウェブサービス 「花と歌」を期間限定で公開しました。 「利用者が贈りたいと思う相手に対して、花のイラストと短歌を合わせた画像を共有でき る」というサービスで、短歌の創作を支援するためのAIとして、先ほどのお題を詠む短 歌AIが利用されています(図1-1)。

利用者は贈りたい相手に関する質問に答える、2質問への回答内容に沿った短歌一首 が生成される、③生成された歌を自由に編集する、という手順を通して短歌をつくること ができます(図1-2)。これまでに一度も短歌をつくったことのない人でも、気軽に作歌

71

第1章 <短歌 AI> とは何か

花

Hana & Uta

花

Hana & Ulta

歌

まごころの

ラーメンに似て

いるのかも

しれないという

謙虚な気持ち

しあわせの

フィルムカメラが

撮れるまで

また

撮影させて

Ruby's-breath

Cosmos

図1-1 花と短歌を届けるウェブサービス「花と歌」

を楽しむためのツールとして公開され ました。

例を見てみます。 利用者に対して以 下の質問が提示され、これに答えてい きます (1)。

思い出に残っていることは?

Q2 思い浮かぶものは?

Q3 贈りたい花は?

Q1は、場所や風景、食べたものな どのカテゴリから一つを選択します。 ここで選んだ内容によって、「テーマ」 の語彙が変化します。 例えば「場所」

を選ぶと、「向かう」といった語がテ

ーマとして与えられます。

72

22

ユーザーによる質問回答

Q1 思い出に残っていることは? 【場所/風景/食べたもの】 などから1つ選択

テーマ 生成短歌と関連する5つの語【向かう、花光 思い、のんびり

Q2 思い浮かぶものは? 自由入力

キーワード生成短歌に必ず含めたい語 ドライブ

Q3 贈りたい花は? 10の花から1つ選択

モデル

第1句 生成短歌の書き出し

2. モデル生成

アイラブユー

アイラブユー ドライブしてた時のあのような気持ちで心ゆくまで

3. ユーザーによる編集

↓

アイラブユードライブしてた時のあのような気持ちで隣に座る 図1-2 短歌AIが作歌をサポートする仕組み

で、例えば「アイラブユードライブして さらにこれを利用者が編集すること

を入力しています。 のような気持ちで心ゆくまで アイラブユードライブしてた時のあ そして生成されたのが次の歌です(2)。 「ブユー」が書き出しに設定されました。 されます。ここではバラを選び、 「アイラ んだフレーズが、短歌の書き出しに反映 びます。ここで選んだ花の花言葉にちな 最後に、Q3 として贈りたい花を選 ます。例では、「ドライブ」という言葉 かぶものとして、自由な入力を受け付け Q2は、相手との思い出から思い浮

<短歌 AI> とは何か

第1章

73

連歌に参加するAI

た時のあのような気持ちで隣に座る」といった歌をつくることができます (⑥)

実際にウェブサイトやワークショップを通じて多くの方に利用され、まだ短歌に触れた ことのない人へ作歌の機会を提供するAIサポートツールとして、お題を詠む短歌AIが 応用されています。

2023年の10月には、「朝日歌壇」の選者でもある永田和宏さんとのイベントを開催し ました。永田さんは、歌人として活躍される一方で、 細胞生物学者としても多くの功績が ある方です。事前の取材で〈短歌AI> をお見せすると、強い関心を寄せていただくとと もに、また違った応用の形を提案してくださいました。 それが、「連歌」をするAIです。

連歌とは、参加者の間で五・七・五の長句と七・七の短句を交互につけていく「座の文 「芸」とも呼ばれる歌の形式です。 各参加者は、一つ前の人の句をもとに自らの句をつくり ます。この時、直前の内容とのつながりを感じさせつつも、新たな展開・変化を生む句を つけることが重要とされます。一人でつくる短歌とは違う、人と人との相互のやり取りの なかで言葉を発していく連歌ですが、ここに人ではないAIが加わると、いったい何が起 こるでしょうか。

10

イベントに向けて私たちが用意したのは、一つ前の句の内容を手がかりにしつつも、新

たなイメージを喚起させる次の句をつくるという指示を与えたAIです。イベントでは、 参加者の方も交えながら、リアルタイムに句の生成に取り組みました。

実際の生成を見てみます。

発句(永田和宏さん)

2句(参加者)

3句(連歌AI

魚河岸の匂いもなくて秋の風

手にはぶらりと三越の秋刀魚

炙り出す焼ける香りと遠き日々

なぜこの句をつくったか

秋刀魚の描写から、その焼ける香りを通じて過去の記憶や情景を思い起こす、という意

味合いを込めています。遠き日々という表現は、時間の流れや過ぎ去った季節を象徴して います。

75

第1章

<短歌 AI> とは何か

3連歌AI

連歌AIをつくる際にはいくつものアプローチを試したのですが、ここに挙げたものは ChatGPTに短歌の実例と連歌について教える指示文を与えることで、新たな句を生 成させています。 また、指示文には「なぜこの句をつくったか」という理由についても生 成させるようにしています。

ここでは確かに「秋刀魚」から「焼ける香り」を導きつつ、そこからさらに「遠き日々」 にまで思いを馳せるような内容が生成されています。また、この句を生成した理由につい ても、矛盾なく説明ができているように見えます。

一方で、前の句から新しいイメージを想起させる 「飛躍」については、その生成の難し さも見られました。以下に示すのは、いずれも連歌AIによる「手にはぶらりと三越の秋 刀魚」に続く3句目(五・七・五)と、「なぜこの句をつくったか」の生成です。

微生物の秋刀魚を宿し生命の舞

なぜこの句をつくったか

秋刀魚の描写から一転、その秋刀魚が微生物の宿主となり、生命の舞を描くという、現 実とはかけ離れた想像力を働かせた表現を試みました。ここでは、秋刀魚の存在が微生物

76

3句(連歌AI

の生命を支え、それが一種の舞となるという幻想的なイメージを描いています。これは、 人間の感覚や経験を超えた、ある種の神秘性や生命の連続性を表現する試みでもあります。

遥か彼方星々の舞に心躍る

なぜこの句をつくったか

前の連歌から一転、遥か彼方の星々の舞いに心が躍るという、現実とはかけ離れた想像 力を働かせた表現を試みました。 ここでは、星々の舞いが人間の心を動かし、それが一種 の感動や興奮を引き起こすという幻想的なイメージを描いています。 これは、人間の感覚 や経験を超えた、ある種の神秘性や宇宙の壮大さを表現する試みでもあります。

これらの例は、前の句から離れることばかりを意識したせいか、どちらも飛躍が過ぎて しまって、逆につまらないものになっています。 最初に挙げたものは、「秋刀魚」をそのま ま引きながら、「微生物」 や 「生命の舞」といった全く異なるスケールの内容を展開してい ます。後に示したものでは、舞台は宇宙まで「飛んでしまっていて、もはや前の句との 関連が全くといっていいほど感じられません。

77

第1章

<短歌 AI> とは何か

短歌に出会うためのAI

イベントは、AIの生成を見ながら永田さんに直接コメントをもらい、参加者も含めて 連歌について深く知ることのできる会となりました。前の句を受けながらさまざまな「続 きの展開」を見せるAIが、これまでにない連歌の体験、「座の文芸」を提供しています。

短歌は、つくるだけのものではありません。それを耳や目にして、感じる人間がいるか らこそ、一千年以上も続く文化として今日にも存在しているのでしょう。自分ではない誰 かのつくった歌に出会ったり、自分が過去につくった歌に再会したりする。 そしてそこか ら、新しい発想を得たり、忘れていた感覚を取り戻したりして、それがまた新たな歌やそ の鑑賞につながる、そんな短歌の循環があるように思います。

つまり、「つくる」ということだけに焦点を当てると、見落としてしまう短歌の側面が きっとあります。 ここで、これまで見てきた「短歌を生成するAI」とは違う、「短歌に 出会うためのAI」をご紹介しましょう。

私たちは、2022年の夏に「朝日歌壇ライブラリ」というウェブサイト (https://www. asahi.com/special/asahikadan-library/) を公開しました(図1-3)。このサイトでは、朝日新聞の短 歌投稿欄 「朝日歌壇」 の入選歌を検索することができます。

朝日新聞 DIGITAL

地で詠まれた短歌が、積み重なった地層のようなものだと言えるでしょう。それを発掘す 生活を送った人たちが詠み、投稿された歌を掲載してきました。これは、各年代、全国各 検索できる〉というものです。 れた言葉と似た意味を持つ短歌を ベクトル」を応用して、〈入力さ ます。これは序章で説明した 「文 〈AI検索〉という機能を備えてい 年代別のフィルタリングに加えて、 万首で、単語・作者による検索、 22年6月までに掲載された約5 短歌は、1995年5月から20 現在システムに収録されている 歌壇ライブラリ」です。 るための道具となるのが、「朝日 使い方|このサイトについて 今の気持ちを単語や文章で検索 AIRR we 全年代 楽しい おすすめワード 今日もいい日になりますように

PREMIUMA

+

短歌でさがす いまの気持ち、 XALWER

朝日歌壇から1995年以降の入選歌を集めた「朝日歌壇ライブラリ」を作りました。 単語や作者名からお目当ての短歌を探したり、AI検索エンジンで今の気持ちに寄り う短歌に出会ったり。歌づくりの参考になる一言や、あなたの支えになる一首を てみませんか。

図1-3 短歌と出会える 「朝日歌壇ライブラリ」

<短歌 AI> とは何か

朝日歌壇は、前述のように100年以上にわたって続く新聞歌壇で、それぞれの時代に

第1章

例えば「夏が終わった」という

X

a

79

言葉を入力してみると、

この夏はビーチサンダル履かぬままこうして若さを置き忘れてゆく

上田結香 松田わこ

友達と会えない二度目の夏が過ぎ少しカサカサしている私 「かき氷売り切れ」の紙捨てるとき高校最後の夏が香った

赤松みなみ

このような歌が表示されました。 「夏が終わった」という表現の周囲に存在している歌 を並べてみることができるのです。

短歌は、例えば「悲しい」 という感情をそのまま「悲しい」という言葉を使って直接的 に表すことの少ない表現形態です。 AIが計算する文の類似度による検索は、入力された 内容を直接には含まないが、それとなんとなく似ているものを探すことができるので、 「短歌の表現に適した検索」と言えるでしょう。

この「AI検索」によって、あなたの心にふと浮かんだイメージや感情、もしくは単語 だけでは表すことのできない複雑な心のざわめきだったりに、寄り添う歌を見つけること ができるかもしれません。

ここまで、〈短歌AI〉についてその全体像を紹介しました。AIが短歌を学ぶとは、

短歌をつくるとは、そして人はどのようにこの生成装置と向き合うのか、といったことに

ついて、次の章から、より具体的に考えていきましょう。

この章から学ぶ「短歌入門」

●SNSや書籍など、どこからでもよいので自分にとっていいなと思える短歌を探す (す でに何かある人は、次に進む)。

●見つけた短歌を、大事にとっておく。

●この本を読み終えてからもう一度その短歌を読み直して、感じ方の違いを観察する。

81

第1章

<短歌 AI> とは何か



第2章 型を身につける

「短歌を生成する」とはどういうことか

ここで一度、立ち止まって考えてみたいことがあります。それは「短歌を生成する」と はどういうことか、ということです。 いったい言語モデルがどんな「言葉」を生成できた ら、「短歌を生成できた」と言えるのでしょうか。

「短歌」という語を辞書で引いてみると、こんなふうに書いてあります。 「和歌の形式の 一つで、五・七・五・七・七の五句から成る歌」(新明解国語辞典 第八版)。

きた

ころもほ

確かに、序章冒頭でも挙げた「春過ぎて 夏来るらし白たへの衣干したり天の香具山」 は、「春過ぎて(5音)」「夏来るらし (7)」「白たへの (5)」「衣干したり (7)」「天の香具 (7)」と、五・七・五・七・七の五句〉から構成されています。

ほかにも、私の好きな短歌を挙げてみます。

かぐ

他界より眺めてあらばしづかなる的となるべきゆふぐれの水 マッチ擦るつかのま海に霧ふかし身捨つるほどの祖国はありや たっぷりと真水を抱きてしづもれる昏き器を近江と言へり

ライターをくるりと回す青いからそこでなにかが起こったような

葛原妙子

寺山修司 河野裕子

永井祐

க

F

雨すぎて黒く濡れたる電柱は魚族のひかり帯びて立ちおり 独白もきっと会話になるだろう世界の声をすべて拾えば

これらはいずれも〈五・七・五・七・七の五句から成る歌〉 です。 辞書が説明する通り、 多くの短歌は五・七・五・七・七で構成されています。短歌のリズムは、長歌 (五・七音の 繰り返しからなり、最後に七・七音で終える歌の形式)に添えられる五・七・五・七・七の「反歌」 にも見ることができます。

小島なお 木下龍也

しぬ

まな

瓜食めば子ども思ほゆ 栗食めば まして偲はゆいづくより来りしものぞ

か

やすい

な

交にもとなかかりて 安眠し寝さぬ (長歌)

しろかね

くがね

銀も金も玉も 何せむにまされる宝 子にしかめやも(反歌)

この五・七・五・七・七音の「型」が、一千年以上の時間を経て今日まで保たれている ことになります。そこで表現されている内容に目を向けてみると、日常生活で感じられる

(山上憶良「子等を思ふ歌」)

85

第2章 型を身につける

刺激から非日常的な状況を表すものまで、実にさまざまです。短歌は、五・七・五・七・ 七の「器」の中で言葉を展開する表現であり、そこにはありとあらゆるものが込められて きたと言えるでしょう。

そこで、短歌を生成することをまずは「五・七・五・七・七の定型をなるべく満たす文 字列を生成する」こととしてみます。当たり前と言えば当たり前の定義に見えますが、こ のようにすることで、それが文語であろうと口語であろうと、日常の一瞬を切り取ってい ようが、超常的な現象を表していようが、どんな表現でも許容する大きな器としての「短 歌そのもの」をいちばんよく表しているのでは、と考えます。 一千年以上にわたって歌わ れ続けてきた「型」を身につけたAIとして、ひとまずこのように定義してみるのは、そ 悪くないでしょう。

ところで、すべての短歌が厳密に五・七・五・七・七の型に則っているというわけでは ありません。先ほど「なるべく満たす」と定義したのも、これによります。 実際、現代の 日本でもっともよく知られる短歌の一つである次の歌は、五・七・五八七音から構成 されています。

「この味がいいね」と君が言ったから七月六日はサラダ記念日

俵万智

ほかにも、定型に収まらない歌を挙げてみます。

晩夏光おとろへし夕酢は立てり一本の堰の中にて

かなしみよりもっとも無縁のところにてりんごの芯が蜜を貯めいる

ここで、五・七・五・七・七の型よりも、音が少ないものを「字足らず」、多いものを 「字余り」と言います。さらに、句の意味的な切れ目が五・七・五・七・七の句の切れ目 に揃っていないものを「句またがり」 「句割れ」と呼びます。

杉崎恒夫

東直子

廃村を告げる活字に桃の皮ふれればにじみゆくばかり来て 塾とドラッグストアと家族葬館が同じにおいの光を放つ ほんとうに夜だ 何度も振り返りながら走っている女の子

岡野大嗣

平岡直子

さらに、五・七・五・七・七の定型を大きく壊すことを 「破調」といいます。

葛原妙子

87 第2章 型を身につける

上空より東京を見れば既にあやしき人工の物質塊 “Masse” と謂はむか 斎藤茂吉

さらには、記号を用いた次のような歌までもが存在します。

×××は麒麟XXX$$$だ××× 記述できない午前十時を

定型を満たす短歌の生成

このように、短歌は必ず定型に収めなくてはならない詩型ではありません。特に最近の 現代短歌では、きっちりと定型に収まる歌はむしろ少ないようにすら感じます。しかしそ れは、やみくもに音を削ったり足したりしてもよい、ということではありません。まず定 型の五・七・五・七・七があり、その上で効果を生む字余りや字足らず、 句またがりに句 割れ、そして破調があると、意識しておきたいものです。

以上、「短歌を生成する」とは「五・七・五・七・七の定型をなるべく満たす文字列を 生成する」ことであるとして、実際に言語モデルをつくっていきます。

では、「短歌が生成できている」の定義、五・七・五・七・七の短歌の定型をなるべく

荻原裕幸

満たす言葉の生成を達成するには、いったいどのようにすればよいでしょうか。 そのため には、日本語が持っている、そして短歌の定型に関わる「音」の概念をモデルが理解でき る形で表現できるとよさそうです。 そこで「モーラ」という便利な単位を導入して、日本 語の音を数えていきます。

モーラは、私たち日本語話者にとって自然に感じられる音の数え方です。 先ほど「便利 な単位」と表現したのも、その自然さによります。日本語におけるモーラは基本的に仮名 文字の数と同じで、「きゃ・きゅ・きょ」のような拗音を除けば、両者が1対1で対応し ます。

例えば「さくらんぼ」は「さ・く・ら・ん・ぼ」と5モーラに数えられ、各モーラが均 一な時間の長さを持っています。 確かに、「さくらんぼ」はそれぞれの文字を同一の長さ で発音することで、それが小さくて丸くて赤い果実であることが他の人にも無理なく伝わ ります。長音・拗音・促音・撥音も1モーラとして数えるため、「チョコレート」は「チ ョ・コ・レ・ー・ト」で5モーラですし、「切手」は「き・って」で3モーラ、「短歌」 は「た・ん・か」で3モーラです。

いかがでしょう。私たちが普段意識せずとも使っている日本語の音を、自然な形で数え ている単位に感じられませんか。

89

第2章 型を身につける

モーラを言語モデルの内部でも計算できるような工夫を加えたのが、2020年につく った〈短歌AI〉です。このモデルでは、内部で扱う言葉の情報に追加して、モーラの情 報も計算できるような仕組みをつくっています。 このようにすることで、言語モデルが短 歌を生成していく際に、モーラも気にしながらの言葉の選択が行われることを期待しま す。毎回の生成で確実に五・七・五・七・七の定型に収まる文字列が生成される、という わけではないのですが、 モーラを計算する仕組みを持たないふつうの言語モデルに比べ、 定型の短歌が出やすくなっています。 短歌の「型」を少しだけ身につけたモデル、 と言え るでしょう。

モーラを計算した上で、どのようにして短歌の定型に従う言葉を生成するのかを説明し ましょう。言語モデルは現在生成している言葉が「合計で何モーラになっているか」を計 算して、「短歌の定型である31モーラまで、残り何モーラか」という情報を持ちながら言 葉を生成していきます(図2-1)。これはちょうど、短歌を始めたばかりの人が、音を指 折り数えながら歌をつくるのと、同じことをしているとも言えます。

実際に〈短歌AI〉が生成した例をいくつか見てみましょう。

さっきまで人間だった人形が喋ってみせる世界であった

90

例

内部で日本語の音 (モーラ)を学習

「生成系列

揺れている>構造物があるとする場合に限り > 地震の揺れは

31

26

残りのモーラ数

19

14

図2-1 「残りのモーラ数」 をもとに短歌を生成する

まぶしくて見ていてつらい夕焼けの空にまにまにオレンジの花 画面では表示されないバーコードセグメントを非表示にできる

なのに、実際はそうなっていないという例もあります。 また、モデルとしては正しく3音の文字列を生成しているつもり 感じられない、ただの説明文が生成されているようにも見えます。 ドセグメントを非表示にできる」という例では、短歌 「らしさ」の にも思えてくるでしょう。 例えば「画面では表示されないバーコー やっと短歌が生成できた」と感じられるのかと言えば、少し、疑問 がします。しかし、果たしてこれを短歌と呼んでいいのか、「ああ これらを見ると、確かに音の数は揃っていて、調子だけはいい気

光ってる森の中を移動して見えるのは今ここだというの

と言語モデルの中で分解され計6 モーラとして数えられてしまって これは、「光ってる(5モーラ)」が「光(ひかり・3)って(2) る (1)」

91 第2章 型を身につける

いることが原因の一つと考えられます。つまり、言語モデルにおける言葉の粒度で見るモ ーラ数「光(ひかり・3)」 と、それに続く語が結びついた時のモーラ数 「光(ひか・2)って (2)」 とが異なってしまっているのです。

また、定型から大きく外れた歌が生成される場合もあります。

さっきまで平和だったのに今度会ったら違う人になってるかも

まぶしくて見ていて気分がわるいやうれしくないやわかってるやでも 光ってる波か? 光ってる 波か? 光ってる 波か? 光って

日本語の音を理解しながらの生成に関しては、いまだ改善の余地が大いにあります。こ の学習の難しさは、言葉をテキストデータとして扱う言語モデルの奥にある「音」の複雑 とも言える世界の広がりを感じさせます。 字面だけでは追えない、AIでは容易に扱えな い日本語の音から、この音に対する感覚を長い間保ってきた私たち人間の潜在的な力も見 えてくるようです。

いま、私たちが日常で短歌に触れる機会は、本であったり、SNSであったり、おそら く文字=視覚情報としてそれを「読む」ことが、耳で「聴く」ことよりも、圧倒的に多い

22

のではないでしょうか。 しかし、そこでは明示されない、でも感じることのできる日本語 の「音」に対する感覚を体に取り入れること、またそれを意識して短歌をつくることの重 要性が、短歌を生成するAIを構築することで、改めて感じられます。

「モーラ」を合わせて穴埋めしてみる

定型を一度身につけると、いつの間にかするすると五・七・五・七・七の短歌が頭に浮 かんでくるようになっているかもしれません。目や耳・肌で感じるものやことから、身近 な人間関係、あるいはより大きな社会問題に至るまで、あらゆる対象に短歌の言葉が頭を よぎって、まるで新しい能力を手にしたかのようです。

しかし、パッと自然の流れに任せて思いつく内容というものは、それがどういった表現 形態であるにせよ、後で冷静になって見返してみるとあまりよくない、といったことがあ ります。そこで一度つくったものを見直し、編集したくなってくるものです。短歌をつく る場合、この過程でももちろん「定型」を意識した上での歌のつくり直し・調整が必要で す。

これまで、言葉を一つ一つつなげながら文字列を生成する言語モデル〉としての〈短歌 AI〉を見てきました。一方で、序章では文章の「穴埋め」 をする言語モデルがあるとい

93

93

第2章 型を身につける

話をしました。ここでは、その「穴埋め」 モデルにモーラの計算を掛け合わせることで、 定型に沿った短歌の編集をやってみようと思います。

例えば、次の短歌があったとします。

語と語たち並んだ様を学習し感覚と書く梅雨の青空

この歌の「感覚」という部分が、なんとなく気に入らないとしましょう。そこで、これ を他の語に置き換えてみます。 以下のように「感覚」を □として、これに置き換わる 候補を穴埋めモデルによって計算してみます。

語と語たち並んだ様を学習し ]と書く梅雨の青空

すると、モデルは以下のような候補を出しました。

直す ・たり ・あう て

.

十年 ・涙 ・ました ・生きている･･････

94

いかにも多様な語が生成されているように見えますが、これだけ見てもよくわかりませ

ん。これらの語で穴を埋めてみると、次のような文字列が完成します。

語と語たち並んだ様を学習し直すと書く梅雨の青空 語と語たち並んだ様を学習したりと書く梅雨の青空 語と語たち並んだ様を学習しあうと書く梅雨の青空 語と語たち並んだ様を学習してと書く梅雨の青空 語と語たち並んだ様を学習し十年と書く梅雨の青空 語と語たち並んだ様を学習し涙と書く梅雨の青空

語と語たち並んだ様を学習しました と書く梅雨の青空

語と語たち並んだ様を学習し生きていると書く梅雨の青空

いかがでしょうか。どれも確かに、意味の通る文字列になっています。しかし、短歌の 定型から崩れてしまっているものがほとんどです。もともとこの穴にはまっていた言葉は、 「感覚」でした。 これは、「か・ん・か・く」で4モーラの語ですね。 そこで、穴埋めモデル が計算した語の中から、「感覚」と同じく4モーラのものだけを残すようにしてみましょう。

95

第2章 型を身につける

すると、次のような歌が並びました。

語と語たち並んだ様を学習し忘れたと書く梅雨の青空 語と語たち並んだ様を学習し幸せと書く梅雨の青空 語と語たち並んだ様を学習ししみじみと書く梅雨の青空 語と語たち並んだ様を学習し 生活と書く梅雨の青空 語と語たち並んだ様を学習し 日本語と書く梅雨の青空 語と語たち並んだ様を学習し 思い出 と書く梅雨の青空 語と語たち並んだ様を学習し 千年と書く梅雨の青空 語と語たち並んだ様を学習し生き生きと書く梅雨の青空 語と語たち並んだ様を学習しゆっくりと書く梅雨の青空

確かに、いずれも短歌の定型に沿う文字列です。 短歌の表している文脈を考慮した上で の、定型を保ったままの語の置き換えができました。 それぞれの置き換え結果を見てみる と、動詞・名詞・副詞といった品詞も違えば、「忘れた」 「しみじみ」「生き生き」 とその 語が表す雰囲気までさまざまなものが並んでいるのがわかります。

96

言語モデルによって語の置き換えをするという行為は、例えば人間が類語辞典を参照し ながら他の言葉を探すのにも似ているかもしれません。穴埋めモデルを応用することで、 定型という制約の中での語彙選択を広げることができました。

一方で、そこにどんな語が収まれば「SS」と思えるのか、表現したかったものに近づ けるのか、はたまた表現しようとは思っていなかったが 「これだ」と感じる新たな語を獲 得できるのか、ということは、作歌のきっかけを実際に持つ短歌のつくり手だけが判断で きるものでしょう。まだ言葉になっていないなんらかの刺激から、短歌をつくる。その過 程で何を表現したかったのか、それを決めないということすらも) 決めて、言葉を選び取っ ていくのは、ほかでもない私たちであるという思いを強くします。

またそれは、型を身につけているとかいないとか、短歌の生成が上手いとか下手である とか、そういったこととは全く別の軸に存在している独立した能力、もしくは特権である ようにも思えてきます。 「言葉」を扱うAIがいくら高度に短歌を生成できるようになっ たとしても、私たちが作歌をする余地や理由は常に存在し続ける。そんなことも、当たり 前のことかもしれませんが、意識しておきたい点であると改めて感じます。

97

97

第2章 型を身につける

「型」を身につけたAIたち

ここで、短歌生成について、これまでになされた取り組みを振り返ってみたいと思いま す。

2008年に歌人の佐々木あらら氏によって開発された短歌自動生成スクリプト「星野 しずる」は、あらかじめ用意された語彙をランダムに組み合わせるアルゴリズムによって、 短歌を自動で生成します。 機械学習による生成ではありませんが、 イラストレーションに よって擬人化され、2009年に第7回枡野浩一短歌賞を受賞、2012年には電子歌集 を発表するなど、単なる生成プログラムを超えた「バーチャル歌人」として存在していま す。

2019年には、短歌研究社とNTTレゾナントが「恋するAI歌人」を期間限定で公 開しました。AIを与謝野晶子や岡本かの子といった近代女性歌人の短歌5000首以上 で学習し、はじめの五音を入れると続く短歌を生成する仕組みになっています。歌人の野 あや子氏がアドバイザーとして関わり、短歌誌「短歌研究」にて座談会も組まれるなど、 歌壇との関わりを持ちながら実施されたプロジェクトです。

西安交通大学の金中教授らが2021年に発表した和歌生成モデル「WakaVT」は、 8~15世紀の和歌1万首以上を学習し、指定されたキーワードに基づき和歌を生成するこ

98

とができます。生成時の言語の選択にモーラによる制約を設けるほか、五・七・五・七・ 七の各句や上の句・下の句といった和歌の持つ構造をモデルに意識させる仕組みを持ち、 質の高い生成を実現しています。

さらに、「型」を持つ言語表現は、短歌以外にも存在します。まず思い浮かぶのは、俳句 ではないでしょうか。 北海道大学の川村秀憲教授らによる俳句生成AIプロジェクト「A Ⅰ一茶くん」では、人間との勝負や句会への参加に積極的に取り組んでおり、 「俳句」を通 して人とAIの違いや関係性を考える実践を数多く行っています。 また、ラップの生成に ついても、これまでにさまざまな言語モデルが提案されてきました。ラップは、リズムに 合わせて韻を踏んだ表現を繰り出すという「型」を持っています。 最近では、兵庫県立大 学の三林亮太氏と大島裕明准教授らが、対話形式で相手のラップに対して韻を踏みながら 適切な掛け合いを提示する「ラップバトル」を生成するシステムを開発しています。 音楽の旋律に対して与えられる歌詞を考えるという行為も、「型」 といってもよいかもし れません。国立研究開発法人産業技術総合研究所の渡邉研斗氏は、楽曲の音楽的性質を考 慮し、単にメロディにはまるという制約を超えた、テーマやストーリーをも含む作詞支援 をはじめとした「歌詞情報処理」に取り組んでいます。

「型」を持つさまざまな言語表現を扱うAIを見ていくと、それぞれの表現にとって、ま

99

第2章 型を身につける

た人間にとって「型」とは何かを改めて考える機会を提供しているようにも感じます。扱

う言語表現は違えど、いずれもAIを通して人間そのものにも迫る試みであるということ ができるのではないでしょうか。

AIに「何を任せるか」という視点

この章では、短歌の定型を身につけたAIについて見てきました。 確かに、 「短歌を生 成できている」と言えそうな、31音の制約の中での言語モデルの挙動を見ることができま した。こうしたAIの振る舞いに対して、私たちは「面白い」とも思えば、あるいは「怖 い」といった感情を覚える方もおられるかもしれません。ここで一度、「私たち人間はAI に何を任せられるか」ということについて考えてみたいと思います。

短歌の作歌に慣れていない人にとって、短歌の定型に沿った言葉を次々と考えていくの は、まだ難しい問題であると言えます。私自身も、短歌を始めたばかりの頃や、またしば らく歌をつくることから離れていたときには、つくろうと思っているモノやコトを短歌の リズムにするので精一杯、という経験をしています。

一方で、AIは命令さえ受け取ってしまえば、短時間にいくらでも大量の短歌を難なく 生成できると、第1章でも触れました。 これは、人間には到底真似できない芸当です。も

100

っとも、人には短時間に大量の「言葉」を生成するような機能はなく、文字を打つか、書 くか、音声を発するかしかないので、当たり前といえば当たり前です。

しかし、人は短歌を詠みたい「きっかけ」や「気持ち」、またひょっとすると「予感」 のようなものまでが自然と湧き上がってくる、あるいは能動的に摑むことができる生き物 です。これは、短歌を簡単に生成できるAIを前にしたとき、際立ってくる性質のように 感じられます。

AIにも、例えばインターネット上に存在する天気予報サービスとつなげておいて、天 気が晴れから雨に変わったら「雨」にまつわる歌を生成させる、といったアルゴリズムを 適用させれば「何もないところからの詠み」を発生させることはできなくもないでしょう。 しかし、現状AIには、自発的な詠みを引き起こさせるような仕組みについて、人間のそ れをうまくモデル化した機構があるわけではありません。つまり、AIによる生成では、 歌をつくりたい、誰かに伝えたい、といった動機の部分が存在していません。 言語モデルが定型を学習するのを横目に見ながら、私たちは五・七・五・七・七のリズ ムを身につける。モデルが1秒間に100首生成するのを尻目に、私たちは一首をつくり あげるのに頭を悩ませる。私たちだけが持っているであろう「短歌をつくりたいと思う感 覚」に改めて思いを巡らすと、それをAIと共有することの意味や意義について考えたく

101

第2章 型を身につける

すがすがしい眺められるが観覧車は

なんとなく見ているだけなので

すがすがしいホテルから見る観覧車 なんとなく見ているだけなのに

希望へと散歩に行って思い出に 残る時期を迎えることの

希望へと散歩に行って思い出に これから先も迎えることの

誠実さ負けず嫌いの散歩等 楽しむという時もあります 誠実さ負けず嫌いの散歩道 楽しむという時もあります。

図2-2 ユーザーによって生成短歌へ与えられた編集例

なります。

前章で紹介した「花と歌」では、短歌をつ くったことのない人に向けて作歌の機会を提 供する道具として、言語モデルが機能してい ました。図2-2は、実際に「花と歌」に触 れた人が、生成された短歌へどのような編集 を与えたのかを示します。 確かに、AIが生 成した歌に対して、人が編集を加えるという 形での作歌が展開されていたことがわかりま す。

さて、具体的にはどのような編集が行われ ていたでしょうか。

「眺められるが」が「ホテルから見る」と具 体的な場所に置き換わっているのは、この歌 を贈る相手との思い出が込められているのか もしれません。「残る時期を」から「これか

102

ら先も」では、どことなく終わりを感じさせる 「残る･･････」という表現から、未来に目を 向けたポジティブな表現への変換が試みられています。 「散歩等」の「等」は、曖昧かつ表 記が固いと感じられたのでしょうか、「道」 と置き換えられています。こうした編集が行わ れたという事実は、生成された歌では満足できない、しっくりこない、もっと違う形があ ると感じる、私たち人間の気持ちの表れと言えるでしょう。

このようにして、あなただけが持っている〈まだ言葉になっていないもの〉をひとまず 〈型〉にはめてみるために、言語モデルを利用することができるかもしれません。つまり、 AIが得意な「計算」と私たち人間が持つ「気持ち」を相乗させながらの作歌があり得る のではないでしょうか。短歌にまつわるAIとの付き合い方については、最後の章で詳し く取り上げますが、それまでの内容を読んでいく際にも、頭の片隅に入れておいていただ ければと思います。

この章から学ぶ「短歌入門」

●指折り数えて五・七・五・七・七の定型に沿う短歌をつくってみる。

●これから目にする短歌をすべて声に出して読んでみる。

●日常生活の言葉や独り言までもが五・七・五・七・七になるまで続ける。

あいまい

103

113

第2章 型を身につける



第3章 「詠む」前に「読む」

短歌AIの学習データ

前章で見た短歌生成は、確かに短歌の「定型」には沿っていました。 しかし、そこで表 されている内容は、無機質な、説明文のようなものでした。 この、ある種「うまくない」 生成の結果に「まだAIはこんなものか」と安心する方もいれば、「いやこれではいくらな んでも物足りない」と感じる方もいるでしょう。しかしこれには、明確な理由があります。 それは、学習データが「擬似的な短歌」であったということです。

序章で説明したように、言語モデルの学習には「コーパス」と呼ばれる大量のテキスト データが必要です。 短歌を学習させるには、コーパスとして大量の短歌が必要になります。 しかし、ではその「大量の短歌データ」 はいったい、この世界のどこに存在しているでし ょうか。

見渡してみれば、短歌はありとあらゆる場所に残されています。 例えば、これまでに発 刊された歌集や短歌雑誌に収められている歌を集めてきて、それをデータにする、といっ たやり方があるかもしれません。しかしこれは、人手で短歌を紙 (誌) 面からデータ化しな ければならないという点で、かなり根気、そして時間とお金を要する作業になるでしょう。 OCR(Optical Character Recognition/光学的文字認識)と呼ばれる、書物の電子化を自動で行

106

技術もありますが、毎回100パーセントの精度で文字が認識できるというわけでもな く、ここでも人手が必要になってきます。 そこで、インターネットに載せられている短歌 を自動で集める、という方法が考えられます。これは、プログラムを書きさえすれば自動 かつ大量に短歌を収集することが可能ですから、現実的な方法と言えます。

とはいえ、こうして収集できたとしても、著作権やモラルの問題があります。

無作為にまた作者に許可を取ることなく、人間がつくった短歌を収集して、言語モデル の学習に利用するという行為は、現行の法律や研究という範囲では許容されるかもしれま せん。しかし、実際の応用を考えると、たとえば「学習データとほぼ同じ短歌が生成され た時にどうする?」「許可なく自分の短歌が学習に使われていたらどうする?」 といった、 創作における著作権やモラルの点で、課題があり、また躊躇するところがあります。

擬似的な短歌を学習データにする

ちゅうちょ

そこでまず私たちは、「オープンなデータで、誰かがなんらかの思いを込めるなどして つくりあげた短歌ではない、でも短歌のように読めるテキストデータ」を集めて、これを 学習に使うこととしました。具体的には、オープンアクセスデータであるウィキペディア 日本語版(https://ja.wikipedia.org/) の記事から、短歌の定型を満たすテキストを集めて、これ

107

第3章 「詠む」前に「読む」

を「擬似的な短歌」として学習データをつくったのです。

このような形であつめられる短歌は「偶然短歌」という名前でプロジェクト化されてお り、書籍も出版されています。その名の通り、ウィキペディアの記事中で「偶然にも」短 歌になっている言葉を集めているわけですが、私たちもほとんど同じようにして短歌をウ ィキペディア日本語版から収集することにしました。具体的には以下のようなデータにな ります(下部に引用元の項目を記しました)。 さまざまな事柄を説明する記事における五・七・ 五・七・七の短歌の定型に沿う断片擬似的な短歌が、抽出できていることがわかりま す。 なお、データセットの作成においては、得られた断片から句読点を省く処理をしてい ます。

粘液の入った管があったりとその状態はさまざまである ( 「粘液」)

偏光をかけて重ねて投影しこれを偏光フィルタの付いた (「3次元ディスプレイ」) 強力で今日では正規表現と呼ばれるものと対抗できる ( 「Text Editor and Corrector」) きっかけとなり対戦を要求しそれが通った形となった(「チェリーボム(プロレスラー)｣) 前輪の回転軸はフレームの最前列に一段高く(「キュニョーの砲車｣)

このようなプログラミング環境の下でこれらの文字はしばしば (「Unicode文字

108

のマッピング」)

短歌AIの学習では、これらの擬似短歌を1万件ほど集めました。そこから、短歌のリ ズムをもった言葉の並びを学習しています。例えば、次の擬似短歌データをモデルが学習 するとします。

表現はもともと古代アテナイの三大悲劇詩人のひとり (「ヤーコブ・ヨルダーンス」)

この時、短歌AIは「表現」という言葉のあとに「は」が続くことや、「古代」の後に 「アテナイ」が続くことを学んでいきます(なお、実際のモデル学習では、文字列が常にきれいに単 語単位で分けられているとはかぎりません。 どのようにしてモデルが学習するための適切な「言葉の断片」 をつくるか、という問題に対しても、いくつかの手法が提案されています)。

他の例も見てみましょう。 例えば、次のような擬似短歌があります。

イギリスや他の国々の沿岸で伝統的に歌われていた 「シーシャンティ」) 特性を線形予測フィルターの係数としてパラメータ化し (「線スペクトル対」)

109

第3章 「詠む」 前に 「読む」

父親が日本人で母親がハンガリー系ルーマニア人 (「室伏広治」) 木星と土星は主に水素からなる大量の大気を有し (「外惑星」)

これらを見てみると、「国々」「沿岸」 「特性」 「線形予測」といった語そのものにしても、 また「係数としてパラメータ化し」 「水素からなる大量の大気を有し」といった語の並び にしても、当然のことながらそれがウィキペディアらしいものになっているのがおわかり いただけるでしょう。こうした擬似短歌からなるコーパスを学習した言語モデルは、当 然、その「ウィキペディアらしさ」を感じる言葉の並びをうまく捉えて、それに従った短 歌を生成することになります。

「ほんとうの短歌」への第一歩

くらし

ここで改めて、擬似短歌を学習した短歌AIの生成を見てみましょう。

入力はたらけどはたらけど猶

なほ

生成 活躍の道は限られるというわけで

生活楽にならざりぢつと手を見る)

110

入力 春過ぎて

生成 人見知りを克服して友人も多く同性から

(夏来るらし白たへの衣干したり天の香具山)

「はたらけどはたらけど猶」は皆さんもご存知でしょうか。石川啄木の短歌です。

「ぢつと手を見る」という有名なフレーズの続く歌ですが、モデルの生成はどうなってい るでしょう。「活躍の道は限られるというわけで」。なんだか普通のことを言っていますね。 入力されたテキストの表現する文脈を、素直に受けた内容になっています。これはこれで 面白いですが、それは「あまりにも普通すぎる」という、短歌らしくない 「逸脱」を感じ るからと言えそうです。もう少し短歌の「真ん中」を感じられるような表現が欲しくなっ てきます。

続いての「春過ぎて」は、序章でも引いた万葉集の歌から取ったものです。 生成結果を 見てみると、「人見知りを克服して友人も多く同性から」と、春の新生活について書いてい るように見えてきます。こちらも先ほどの例と同じように、ただただその新しい環境での 報告がなされているようで、やはり「詠われている」という感じはしません。また「同性

111

第3章 「詠む前に「読む」

から」と文章の断片でふつと切れていますが、この表現が何か効果的に使われているかと いうと、どうもそうではないと感じます。

このように、ウィキペディア日本語版の記事から抽出した擬似的な短歌を学習した短歌 AIでは、その生成もウィキペディアらしい、味気ないものになっています。 それでは、 擬似ではない「ほんとうの短歌」を学習すると、どうなるでしょうか。 それをみたくなっ てきます。

ちょうどそのとき、でした。私たちは、実際に歌壇で活動する歌人の方々から、彼らの 歌集を短歌AIの学習データとして提供してもらえる機会を得ることになります。その経 緯も踏まえながら、「ほんとうの短歌」を学習した短歌 AIがどのように変身するか、見て いきましょう。

俵万智さんの歌を学習したAI

第1章でも述べたように、先ほどの〈短歌AI〉を一人で試作して、ただただ面白いな、 と遊んでいる頃、朝日新聞社では、朝日歌壇を担当する文化部が「テクノロジーを使った 新たな企画」を欲しているという動きがありました。

当時、朝日歌壇はハガキによる投稿のみを受け付けていたのですが、いわゆるDX(デ

112

ジタルトランスフォーメーション。 情報技術を使って、サービスや業務に変革をもたらすことだと私は思 っています)企画の一環で、電子化とそれに付随した企画を模索していたのです(なお、20 24年4月からウェブ投稿が始まりました)。

そこで、ある日打ち合わせを持ち、〈短歌AI〉のデモンストレーションを見せること になりました。するとこれを面白がってもらい、さらに、ちょうどその頃に俵万智さんが 朝日賞(2021年度)を受賞されたことをきっかけに、俵さんにAIと短歌に関する企画 について相談することとなったのです。

俵万智さんは、「日本でいちばんよく知られた歌人」と言って、 「いや、そうかしら」と 言う人はないかと思います。 「そうだったのか!」とびっくりする人もいないでしょう。 そんな俵さんが「AIと短歌」に興味がある、ということで、突然にそう大きな話になる ことはないかと思っていたのですが、さっそく打ち合わせの機会を持つことになりました。 当日。新型コロナウイルスの流行による自粛期間で、オンライン会議だったのですが、 始まる前から落ち着かず、 少し前に短歌をつくり始めた自分が、俵さんと話すこと自体、 現実感も薄いような気がして、どうしようかと考えていました。ここは開き直るしかない か、と、「今日がここ十年でいちばん緊張しています」と告白してからの開始となった打 ち合わせでしたが、ご本人に〈短歌AI>をお見せするととても興味を持っていただき、

113

第3章 「詠む」 前に 「読む」

なんとそれまで出されている全歌集を学習データとしてご提供いただけることになったの です。

俵さんの歌は、第一歌集の『サラダ記念日』 から第六歌集『未来のサイズ』 まで、全6 冊の歌集に収められた作品だけでも2300首あまりありました。 これを「データ」とし 擬似短歌を学んだ先ほどの短歌AIをさらに学習させることで、〈ほんとうの短歌を 学習したAI〉が誕生しました。

早速ですが、 実際の生成を見ていきましょう。以下は、2021年の3月、築地の朝日 新聞社にて文化部とともに行った取材で生成したものです。それまでオンラインでやりと りしていた俵さんと実際にお会いする、初めての機会でした。なお、取材では俵さんのデ ータを学習したAIを〈万智さんAI〉と呼ぶこととしました。以降、擬似短歌だけを学 んだAIを〈短歌AI>として、それぞれを分けて書いていきます。

入力 二週間前に赤本注文す

生成(万智さんAI

この本のこときっと息子は 父は病気のことを書かねば

114

いかがでしょうか。 ここでは、取材時に俵さんが推敲されていた歌の上の句「二週間前 に赤本注文す」 (2023年刊行の第七歌集『アボカドの種』に「二週間前に赤本注文す息子は大物なの かもしれず」として収録)という入力に対して、それに続く内容が〈万智さんAI〉の生成結 果になっています。俵さんの歌には息子さんを歌ったものが多いのですが、まさに「息子」 生成していて、それがうまく現れているのがわかります。また「父」「書かねば」とい った語彙や表現にも、これまでの生成にはなかった、俵さんらしさが感じられるのではな いでしょうか。

ではここで、同じ入力に対する〈短歌AI〉の生成を見てみます。

二週間前に赤本注文す

(短歌AI)

だが発送が遅れたりなど

さきに青本注文すすむ

先ほども見たような、「普通な」短歌を生成していることがおわかりいただけるでしょ

115

第3章 「詠む」 前に 「読む」

う。 「赤本を注文したけど、発送が遅れる」 「さきに青本の注文がすすむ」 ••••••これではあ

まりにも報告的、と言いますか、普通すぎる内容で、短歌の言葉から遠い、と誰しもが感 じるのではないでしょうか。学習するデータが「ほんとうの短歌」になることで、言語モ デルの生成も大きく姿を変えることが実感いただけたかと思います。

次に示す例も、実際に俵さんが当時つくりかけていた短歌の上の句を入力して得られた 生成です。与えられた内容から上手く下の句を生んだ結果に、俵さんご本人も「これはや られた」と驚かれていました。

入力 一人称あまり使わぬ日本語に

生成(万智さんAI)

君の心を隠しているか

俵さんはこの生成を見て、「一人称を使わないというのは、心を隠していることかもしれ ない」と感想を述べられました。確かに、人間が読んで「上手い」と感じられる生成と言 えるでしょう。

他にも〈万智さんAI>の生成を見てみます。ここでは、俵さんの歌の一部(上の句)を

116

入力として、そこからどんな結果が得られるかを示していきます。

入力 「この味がいいね」と君が言ったから

(「この味がいいね」と君が言ったから七月六日はサラダ記念日/第一歌集『サラダ記念日』)

生成(万智さんAI)

ほぐせば今日はつるりと世界

我を愛せよ二本のパンで

いいねの道を呼びこまれてる

おまえの手紙を摘む昼下がり

だるさ見ており「母さん」として

君の言いたいもの青い花

電話をなくせないバスに乗り

空、青になる朝 平和あり 生きて命と言うように飲む ここは寂しい海に似ている

117

第3章

「む」 前に 「読む」

「つるりと世界」「手紙を摘む」といった表現からは、擬似的な短歌を学習した短歌AI にはなかった言葉の組み合わせを感じることができるでしょう。また、「『母さん』として」 の生成からは、母としての目線から詠まれた歌の多い「俵さんらしさ」を感じます。さら に「朝平和あり」では、短歌の中で空白を用いる 「一字空け」と呼ばれる技法を使って いるようです。「ほんとうの短歌」らしい表現を、モデルが上手く掴んでいると感じます。

入力 「寒いね」と話しかければ「寒いね」と

生成(万智さんAI)

(「寒いね」と話しかければ「寒いね」と答える人のいるあたたかさ/第一歌集『サラダ記念日』)

言われたような言の葉がある

答えるような水仙の花

言の葉島の声を知らぬまま

言の葉の香りつかむ夕べ

紙を拾える公園の花

呼ばれてみたき三百六十五秒

煮つめられたようなオレンジ

118

呼ぶほど思えば言の葉がある

答えし我が言葉をさがす

しまんと

言うためにある言葉の予感

この生成では、「言の葉」や「言葉」といった語が目立ちます。 これは、入力に与えられ 会話表現に注目して得られたもののように感じます。 「三百六十五秒」と、時間や空間に 対する具体的な表現を用いている点も、とても短歌らしい生成と言えるのではないでしょ うか。

入力 四万十に光の粒をまきながら

生成(万智さんAI)

(四万十に光の粒をまきながら川面をなでる風の手のひら/第二歌集『かぜのてのひら」)

眠る夜に眠れるゆえの

風吹いてもゆらゆらの時間

君を愛す時間、コケのぼりゆく

ゆく昼下がり今日のため見る

119

第3章 「詠む」前に「読む」

立つ朝の朝、吾は見ており 風を切り取る君の口づけ 光を曲げる朝 いっせいに 何かにぬるきを君は味わう 君のゆく町を待とうと思う 見えてくるなり君への手紙

「君」は、短歌では敬愛を寄せる相手に呼びかけるという特別な意味を持った言葉です。

この生成では、「君」を含む短歌が多く得られました。これも〈万智さんAI〉が獲得した 「短歌らしさ」と言えるでしょう。

入力バンザイの姿勢で眠りいる吾子よ

(バンザイの姿勢で眠りいる吾子よそうだバンザイ生まれてバンザイ/第四歌集『プーさんの鼻』)

生成(万智さんAI)

生まれるものを語りはじめる

立ちのぼりくる君の十年

120

「友だち」という言葉のポーズ

「好き」と思えば「いい」と思えり 生まれ出るもの立ちのぼりくる 「いいんだ」という言葉の向こう いとおしむような何かを思う

「ありがとう」という言葉の輪郭

「好き」と思えり「好き」と思えり

「落ちつきなさい」という語残して

この生成では、「 」 (かぎ括弧)を使った表現が多くみられます。俵さんは、短歌に会話 を取り入れれまでにない新たなスタイルを表した歌人の一人です。 言語モデルの生成を 見ることで、私たちが積み上げてきている短歌の歴史までをも体感することができます。

俵さんにあって「擬似短歌」にない語彙

ここで、俵さんのデータにのみ含まれる「語彙」を見ていきたいと思います。 さんの データが含む言葉の中から、先ほどの「擬似短歌」 コーパスには一度も登場しなかったも

121

第3章 「詠む」前に「読む」

のを数えてみました。その数は3750にもおよび、次のようなものでした。

・嘘

・はりまや橋

・冴えわたる

・アンチョビ

.

エアメール

・パンプス

いっせいに

・湯豆腐

.

心地よく

・ヤツ

・ちりばめ

・軽し

みいだ

このことから、言語モデルが擬似短歌の学習中には見なかった 「語彙」を俵さんのデー タの中で見出した、と考えることができます。 「こんな言葉を短歌に使っていいんだ」 「こ んな言葉は知らなかった」といったことは、実際に人が短歌を読んでいてもよくあること です。きっとそれと同じことが、言語モデルの学習過程でも起きているのか、と想像しま す。

また、俵さんの歌と擬似短歌コーパスの両方に共通して登場する言葉でも、その使われ 方はかなり異なることがわかります。 次に示すのは、俵さんの歌と擬似短歌のそれぞれで 「音楽」を含む例です。

122

う。

さんの短歌

擬似短歌

吹雪ふぶき枯れ木を揺さぶる音楽は世界の記憶、 未来の予感

泣くという音楽があるみどりごをギターのように今日も抱えて

日本の音楽文化発展に寄与することを目的とする

アメリカの小学校の音楽の教科書に載り、幼稚園でも

同じ「音楽」という言葉でも、それが 「世界の記憶」と結びついたり、「泣くという音 「楽」と表されたり、「語彙」だけではないその「組み合わせ」も、普通のテキストと短歌で は大きく違うものがあり、それが歌をつくっているのではないでしょうか。こういった表 現に触れられるのも、実際の短歌を読み込んでいくほかにはできない経験と言えるでしょ

実際、短歌が上達するためには、たくさんの作品に触れた方が良いと言われます。 好き な作品に出会ったり、意外な言葉の使い方に驚いたり、これまでに詠われた短歌で実践され 表現に触れ、それを感じることが、自分の作に影響を与えるということがあるでしょう。

123

第3章 「詠む」 前に 「読む」

ちょうく

永田和宏さんの歌を学習したAI

永田和宏さんは、現代短歌界において重要な歌人の一人です。 歌壇最高峰の賞とされる 迢空賞や、現代短歌大賞など多くの賞を受賞する一方で、宮中歌会始選者や宮内庁御用掛 を務めるほか、2005年からは「朝日歌壇」の選者として、朝日新聞社にとってもつな がりの深い歌人です。

永田さんは前述 (第1章)のように、細胞生物学者としての顔も持っています。科学者と しての背景から、AIと短歌の関係―このテクノロジーが短歌の創作や鑑賞にどう影響 するかという点について、強い関心と興味を示されていました。そこで、〈短歌AI〉を持 って、文化部とともにお話しする機会を得ることになります。

最初の取材では、永田さんの歌集の一部を学習した短歌AIの生成として、次の歌をお 見せしました。先ほどの〈万智さんAI>とは、生成の雰囲気が大きく異なるのがご覧い ただけるでしょう。

入力 足裏を砂流れおり

(足裏を砂流れおりいまさらに扱いかねている肉の量/第四歌集 『やぐるま』)

124

生成(永田さんAI)

見る人の心に届く一石となる

波打ってもこもこした土塊となる

小孔が空いた様子山全体が

露よ遠く彷徨う人の声をあざけるように

永田さんからの反応は、

「1首目はおもろい。 思わせぶりな歌になってる。でも、まだAIがこのレベルでよかっ たなぁ」

というものでした。続けて、

「でも、それらしきいい歌ができることは間違いない。 すぐに人間を追い越しちゃうかも しれない。作者と読者の関係という問題にも関わってくる」

として、創作におけるコミュニケーションについての問いを投げかけています。 この興 味は、第1章でも紹介した〈連歌AI〉につながっていきました。

永田さんは、その歌歴の中で作歌のスタイルを大きく変えたという点でも特徴的です。 前衛短歌の担い手として新かな遣いで歌をつくられていましたが、60歳を迎えて以降、旧

125

15

第3章 「詠む」 前に「読む」

かな遣いでの作歌を始めます。

六十歳になったら旧かなでいこうかと漠然と考えていた。そんなことを口走ったこ ともあった。新かなか旧かなかどちらが正当かなどという議論にはほとんど興味はな いが、年齢とともに、旧かなのもつやわらかさと、ゆったりとした響きの奥行きが身 に添うようになってきたというのが実感に近い。旧かなを窮屈と感じる向きもあるだ ろうが、私自身は旧かなのもつ自在さに、そしてある種の開放感といったものにも魅 力を感じている。 (『日和』あとがきより引用)

私たちは永田さんのこの歌歴に従って、新かな遣いと旧かな遣いでそれぞれ異なるモデ ルを作成し、生成の違いを見ることにしました。実際の生成は、次の通りです。

入力足元をゆっくりと陽は廻りゆく

(足元をゆっくりと陽は廻りゆく冬の陽射しのはかなきゆうべ/第五歌集『華氏』)

生成(永田さんAI・新かな)

闇の底にさびしき花が

126

生成(永田さんAI・旧かな

見ゆる風がいつにもまして

入力 きみに逢う以前のぼくに遭いたくて

(きみに逢う以前のぼくに遭いたくて海へのバスに揺られていたり/第一歌集『メビウスの地平』) 生成(永田さんAI・新かな)

裏山を登れば五月の湿り

生成(永田さんAI旧かな)

きみを待つだけの老いにも逢いたく

同じ入力から、それぞれのモデルで全く異なる印象の生成が得られています。かな遣い 厳密に制御しながらの生成とまでは至りませんでしたが、前衛短歌の雰囲気を持つ新か なモデルと、「やわらかさと、ゆったりとした響き」とご自身もおっしゃる旧かなを学んだ モデルとで、違いが現れているのがおわかりいただけるでしょう。

このようにして見ていくと、学習データは歌人の「歌歴」も表すことができそうな気が してきます。最近では、コンピュータやスマートフォンといった端末で短歌をつくる人も

127

第3章 「詠む」 前に「読む」

きっと多いでしょう。日々つくる短歌をどこかに保存しておいて、「未来のためのデータセ ット」にする。そしてそれを用いて、あなただけの言語モデルをつくる。仮にそんなこと が可能になれば、あなたのそれまでの言葉を模倣する道具がそこにある、ということにな す

また、永田さんは「自分の時間だけには嘘をつかないで」歌をつくり続ける、というこ とをおっしゃっていました。 これは、過去の出来事や未来に起こりうることを頭の中で展 開して短歌をつくるのではなく、まさに自分が立っている「いま」から、いまの自分にし かつくれない歌をつくるということです。そしてそれが、人生という有限の時間の中で歌 をつくる人間の特権である、ということではないでしょうか。そうしてできた歌の蓄積は 「瞬間瞬間でのあなたを表すデータセットをつくる」ことでもある、と言えます。そこか 言語モデルという道具によって得られる生成は、あなたを新しく理解する 「読み」を誘 うかもしれません。

「何を読んだか」が「何を書くか」になる

ここまで見てきたように、言語モデルの生成では「どんな言葉を学習するか=何を読ん だか」によって、「どんな言葉を生成するか=何を書くか」が大きく変化することがわか

128

りました。

これをそのまま人間の読み書きに当てはめることが、必ずしもできるとは思いませんが、 私たちにとっても読むこと、つまりこれまでどんな歌がつくられてきたのかを知り、「これ 「はいいな」と思ったり、もしくはそうでないと思うことすらも、とにかく「読んで感じる」 ことがとても大事なのではないかと思います。

私がつくった歌の中で、初めて新聞歌壇に掲載された短歌が、 次の一首です(「東京歌壇」 東直子選/2021年3月2日)。

コート着たままの昼寝が好きだったいまは消毒除霊までして

2021年、コロナ禍の真っ只中とも言える時期につくったものです。 どこへ行くにも、 何に触れるにもまずアルコールという、それまでの生活を基準と考えれば「過剰」とも言 える消毒にまみれた生活を、「除霊」という言葉を持ち出して表しています。この「除霊」 は、この歌をつくった頃に寺山修司の全歌集を読んでいて、その影響を受けて出てきた言 葉だと思っています。

特に短歌を始めたばかりの頃というのは、触れる短歌のどれもが新鮮で、「こんな表現

129

第3章 「む」前に「読む」

ができるのか」という驚きの連続を体験できるとても貴重な時期です。 そこから徐々に自 分の語彙というものを獲得していくのではないかと考えますが、そのようにしてやはり 「読むことで言葉が変わっていく」のでしょう。 「何を読んだか」が「何を書くか」に強く 結びついていると感じます。

しかし、人のつくった歌をただ吸収してそれをなぞっていくというだけでは、きっと何 かがいけないだろう、とこれを読んでいる方は誰しも思われるのではないでしょうか。短 歌は創作です。 これまでの世の中に存在しなかったものをつくるという、ルールというか、 使命のようなものがあると、信じられているように思います。 つまり、他の誰にも似てい ない、あなただけの言葉を、あなたが生成する。あなたがたくさん摂取した言葉があって、 その上で自分の言葉をつくっていく。そんなことが人間の作歌では求められているのでは ないでしょうか。

言語モデルは、過去につくられた短歌を学習して、確率的に言葉を並べていきます。 そ の結果は過去の再現ともいえ、そこから新しい表現を生み出すのは簡単ではないでしょう。 私たち人間と同じように、読んだものをただ再現するだけでは創作になり得ないという課 題を、AIも抱えているのです。

130

覚えること忘れること忘れられないこと

言語モデルは、学習データにある言葉の並びを学んでいきます。 これまで見てきたよう に、一度ウィキペディアで学んだモデルは、ウィキペディアらしい言葉の使い方を獲得し ていきました。しかし、そのあとで歌人の歌を学んだモデルは「ウィキペディアらしい言 葉」をいわば「忘れ」て、歌人らしい言葉の使い方を学んでいたようにも見えます。実際、 言語モデルは一度学習したものとは性質の異なるデータを学習することで、以前に学んだ 内容を忘れてしまうことが知られています。これは、新しく学習した内容でニューラルネ ットワークの中身が上書きされ、過去に学んだことを忘却してしまう現象です。 一方で、人にはどうしても忘れられない、といったことがあるように思います。それは 良い意味では、ある体験に心を動かされて「忘れられない」、悪い意味では、ひどく傷つ いて「忘れられない」、どちらも、忘れようと思っても忘れられないものとして、その人 の未来へ影響を及ぼしていきます。

きっと皆さんも、たくさんの歌を読んでいくうちに驚きや感動があって、「これは忘れら れない」と感じる表現に出会うことがあるでしょう。 また、自分では意識していなくても 「覚えてしまっている」ことがあるようにも思います。私たちに備わっているこの「忘れら れなさ」を大事にしながら、忘却を恐れることなくたくさんの歌に触れる。そうすること

131

第3章 「詠む」 前に 「読む」

で、言語モデルとは違う言葉の生成が私たちにできるのかもしれない、と考えます。

この章から学ぶ「短歌入門」

●歌集を一冊読む。

歌集の中で心に留まった言葉を使って、短歌をつくってみる。

どこかへ出かけたり、人と会ったり、映画を観たりして、読んだ歌集のことをすべて忘 れたふりをして、短歌をつくってみる。

132

第4章 言葉を飛ばす

言語モデルが言葉を生成するとき

第1章で説明したように、言語モデルは入力された文字列に対して計算される「次にく

る言葉の生成確率」 から、 文字列を生成することができました。図4−1では「今日の天気 は」という入力に対する「次にくる言葉の生成確率」を言語モデルによって計算していま す。 「晴れ」「曇」「、」という語にそれぞれ20%、15%、13%と生成確率が与えられています。 なお、この時に言語モデルが扱う言葉の単位を「トークン」と呼びます。トークンは、 例えば「単語」のような、人にとって自然な文章の区切り方とは少々違っていることに注 意してください。図4−1では、入力に与えた「今日の天気は」が「今日の天気は」 と三つのトークンとして表され、また「晴れ」 「曇」 「、」のそれぞれのトークンに生成確 率が与えられています。

さてここで、「次にくるトークンの中でいちばん確率の高いもの」を選ぶだけでは「自然 な言葉の並び」が得られないことが知られています。 この「次にくるトークンの生成確率 が与えられた中で、どのトークンを実際に選び取っていくのか」という部分にも、さまざ まに考えられることがあるのです。

実際に言語モデルが計算するトークンの生成確率を見ながら、「次にくるトークンのなか

134

昼

(15%)

今日の天気は

晴れ (20%)

でいちばん確率の高いもの」を各時点で選び続けて、文字列を生成してみます。なお、こ とで扱う言語モデルは、〈短歌AI〉ではなく、さまざまな文書を学習した汎用的なもの です。

(13%)

図41 「今日の天気は」 の次にくる言葉の生成確率

入力短歌を

トークンの生成確率 詠 (13.9%)、詠んだ(9.7%)、投稿(6.0%)、 書 いて (4.0%)

まず、「短歌を」という文字列をモデルに入力してみました。 「トークン の生成確率」に示すのは、各入力に対する生成確率の上位五つのトークン です。ここでは「詠」が次にくるトークンのなかで最も確率の高いものと して計算されています。ですので、「短歌を」に「詠」というトークンを つないだ文字列を新たな入力として、続きの生成確率を計算してみます。

入力短歌を詠

トークンの生成確率 む (54%)、 んで (12.6%)、み(11・6%)、んでい

135

35

第4章 言葉を飛ばす

る (7.7%)、んでいた(0.9%)

ここでは、「む」が最も高い確率のトークンとして得られました。 先ほどと同様に、「短 歌を詠」に続けて「む」というトークンをつなぎ、これを新たな入力にします。以降もこ の操作を続けていきましょう。

入力 短歌を詠む

トークンの生成確率の11.0%)、 とき (4.7%)、 ことは (4.7%)、こと (4.5%)、とい うこと (3.2%)

入力 短歌を詠むの

トークンの生成確率は(4.8%)、 が (7.9%)、好き (9.7%)、 に (7.1%)、 も (5.0%)

入力 短歌を詠むのは

トークンの生成確率 %)、簡単(2.0%)

〈読点〉(2.1%)、初めて(6.8%)、好き(5.7%)、とても(2.5

136

入力 短歌を詠むのは、

(0.02)

トークンの生成確率 短歌(7.8%)、 とても(1.5%)、その(1.5%)、今(1.2%)、俳句

入力短歌を詠むのは、短歌

トークンの生成確率の (7.5%)、(14.7%)、が (3.5%)、 に (3.2%)、会 (2.2%)

入力 短歌を詠むのは、短歌の

トークンの生成確率 魅力 (4.3%)、才能 (3.5%)、世界で (2.2%)、 先生 (1.9%)、 「かぎ括弧〉(1.8%)

入力 短歌を詠むのは、短歌の魅力

トークンの生成確率(8%)、を知る(5.5%)、を伝える(5.1%)、に (4.5%)、や (40%)

137

第4章 言葉を飛ばす

このようにして続けた結果、 次の文字列が得られました。

・短歌を詠むのは、短歌の魅力を最大限に活かした、新しい短歌の楽しみ方です。 短歌は、 短歌の魅力を最大限に活かした、新しい短歌の楽しみ方です。 短歌は、短歌の魅力を最 大限に活かした、新しい短歌の楽しみ方です。 短歌は、

......

なんだか、何か言っているようで、何も言っていないような文字列です。さらに、同じ 文を何度も繰り返しています。 まさに壊れたロボットが喋り続けているような雰囲気で、 これが「自然な文字列」 であるとは到底見なせないでしょう。 なお、このようにして、各 時点で最も確率の高いトークンを選んでいく手法を「貪欲法」と呼びます。

では、なぜ、この貪欲法では「自然な文字列」を生成することができないのでしょうか。 その原因の一つとして、選び取るトークンが「各時点で」 最も高い確率を持つという、狭 い範囲で考えた場合の最適解でしかない、ということが言えます。

つまり、最も確率の高いトークンは「その時点のみにおいては」 最適な選択肢に見える ものの、全体の文脈を考慮すれば必ずしもSSとは限らない、といった場合があるのです。 例えば、図4-2を見ると、貪欲法によって選ばれるトークン「晴れ」「。」全体の確率は

最も生成確率の高い トークンを選択し続ける 食欲法 曇 (15%) (17%) って (3%) り (90%) っていて (0.7%) 今日の天気は ・晴れ(20%) 。 (20%) で (10%) .晴れ (10%) 、(13%) ・量 (13%)

図4-2 「自然な文字列」 をつくる「次にくる言葉」とは?

この「n個の候補の数」には「ビーム幅」という け残していく」という方法で文字列を生成します。 しながら、生成した文字列全体の確率が高いものだ 手法は「次にくるトークンの候補の上位n個を保持 まずご紹介するのが、 「ビームサーチ」です。この

いろいろな言葉のつなぎ方

・雨 (6%)

案されています。 選び方」について、これまでにさまざまな手法が提 と言えるでしょう。そこで、この「次のトークンの きる機会を逃してしまうのが、貪欲法の大きな欠点 ぶことでその後の選択肢を狭め、より良い表現がで となります。各時点で最も確率の高いトークンを選 5%)になり、こちらの方がより確率の高い文字列 ン「曇」を選べば、全体の確率が15%×30%=13

章 言葉を飛ばす

第4

(3x814%)となります。 しかし、別のトーク

39 139

入力 短歌を詠むのは、

名前がつけられています。 例えば、ビーム幅を3に設定した場合、モデルは各時点で確率 の高い上位三つのトークンを保持し、それぞれについて枝分かれしながら次のトークンの 予測を行います。 そして、 それまでの結果から確率の高い枝を三つ残して、またそれぞれ について上位三つのトークンを選択して……という過程を繰り返していきます。 実は、図 4-2で表したのはビーム幅3によるビームサーチの例になっていました。この手法によ り、モデルはより多くの候補を探索することができ、先ほど見た貪欲法よりも、全体とし 確率の高い、もっともらしい文字列を生成する可能性が高くなります。

試しに、「短歌を詠むのは、」という入力に対して、ビーム幅3で生成した結果を見ると、 次のようになりました。

生成短歌を詠むのは、短歌を詠むのが好きな人なら誰しも一度は経験したことがあるので はないでしょうか。今回は、短歌を詠むのが好きな人なら誰でも一度は経験したことがあ るであろう、短歌を詠むのが好きな人のための短歌講座をご紹介します。 短歌を詠むのが 好きな人なら誰でも一度は経験したことがあるであろう、短歌を詠むのが好きな人のため の短歌講座をご紹介・・・・・・

140

入力 短歌を詠むのは、

いかがでしょうか。貪欲法による生成より、若干良くなった気がします。しかしそれで も、表現の反復が見られます。そこで、これを防ぐために、ある「トークンの連続」が重 複して現れないようにする処理が言語モデルではよく実装されています。 ここで、連続す 2トークンが重複して現れないようにすると、どうなるか見てみましょう。例えばここ では、すでに入力にある「短歌を」などが重複しない生成が期待されます。

生成短歌を詠むのは、短歌が好きな人なら誰でも一度は経験したことがあるのではないで しょうか。今回はそんな短歌の魅力について、ご紹介していきますので、ぜひ参考にして みてくださいね。

このように、先ほどより自然な文章が(やっと) 得られました。

さて、一見よさそうに見えるこのビームサーチですが、短歌生成への適用を考えたとき には、ある問題が生じます。それは「得られる表現の多様性に限りがある」ということで す。例えば、ビーム幅を3としたビームサーチを考えます。このとき、結果として得られ

141

第4章 言葉を飛ばす

るのは三つの枝=文字列であり、これは入力が同じであれば、何度試したところで変化し ません。一方、短歌の生成は〈何か一つに決まった正解〉を持たず、 そこではむしろ自由 で多様な生成が期待されるでしょう。まったくのでたらめでは困りますが、トークンの並 びの自然さを保ちながらも、多様な結果を言語モデルから得るには、どうすればよいでし ょうか。

ここで、言語モデルから多様な生成を得るための一つの試行として、トークンを入手で 好き勝手に選んでみる、ということをやってみたいと思います。私が各時点で 「良いかも」 と思えるトークンを、その生成確率の上位にあるものから自由に選びとってみても、きっ それなりの結果が得られるのではないかと想像します。 早速やってみましょう。

入力 短歌を詠むのは、

(0.9%)

トークンの生成確率 短歌 (7.8%)、 とても (1.5%)、 その (1.5%)、今(1.2%)、俳句

入力 短歌を詠むのは、とても

トークンの生成確率 難しい (18.2%)、 楽しい (14.3%)、大変な (4.8%)、簡単(4・8

142

%)、 大変 (3.6%)

(0.8%)

入力 短歌を詠むのは、とても大変な

トークンの生成確率 ことで(49%)、ことだ (15.8%)、作業(10・3%)、こと (8・8%)、 事(3.2%)

入力短歌を詠むのは、とても大変なことで

トークンの生成確率(9.8%)、 〈読点〉 (2.2%)、 は (2.0%)、 も (1.4%)、しょう

入力 短歌を詠むのは、とても大変なことで、

トークンの生成確率 その(2.5%)、しかも (2.1%)、 また (1.4%)、 多くの (1.1%)、 毎日(1.0%)

入力 短歌を詠むのは、とても大変なことで、しかも

トークンの生成確率、〈読点〉 (19・2%)、その(3.2%)、難しい (2.0%)、 大変な (1.5

143

第4章 言葉を飛ばす

%)、それが (1.5%)

入力 短歌を詠むのは、とても大変なことで、しかもそれが

トークンの生成確率、〈読点〉(6.1%)、「〈かぎ括弧〉 (2.3%)、 短歌 (1.9%)、 とても (1.9 %)、 楽しい (1.5%)

入力 短歌を詠むのは、とても大変なことで、しかもそれが楽しい

トークンの生成確率の(11.9%)、 もので (9.7%)、 こと (8.8%)、もの (6.8%)、こと で (6.7%)

入力 短歌を詠むのは、とても大変なことで、しかもそれが楽しいもので

読

トークンの生成確率 す (4.2%)、 は (16.6%)、 も (2.0%)、なければ(5.6%)、 点〉(2.7%)

入力 短歌を詠むのは、とても大変なことで、しかもそれが楽しいものです

トークンの生成確率 〈句点〉(1.5%)が(4.9%)、から(2.9%)、よ (2.7%)、ね (2.

144

+)

多様な生成を得る手法

完成 短歌を詠むのは、とても大変なことで、しかもそれが楽しいものです。

結果、「短歌を詠むのは、とても大変なことで、しかもそれが楽しいものです。」という 文字列を得ることができました(そんなふうに思っていたいものです)。いかがでしょう? モ デルが計算する上位のトークンから「その場の思いつき」で選んでいっても、自然な文字 列が生成できることがおわかりいただけますか。こういった方法で生成を繰り返せば、さ まざまな文字列=多様性のある表現が得られそうです。

いま見たように、トークン選択の過程にランダム性を導入して、多様な生成を得る手法 が提案されています。この手法は「サンプリング」と呼ばれ、またその中でいくつか異な る方法があります。 先ほどは人手でトークンを選んでいきましたが、コンピュータではど のようにして選び取っていくのか、例を交えて説明しましょう。

145

第4章 言葉を飛ばす

入力 短歌を詠むのは、

(0.0)

トークンの生成確率 短歌 (7.8%)、とても (1.5%)、 その (1.5%)、今 (1.2%)、俳句

ここで、「短歌を詠むのは、」という入力に対していちばん生成確率の高いトークンは 「短歌」です。しかし、「とても」 「その」「今」といったトークンも「短歌」よりは確率は 低いけれど、それに続く候補として計算されています。

「サンプリング」では、トークンに与えられた確率に従って、そのうちのどれか一つを選 んでいきます。 これによりトークンの選択に幅が生まれ、かつ毎回の生成によってその内 容が変化します。

もっとも単純なサンプリング手法として、「Top-Kサンプリング」があります。こ れは、各時点で計算される候補の上位K個から、確率に従ってトークンを選んでいくとい う手法です。 先ほどの例では、K=3とすると「短歌」 「とても」 「その」のどれか一つを 選んで、文字列を生成することになります。実際に、K=3で得られる生成の例をいくつ か見てみましょう。

146

.

.

入力 短歌を詠むのは、

生成(K=3の出力例)

短歌を詠むのは、短歌を詠んでみようという気持ちが一番の動機だと思います。

短歌を詠むのは、短歌が大好きで、短歌にのめり込んでいる人ばかりです。

・短歌を詠むのは、短歌が好きな人なら誰でも、誰でも、だれでも、誰でも、誰にでもで きる。

いかがでしょうか。確かに、多様なテキストが生成されています。 また、毎回の生成で その内容が変化するので、何が出るかわからないものを待つ「生成ならではの楽しみ」 が 生まれたような気がします。一方で、「誰でも」を繰り返す、 不自然な生成もまだ見られま した。そこで、Kの値をもっと大きくしてみましょう。これまでは生成確率の上位3トー クンから選んでいましたが、たとえばこれを1000として、上位1000個の中から選 んでいくようにしてみます。

入力 短歌を詠むのは、

生成(K=1000の出力例)

147

第4章 言葉を飛ばす

短歌を詠むのは、その人にとっての「歌」であり、その人にとっての「短歌」は、その人 の「心情」を反映しているもの。

・短歌を詠むのは、とても難しいことで、短歌を詠んだとしても、それが誰かの心に残る ことは、まずない。

・短歌を詠むのは、短歌の魅力を存分に発揮するのに、一番手っ取り早い方法だと思います。

これまでとは全く違う、豊かな言葉の並びが得られました。 「短歌を詠むこと」に対す る、さまざまな意見が集められているようにも見えます。中にはずいぶん厳しい言葉もあ ますね。

単純にK個の候補からサンプリングするのではなく、もう少し工夫を加えた手法もあり ます。その一つが、生成確率の合計が1%以上になるまでの上位の候補から選ぶ 「Top pサンプリング」です。Toppサンプリングは、確率の極端に低いトークンを選ん でしまったり、またその逆に確率の高いトークンを見過ごしてしまうといったことを防ぐ ことができます。

例えば、ある時点で次にくるトークンとして「短歌」の確率が9%で、他の語の確率が 非常に小さい(つまり、それを選ぶと不自然に感じられる)場合があったとします。この時、K

148

=2以上のTop-Kサンプリングでは、その小さな確率のトークンを選んでしまう可能 性があります。一方、p=90%としたTop-pサンプリングでは、「短歌」のトークン 一つで確率が90%を超えていますので、この「短歌」だけを候補として、他の小さな確率 を持つトークンは無視して生成するといったことができます。

次頁と次々頁の四つの棒グラフは、K=10としたTop-Kサンプリングと、p= としたTopipサンプリングにおける、トークン候補の数を示しています。上側二つの グラフが示す「今日の天気は」という入力では「晴れ」 「曇」の2トークンで生成確率の 合計が30%を超えるため、 Top-pサンプリングはこの二つを選択候補とします(図4 -5)。一方、Top‐Kサンプリングでは「、」以降の、より確率の低いトークンまでが 候補に入っていることがわかります(図4−3)。下側二つのグラフに示した「今日の天気 は、晴れです。 そして、」という入力に対しては、次にくるトークンの生成確率はどれも 小さいため、Top-pサンプリングの候補数と、Top-Kサンプリングの候補数はど ちらも10になっています(図4−4、図4−6)。モデルが計算するトークンの生成確率に合 わせて、動的に候補の数を変えられるのがTop-pサンプリングです。

380

149

第4章 言葉を飛ばす

0.200 0.175 0.150 0.125 0.100 〈確率〉 0.075 0.050 L 0.025 0.000 晴れ 雨あい快晴良い < 言葉 > どう 今「いい

図4-3 「今日の天気は」 の次にくる言葉と確率

Top-K, K=10

0.08-

0.07-

0.06

0.05

確率

0.04

0.03

0.02

0.01

0.00

今日 気温 明日 昨風 朝雨今今日の雲 お 台風 〈言葉>

図4-4 「今日の天気は、晴れです。 そして、 の次にくる言葉と確率

150

0.200 0.175 〈確 0.150 0.125 0.100 0.075 0.050 0.025 0.000 晴れ 曇 雨あい快晴良い. <言葉> どう 今「いい

図4-5 「今日の天気は」 の次にくる言葉と確率

Top-p, p=30% 0.08 0.07 0.06 0.05 0.04 0.03 0.02 0.01 0.00 今日 気温 明日 昨風 朝雨今 今日の雲 お 台風 〈確率

〈 言葉 〉

図46 「今日の天気は、晴れです。 そして、」 の次にくる言葉と確率

4章 言葉を飛ばす

第

151

.

p=30%、90%とした Toplpサンプリングの生成例を見てみます。

入力短歌を詠むのは、

|生成(=30%の出力例)

......

短歌を詠むのは、その人の人生を豊かにするのにとても重要なことです。 私は、短歌 を詠むことを通して、人生の豊かさや喜びを実感しています。 短歌を詠む･･････

・短歌を詠むのは、短歌の先生に教えてもらってから、ずっと続けてきました。 短歌は、 自分の言葉で、自分の心に響くものを探しています。 短歌は、自分の言葉で、自分の心

・短歌を詠むのは、その人自身です。その人自身が短歌を詠むことで、短歌はより一層、 深みを増します。 短歌を詠むことで、その人自身を、より深く、より深く・・・・・・

入力 短歌を詠むのは、

|生成(p=30%の出力例)

・短歌を詠むのは、自分の心にひそむ不安や苦しみを、その心の奥深くから解き放ってく

れるからです。今日もお疲れ様でした。 今日も楽しく過ごせました

152

・短歌を詠むのは、そんなに上手ではない私でも、短歌というジャンルはとても好きで す。今回は、「短歌という響き」や、「短歌で人を想う」ことについて、少し調べてみた いと思います。そう考えると、短歌......

・短歌を詠むのは、人生を豊かに過ごす上でも、大切なことなのかもしれませんね。

いかがでしょうか。p=30%にはまだ繰り返しが見られますが、いずれもTop-Kに 比べるとさらに自然で、ひょっとするとこれらを書いた「人」の雰囲気まで想像できてし まうかもしれない、そんな生成になったと感じませんか。最初に見た貪欲法による結果と 比べると、まるで違う言語モデルが生成しているような感覚すら覚えます。 同じ言語モデ ルでも、そこから言葉を選び取るという方法を変えるだけで、これだけ違った結果が得ら れるのです。

言語モデルから言葉を生成するのは、なかなか一筋縄ではいかないということがおわか りいただけたでしょうか。ここに、短歌の生成における課題や、さらには私たち人間が言 葉をつないでいくという行為に対する、新たな視点を提供する可能性を感じます。

153

第4章 言葉を飛ばす

「生成パラメータ」 による調整

.

K=1

これまでに見た生成手法では、ビームサーチのビーム幅や、Top-KのK、Topl pのpといった、生成するときに設定できる値がありました。 このような生成時の設定を 「生成パラメータ」と呼び、この値によっても結果は大きく変化します。

まずは、Top‐Kにおける選択候補の数であるKの値をさまざまに変えながら、 生成 の違いを見てみましょう。

・短歌を詠むのは、短歌の魅力を最大限に活かした、新しい短歌の楽しみ方です。 短歌 は、短歌の魅力を最大限に活かした、新しい短歌の楽しみ方です。 短歌は

・短歌を詠むのは、短歌の魅力を最大限に活かした、新しい短歌の楽しみ方です。 短歌

は、短歌の魅力を最大限に活かした、新しい短歌の楽しみ方です。 短歌は

短歌を詠むのは、短歌の魅力を最大限に活かした、新しい短歌の楽しみ方です。 短歌

は、短歌の魅力を最大限に活かした、新しい短歌の楽しみ方です。 短歌は

154

.

.

.

K=100

|K=1000

・短歌を詠むのは、とても楽しいことです。でも、それと平行して、短歌にも様々な楽し み方があります。

短歌を詠むのは、短歌を詠むのが好きな方ならどなたでもできます。 初心者の方も、経 験者の方も歓迎です。

・短歌を詠むのは、初めてでした。でも、おしゃれでした。とても、素敵な短歌でした。 ありがとうございました。

短歌を詠むのは、とても良いことです。それは、短歌を詠んだ人達と交流することで す。短歌を詠むと心が洗われるような気になります。

短歌を詠むのは、今から10年以上前は、それほど珍しくはありませんでした。

短歌を詠むのは、短歌を詠むことの喜びをより深く感じ、より豊かな感性を養うためです。

短歌を詠むのは、生まれた時から生きているからこそ出せる芸なんだという風に気が付 いてからというもの、自分を今まで以上に美しいとは意識しなくなりました。

155

第4章 言葉を飛ばす

.

う?

p=0%

・短歌を詠むのは、字に恋をするのではなく、希望を持つこと。きみは自分を人間だと思

・短歌を詠むのは、日ごろの努力の成果だ、そう私たちが昔から、魂のクリーニングを念 じながら、短歌を詠み続けた道のりは、決して短くはありません。

K=1の場合は、先ほどの貪欲法と同じ結果が得られています。 そこからKの値が大き くなるにつれ、文脈から容易に想像される表現を超えた「意外な」 生成が現れているのが ご覧いただけるのではないでしょうか。 K=1000の生成例にある「字に恋をするので はなく、希望を持つこと。 きみは自分を人間だと思う?」 や、 「魂のクリーニング」といっ 表現には、少し驚いてしまうと言いますか、私自身では想像しえない、言語モデルで生 成しなければ得られなかった言葉の飛躍を生んでいると感じます。

次に、ToppのPの値を変えると、どうなるでしょう。

短歌を詠むのは、短歌の魅力を最大限に活かした、新しい短歌の楽しみ方です。 短歌 は、短歌の魅力を最大限に活かした、新しい短歌の楽しみ方です。 短歌は

156

p=30%|

p=6%

・短歌を詠むのは、短歌の魅力を最大限に活かした、新しい短歌の楽しみ方です。 短歌 は、短歌の魅力を最大限に活かした、新しい短歌の楽しみ方です。 短歌は

・短歌を詠むのは、短歌の魅力を最大限に活かした、新しい短歌の楽しみ方です。 短歌 は、短歌の魅力を最大限に活かした、新しい短歌の楽しみ方です。短歌は

・短歌を詠むのは、短歌の世界で有名な人達ばかりです。 その中でも、特に有名なのが、 ・短歌を詠むのは、短歌の才能を磨くこと。 短歌は、短歌の表現の仕方によって、様々な 意味があります。 今回は、短歌の表現の仕方について、ご紹介します。

・短歌を詠むのは、その人にとっての「人生の目標」であり、その目標に向かって、日々 の努力を積み重ねることが、短歌の醍醐味です。

・短歌を詠むのは、私にとっての至福の時です。 私の人生において、短歌は私の宝物で す。 短歌は、人生の貴重な瞬間です。

・短歌を詠むのは、ただ単に短歌を詠むだけではなく、その背景にある様々な問題や想い

157

17

第4章 言葉を飛ばす

.

が、その人の心に響くように詠みます。

短歌を詠むのは、まだまだ先のことかもしれませんが、これからも、よろしくお願いい たします。

p=3%

・短歌を詠むのは、その時代、社会、思想が反映されています。もちろん、それこそ日本 独特の歌でもあります。

・短歌を詠むのは、私にとって至難の業です。 なぜなら、短歌は、人に見せられるものだ からです。それなら、まず短歌に書くのをやめるところから始めてみましょう。

・短歌を詠むのは、誰でも出来るように思えるが、やはり自分の才能が試されることも多 いのだなぁ。

p=0%では、トークンの生成確率上位の合計が0を超えたところまでを候補とするの で、先ほどの貪欲法や、 Top-KでK=1とした場合と変わりません。この値を少しず つ大きくしていくと、先ほどと同じように、多様な生成が得られるのがわかるでしょう。 Toppの特徴として、〈多様かつ自然〉という点が挙げられます。「日々の努力を積

158

み重ねることが、 短歌の醍醐味」 「その人の心に響くように詠みます」 「私にとって至難の 業」「誰でも出来るように思えるが、やはり自分の才能が試される」 ……………。 「短歌を詠む」 ことに関して、まるで「わかっている」人間が語っているようです。Top-Kのような 突飛な表現は見られませんが、より自然と言える文字列が多様に得られています。

確率を「ならす」か 「尖らせる」か

これらの値に加えて、各手法に共通するパラメータとして〈温度〉 (temperature) があり ます。言語モデルに温度? と不思議に思われるかもしれませんが、このパラメータは物 理学における温度の概念に由来します。 物質の粒子が高温で活発に動くように、このパラ メータの値が高いほど、モデルが生成するテキストのランダム性も高くなります。 具体的には、〈温度〉は言語モデルの計算する確率を「ならす」か「尖らせる」かを調 節し、これを1以上に設定すると確率が「ならされます(図4−7)。 砂場を板でならす ように、出っ張っている部分は凹み、凹んでいるところへは砂が流れ盛り上がるように、 確率の値が平らになるのです。つまり、確率の高いトークンは低く、確率の低いトークン は高く、その差を埋めるような操作が行われます。これによって、よりランダム性の高い 生成が得られます。

159

第4章 言葉を飛ばす

0.0010

0.0008

〈確率〉

0.0006

0.0004

0.0002

0.0000

<温度>>1

晴れ

<言葉>

雨あい

と確率)

図4-7 〈温度〉の設定で生成

「今日の天気は」の次にくる言葉 確率の凸凹が決まる

.

.

一方これを1以下に設定すると、確率が「尖 り」、つまり確率の高いトークンはより高く、低 いトークンはより低くなり、結果として確率の高 いトークンが選ばれやすくなります。以下では、 K=100のTop-Kサンプリングにおける、 <温度〉の値を変えた例を挙げてみます。

〈温度〉=0.01

短歌を詠むのは、短歌の魅力を最大限に活かし た、新しい短歌の楽しみ方です。 短歌は、短歌 の魅力を最大限に活かした、新しい短歌の楽し み方です。短歌は

短歌を詠むのは、短歌の魅力を最大限に活かし た、新しい短歌の楽しみ方です。 短歌は、短歌 の魅力を最大限に活かした、新しい短歌の楽し み方です。短歌は

160

160

0.6

<温度> <1

<温度> = 1.0

0.200

0.175

0.150

0.125

〈確率

〈確率〉

0.100

0.0

晴れ

雨あい

< 言葉 〉

0.075

0.050

0.025

かになっていくのを感じることができたら、そ ありません。短歌を詠むことで、自分の心が豊 の。しかし、短歌を詠むことは、それだけでは ・短歌を詠むのは、ある意味、修行のようなも

0.000

雨あ

晴れ 曇

<言葉>

げていきたいと思います。 を、短歌という媒体を通して、広く、広く、 広 の表現したいもの、自分の心境を表現できる場 短歌を詠むのは、自分の内面の美しさや、自分 た、新しい表現方法だと感じています。 短歌を詠むのは、短歌の魅力を最大限に活かし

<温度〉=0.5

み方です。短歌は の魅力を最大限に活かした、新しい短歌の楽し

第4章 言葉を飛ばす

た、新しい短歌の楽しみ方です。 短歌は、短歌 ・短歌を詠むのは、短歌の魅力を最大限に活かし

161

れはとても幸せなことで

〈温度〉=1.25

〈温度〉=1.5

短歌を詠むのは、人生の中のほんの日常のことだけではないんです。 詠まれ続けた、歌 を愛し続ける人生だった。私は、そこに生きたのだ。歌は人生を紡いだ。歌は日々を運 んでくる

短歌を詠むのは、いつもどこかへ消え忘れてしまう自分にとって新たな出会いとなりま した。

短歌を詠むのは、そんな私の日々、いや生活の一部だったようです。 私は、30年ほど 前、生まれて初めて短歌という単語を読みました。

短歌を詠むのは、あなた自身が誰かの作品を参考にするという行為の延長にあるのでは ないでしょうか。それは自由意思で始められる短歌やイラストのスキルでも、文学だっ 同様にあります。

短歌を詠むのは、ただ歌に酔わねばなりません。でも歌が素朴であることが一番重要な

162

ことも忘れてはなりません。

<温度〉=20

・短歌を詠むのは、私で大部分を占める私小説だと思う (14冊 3冊)

・短歌を詠むのは、初めてだ(私には、想像力がないので)私には夢だぜ...←そう!や むを得るよ〈rt> 続き・現代まで至った暁に･･･」 今さら言っていてはな･･･

・短歌を詠むのは、歌に恋しちゃうんだから―――。そう云うのでしょう、実は、この"気" で歌っている気合みたいな「場」があることを知っても何なのか気にはなりません? ・短歌を詠むのは、短歌によって誰かを楽にするための目的で始める人が多いもののひと つであるはずだ。本を読むという目的だけを目的とする短歌や創作活動は避けながら人 生を重ねていくことになるだろう。

<温度〉が大変小さく、0に近い場合は貪欲法と同じ結果を得ています。この値を大きく すればするほど、意外性の高い内容が得られる一方で、〈温度〉=2.0では突飛な表現を 超え、文として破綻を迎えているものまでが生成されています。

生成パラメータの設定を変化させることによって、同じ言語モデル、同じ入力、同じ生

163

第4章 言葉を飛ばす

成手法であっても、全く異なる生成が得られることがわかりました。 入力の表す文脈に近 い内容から、飛躍のある内容、また支離滅裂な内容まで得られ、このバランスの調節が生 成において重要であるということがわかります。

「当たり前」な短歌を生成する

では、〈短歌AI> で生成手法やパラメータを変化させると、どんなことが見えてくるか 試してみましょう。 用意するモデルは、ウィキペディア日本語版から抽出した擬似短歌を 学習した短歌AIです。つまり、無味乾燥な語の並びを生成する、私たちの普段使いの言 葉で短歌をつくるモデルとなります。ここでさまざまな設定から生じる生成の変化を見る ことで「日常的な言葉から、どれだけ飛躍しながら短歌をつくっていくか」を観察してみ ることにします。

まずは、先ほどのビームサーチを使って「入力される文脈から飛躍のない言葉」をつな いでいくと、どんなものが生成されるのかを見ていきます。ここで、「見えてくる」「街角 の」「学校に」「パン屋では」「目が醒めて」と異なる五つの初句を用意して、これを入力と する結果を観察してみます。

164

入力 見えてくる

見えてくるその先にある新しい世界へ飛び込んでいく勇気

入力 街角の

入力 学校に

生成 街角の人々の間で評判が悪くなり別れを告げられる

パン屋では

入力目が醒めて

学校に行くのをやめてフリーターあるいは無職あるいは無業

パン屋では客の好みを聞きながら商品を決め袋に詰める

生成 目が醒めて夢を見ているのんびりとのんびりするのがスタイルである

いかがでしょうか。どの生成も、なんだか「当たり前のこと」を歌にしているように感

165

第4章 言葉を飛ばす

じませんか。

「見えてくる」では、何か未来の出来事に対するポジティブな感覚を、素直に表現してい るように読めます。 「学校に」では、「学校を辞めてフリーターになった」ことをただただ 綴っています。「パン屋では」の例も、パン屋で日常繰り返されているであろう出来事を 記述していて、なんだかこれを「短歌である」という前提で読んでいくと、むず痒いよう な感じがします。

それでも少し面白いと感じられるのが、「目が醒めて」でしょうか。 「目が醒めて」も 「夢を見ている」と入力から素直に言葉をつないでいますが、そこからさらに、「のんびり とのんびりするのがスタイルである」と開き直った宣言をしているのに、脱力してしまい ます。一方で、その脱力感が文脈から飛躍のない雰囲気に不思議と合っていると感じるの は、言語モデルに優しすぎる読みでしょうか。

つまらなさへの固執

次に、入力として与える内容に、もう少し文脈を追加した生成を試してみたいと思いま す。

「見えてくる」には「川の向こうに」という言葉を追加してみました。 「川」によって風景

がゆ

166

を与えて、「向こうに」何が見えるのか、この後の流れに少しの期待をうむ言葉を足してい ます。「街角の」では「影がくっきり」を与え、さまざまなものが雑多に存在している街の 一点に視線を集中させています。 「学校に」に対しては「置き忘れてた」と、時間の幅を感 じさせる言葉を置き、 「パン屋では」では「ちょうどその頃」と時間をごく短い間に固定し ています。「目が醒めて」では「匂いを嗅いで」とつないで、嗅覚という人間が持っている 感覚をその内容に付与してみました。

入力見えてくる川の向こうに

生成見えてくる川の向こうにきりぎりす鳴く鹿の声われに母なく

入力 街角の影がくっきり

生成 街角の影がくっきり浮かぶまでしばらくかかる場合も多く

入力 学校に置き忘れてた

学校に置き忘れてた教科書が発見された事件があった

167

第4章 言葉を飛ばす

入力 パン屋ではちょうどその頃

生成パン屋ではちょうどその頃見習いの制服として白の短パン

入力 目が醒めて匂いを嗅いで

生成 目が醒めて匂いを嗅いで恋しくて目を覚ましたの朝だったのだ

「見えてくる川の向こうに」は、けっこう短歌っぽい生成が得られています。 これはひょ っとしたら、学習データ中に含まれる短歌らしい言葉の並び方が、たまたま生成された例 かもしれません。

「街角の影がくっきり」では「浮かぶまで」とつないでいて、それから何が起こるのだろ と期待をさせてくれますが「しばらくかかる場合も多く」と、なんだか煙に巻かれてし まったようなところで終わりを迎えています。

「学校に置き忘れてた」 では、即「教科書が発見された事件」とつないでしまっていて、 こんなふうにいうのも安易かもしれませんが、詩的な飛躍に至らず、現実的なところで表 現が落ち着いてしまった感があり、かつそれが何かの効果を生んでいるかというと、特に 何もないという印象です。

けむ

168

「目が醒めて匂いを嗅いで」では少し頑張っているようにも読めます。しかし、「目を覚 ました」と入力とほぼ同じ内容を生成していて (「醒めて」が「覚ました」へと表現の変わる、凝 ったリフレインかもしれない、と読めなくはないですが)、また「目が醒めた時の恋しさ」をベッ ドから一歩も出ることなく、とても小さなスケールで表現しているように感じます。

ここでは、ウィキペディア日本語版の記事から抽出された擬似短歌を学習した短歌AI の、ビームサーチによる生成の結果を眺めてきました。私たちが日常で目にする一般的な テキストを学習した言語モデルから計算される、確率の高いトークンを並べた短歌生成で は、「型」は守っていても、それを短歌とはどうも呼びづらい、「歌」にはなっていないも のたちがほとんどであるという結果が得られました。

これらの生成をなぞっていくと、「ああ、なんでそんなに素直なのだろう」 と言いたく なってしまうようなものばかりです。もっと言えば、「短歌にできそうなのに、なりそう なのに、絶対にそうはさせない」ような「つまらなさへの固執」すら感じます。この結果 は、私たちが歌をつくるときには「普段の日常生活で使っている言葉から一度離れる必要 がある」という、当たり前のことを教えてくれているのかもしれません。

169

第4章 言葉を飛ばす

「飛んだ」 短歌を生成する

入力 見えてくる

入力 街角の

入力 学校に

では、いま見た例とは逆に「もっと確率の低いトークンを積極的に選んでいく生成」を 試してみると、いったいどのような結果が得られるでしょうか。

次の生成は、Toplpのpを100%、さらに〈温度〉を4と、生成中で低い確率と して計算されるトークンを選びやすい、文脈からの飛躍をとても大きくした設定による短 歌たちです。なお、入力は先ほどの例と同じものとします。

生成 見えてくる確信というアルバム、またはそれに先行したという

生成 街角のオルガン吹きと無オルガン教師という組み合わせとなる

生成学校に向かう途中の少女鉄神像の間を列車が抜けた

170

パン屋では

入力目が醒めて

パン屋では働いているふりをするやってしまった店員もいる

目が醒めて顔を覆ったときの流れ眠りについてきた体

いずれも、けっこう面白い生成になっています。「見えてくる」では「確信というアルバ ム」、「街角の」では「オルガン吹きと無オルガン教師」、「学校に」では「少女鉄神像」と、 不思議な「もの」がここではたくさん生み出されているのがわかります。特に「無オルガ 教師」 や 「少女鉄神像」といった言葉は、私たちの日常から遠く離れた別世界の存在を 表しているようにも感じられます。

さらに、「パン屋では」では「働いているふりをするやってしまった店員」、「目が醒め て」では「顔を覆ったときの流れ」 「眠りについてきた体」といった「もの」を超えた不思 議な組み合わせの表現が得られました。 いずれも私たちの日常的な言葉から遠く離れてい て、これが「短歌らしい」と言えるのかどうかはさておいて、「なにやら普通ではない」 印象を残しています。

171

第4章 言葉を飛ばす

しょう。

続いて、先ほどと同様に、入力により具体的な文脈を与えた場合の生成例を見ていきま

入力 見えてくる川の向こうに

生成 見えてくる川の向こうにある島の海が見えるそこだけが私

入力 街角の影がくっきり

生成 街角の影がくっきりふりまわり照明までも仮想上での

入力 学校に置き忘れてた

学校に置き忘れてた鍵をかけ学校を消し母親はそれ

入力 パン屋ではちょうどその頃

生成パン屋ではちょうどその頃ベーリング山をパン生地猟基地として

入力 目が醒めて匂いを嗅いで

172

生成 目が醒めて匂いを嗅いでまだ枕の沼にかかる無理があるだろうか

「そこだけが私」 「くっきりふりまわり」 「学校を消し」といった表現は、これもまた日常 的な言葉から離れた表現である上、少し短歌っぽいような雰囲気を感じます。これまでの 生成より、ぐっと「らしく」なったと言えばよいでしょうか。 これは、このモデルが「ほ んとうの短歌」を学習していないことをふまえると、不思議な結果にも思えてきます。

しかし、「ベーリング山をパン生地猟基地として」「まだ枕の沼にかかる無理があるだろ うか」といった生成は、かなり「飛んだ」 表現になっています。 これらはいかにもランダ ムな結果と言いますか、 その文字列の意味するところが非常に掴みにくく、 いずれもそれ までの内容からは想像のつかない意外性を生んでいますが、 「それだけ」と言ってしまえ ばそれだけです。もっともそれは、読み手である私の能力によるところかもしれません が、「意味がわからない」と感じる方は決して少なくないでしょう。

Top-pサンプリングと〈温度〉の値をなるべく飛躍が生まれるように設定した下で の、ウィキペディア日本語版から抽出した擬似短歌を学習した短歌AIの生成を見てきま した。私たちが日常で目にするような一般的なテキストを学習した言語モデルによって計 算される確率の低いトークンまで取りに行く、飛躍を生むような生成を行った場合では、

173

第4章 言葉を飛ばす

確かに意外性のある内容が多く得られることがわかりました。なかには「短歌っぽい」と 感じられるものもあり、日常の言葉から離れることで「らしさ」を生むことができると言 えそうです。

一方で、ここで得られた短歌たちは、どれも飛躍の過ぎる、 「飛んだ」ものばかりでし た。これまでの結果が示しているのは、先ほどの「当たり前」な言葉の並びと今回の「飛 んだ」 文字列の間に、私たち人間がつくりたい 「ほんとうの短歌」が存在しているという ことではないでしょうか。

ちょうどよいところへ短歌を着地させる

ここまでで見えてきたのは、言葉を一つ一つ、つなげながら短歌をつくっていくとき、 文脈からの飛躍がなさすぎても、ありすぎても、あまりいい結果は得られないということ でした。つまり、この「言葉の飛躍」のバランスを探っていって、自分がいいと思えると ころに短歌を着地させる必要がある、と言えそうです。

このバランスを見つけるためには、あえて飛躍のない語を考えてみたり、その逆にジャ ンプをさせる、といったことを重ねていく必要があるでしょう。そこで、毎回の生成ごと にパラメータを調節しながら、 「ちょうどよいところへ着地する」 短歌が得られないか試

174

してみます。

入力 見えてくる

まず、先ほども取り上げた「見えてくる」で試してみます。 「見えてくる」に続く言葉 は、「何が見えてきているのか」という想像を誘う内容になるでしょう。ここには、少し意 外性が欲しいところです。 そこで、Top-p=100%、〈温度〉=20でランダム性 の高い生成を行ってみます。

生成(Toplp=100%、 〈温度〉=2.0)

見えてくる空間的な法則とそれに類するアイディアや技術

見えてくる現実と空想境界線が崩れていくさまが美し

見えてくる世界と自分の立ち位置を知っておくのは大事なこと 見えてくる街角の貴婦人達女になれば蝶結び

見えてくる未来へのパスワールドの案内役になってくださる

見えてくる喜びのためあくびから生まれくる実を感謝しながら

飛躍のある、複数の方向性 ...すような結果が得られました。 特に、「喜びのためあくび

175

第4章 言葉を飛ばす

から」という表現は、見えたのは何か具体的なものではなく「喜び」だったという小さな 驚き、またそれが「あくび」へとつながるちょうどいい飛躍を持っているように感じます。 ここでこの「喜びのためあくびから」を採用して、今度は少し飛躍を抑えた生成を行って みます。Toplp=80%、〈温度〉=1.0としてみましょう。

入力 見えてくる喜びのためあくびから

生成(Top-p=80%、〈温度〉=1.0)

見えてくる喜びのためあくびから涙がこぼれ涙のなかの

見えてくる喜びのためあくびから生まれてきたる喜びのため 見えてくる喜びのためあくびから生まれるものでもないだろうに 見えてくる喜びのためあくびから涙ぐむまで耐え忍ぶのが

確かに、これまでの内容をなめらかにつなぐようなものが生成されました。 しかし、S ずれも平凡な表現ばかりで、つまらないです。 そこで、「見えてくる喜びのためあくびから 涙がこぼれ」までを新たな入力として、ここからの飛躍を生んでくれることを期待して、 Top_p=100%、〈温度〉=2・5として生成を行ってみます。

176

入力見えてくる喜びのためあくびから涙がこぼれ

|生成(Toplp=100%、〈温度〉=2.5)

見えてくる喜びのためあくびから涙がこぼれ花束になる 見えてくる喜びのためあくびから涙がこぼれ果てしない問い 見えてくる喜びのためあくびから涙がこぼれ下がる感知機 見えてくる喜びのためあくびから涙がこぼれやがて雪へと 見えてくる喜びのためあくびから涙がこぼれ涙をなぐる

いかがでしょう。「涙がこぼれ花束になる」「涙がこぼれやがて雪へと」といった表現は、 不思議な余韻を残してくれているように感じます。

「涙をなぐる」といった表現は日常から浮遊したような言葉の並びですが、全くのでたら とも感じられず、意味ありげです。 これまでにつくってきた内容からの着地としては、 許容しても良いような気がしてきます。

他の入力もこれまでの過程と同様にして、途中途中でパラメータを調節しながら短歌を 「着地」させていきましょう。

177

第4章 言葉を飛ばす

入力 街角の

入力 学校に

生成 街角の女の中の男性として生まれたが生まれすぎた身

生成学校に向かう自転車人々を描写した数百点の白

入力 パン屋では

生成 パン屋では昔と同じ形にてもう一度目を開けられる? また

入力 目が醒めて

生成 目が醒めて雨音を夢で聞いてから夢を見ないで寝るのであった

「当たり前」 短歌や「飛んだ」 短歌よりはより「らしい」 生成ができている、と言っても よいのではないでしょうか。

文脈を追加した入力で、生成パラメータを変化させながらの「着地」を試みてみます。

178

入力 見えてくる川の向こうに

見えてくる川の向こうに向かう風あるいは鳥が語りうるごと

街角の影がくっきりふりかかる太陽からの冷たさに耐え

入力 街角の影がくっきり

入力 学校に置き忘れてた

生成学校に置き忘れてた緑色の小さな石が教師になって

パン屋ではちょうどその頃

生成パン屋ではちょうどその頃老鳥に卵を産ます場所が少ない

入力目が醒めて匂いを嗅いで

生成 目が醒めて匂いを嗅いで好きだといい猫になったあとなんとなく死ぬ

179

第4章 言葉を飛ばす

「見えてくる川の向こうに･･････」では、「あるいは鳥が語りうるごと」と、これまでにない 淡い表現を得ることができたように感じます。 「街角の影がくっきり・・・・・・」 では、「ふりか かる」という動詞、また「街角」から「太陽」へとスケールを大きく変える表現に「ちょ うどいい飛躍」を感じませんか。

「学校に置き忘れてた･･････」 では、「小さな石」へと一度浮遊したモチーフが 「教師」 と 学校に関連する言葉にかえってきています。 「パン屋ではちょうどその頃…･････」 では、「老 鳥」がパン屋に登場しています。「卵を産ます場所」というのも、想像を誘う表現です。 またはっきりとした飛躍として、「目が醒めて匂いを嗅いで……」 での 「好き」から「猫に なっ」て「死ぬ」に至るまでのジャンプの連続が挙げられるでしょう。

ここでは、短歌を生成する過程でパラメータを調整し、表現を選び取っていきながらの 短歌生成を試みました。 「ちょうどいい着地点」を探ることで、時には大胆に、また時には 遠慮がちに言葉をつないで、「当たり前」 や 「飛んだ」 短歌とは違う生成を得ることができ ました。この「言葉の飛躍の調整」は、人間による作歌でも、似たように行われる行為で はないでしょうか。

次の「言葉」をつなぐということ

180

ここまで、言語モデルが言葉を一つ一つつないで文字列を生成していく仕組み、その難 しさと工夫について触れました。その後、生成パラメータによる言葉の飛躍の調整を眺め、 そこから実際に短歌をつくってみました。日常の言葉から離れることで、より「らしく」 なること、かといって離れすぎても良い歌には辿り着けないことを見ました。言葉の飛躍 の具合をバランスさせながら、短歌を着地させることを試み、最後には実際に「ちょうど いい」と感じられる言葉のつなぎを得ることができたのではないかと思います。私たちが 実際に短歌をつくる時にも、この飛躍のバランスを探りながら作歌するのが大事と言える でしょう。

しかし、ここで一つ考えたいことがあります。 短歌には、決して頭から歌をつくらなけ ればならないというルールはありません。 下の句を先に思いついてから上の句を考えると いった逆さまの順番によるつくり方もあれば、途中の語を置き換えたり、またある「言葉」 を種にして前後に言葉を並べていったり、さらにはそれらを組み合わせるといった、より 複雑な過程を経ながら「ほんとうの短歌」はつくられているのではないでしょうか。 また、序章でも「『言葉』だけを学習するということ」として触れた通り、言語モデルは 言葉が指し示す実世界の事象やそこから受ける感覚と、文字という記号の関連を完全に理 解しているわけではありません。

181

第4章 言葉を飛ばす

一方、この世界を構成しているあらゆる要素について考えを巡らし、またそれを肌で感 じる能力を持っている私たちは、記号では表し切ることのできない情報すべてを投入して 短歌をつくることができる、と言えるでしょう。そう思うと、言葉で表すことのできない ものをあえて言葉にしていく行為の貴重さすら感じます。

私たち人間と〈短歌AI〉にはそんな違いもありますが、それでも「いま書きかけている 言葉から、その先どこへでも飛んでいける」ということを頭に置いておくだけで、これま でにない〈短歌〉 や、それを表現したいと感じる〈あなた〉に出会うきっかけを掴むこと ができるでしょう。

この章から学ぶ「短歌入門」

書きかけの短歌を用意する。

●以下の三つの方法で、〈書きかけの短歌〉の続きをつくる。

①何も考えず思いつくままに言葉をつないで、続きをつくる。

②一語一語とにかく飛躍させながら、続きをつくる。

③自分が心地いいと感じる飛躍の具合で、続きをつくる。

●それぞれの短歌について評を書く。

182

第5章 うまく付き合う

「勝ち負け」しかないのだろうか

「AIと人間」という話題になると、「勝ち負け」について議論されることが多いように感

じます。2017年には世界トップ棋士に勝利したコンピュータ囲碁プログラムの「Al phaGo(アルファ碁)」が大きな注目を浴びましたが、 これはまさしく勝負の世界の出 来事で、囲碁において機械が人に勝てるわけがない、と考えていた当時の人々の認識をひ っくり返した事件と言えます。

さらにそこから遡って1997年には、IBMの開発するスーパーコンピュータ「ディ ープブルー」が世界チェスチャンピオンを打ち負かし、これは世界で初めてチェスチャン ピオンに勝利したコンピュータとして記録されています。2011年にも、同じくIBM が開発した質問応答システム「ワトソン」が、知識が問われるクイズの世界で人間に勝利 します。

このように、人間対AIの歴史は古く、いずれも大きな驚きをもって記憶に刻まれてお り、あらゆる世代でこの「勝ち負け」という価値観は受け継がれていることでしょう。

短歌と同じく定型詩の一つである「俳句」 でも、人とAIの対決が行われています。2 018年に放送されたNHK 「超絶凄ワザ!』という番組で、北海道大学が研究を進め

184

ている俳句生成AI「AI一茶くん」が、 風景画像をお題に俳句をつくるという企画で人 と対決しました。結果は「惨敗」であったと開発者は記していますが、 ここでも 「勝ち負 け」という文脈でAIが取り上げられています。AIの現在の性能を測り、また人との差 異を見るためにも、競争をする、といったフォーマットは確かにとてもわかりやすい構図 だと感じます。

私たちの〈短歌AI〉についても、これを初めて耳にする方からは「ほんとうに良い歌 をつくれるのか」「人の方がいいに決まっている」といった声がよく上がります。しかし、 短歌には囲碁のような明確な「勝ち負け」のルールはありません。 前にも述べたように、 短歌は何か一つの絶対的な「良さ」を他者と競争する文化ではないでしょう。つまり、短 歌においては「勝ち負け」という視点はむしろ設定しにくく、それとは異なる関係性の構 築へと想像を広げるのが重要ではないかと考えます。

だからと言って私は「短歌の作歌にもテクノロジーが積極的に応用されるべき」という 主張を持っていません。しかし、例えばもしあなたが短歌をつくるとき、「あれ、これ、 いつか見た誰かの作品に似ているかも?」と不安を覚え、検索サイトを開く可能性はない でしょうか。また、自作の歌をインターネットに公開し、会ったことも見たこともない、 匿名の人たちによって即座に評価されて、喜んだり、あるいは時に傷ついたりといった経

85

185

第5章 うまく付き合う

験をするかもしれません。こういったことも、いつかの過去時点ではあり得なかった「テ クノロジーの進化と短歌」 に関連する出来事として捉えることができるでしょう。つま り、何らかのテクノロジーの影響を受けながら短歌をつくるという状況は、すでに始まっ て久しいとも言えるのです。

テクノロジーは、私たちの生活に深く入り込み続けていて、私たちはそれをあえて意識 することなく毎日を過ごしています。 ChatGPTに代表されるように、言語モデルが 日常生活のなかで提供されるサービスとして扱える状況は、 すでにもう始まっています。 いつか、いまAIと呼ばれるテクノロジーが水のようにふつうに日々の生活に浸透してい るかもしれません。そんななかで「短歌をつくる」ということ、もっと言えば「人間であ 私としての短歌をつくる」ということについて、一度考えてみたいと思います。

〈短歌AI〉の取り組みでは、実際に短歌を生成するAIをつくってその成り立ちについ て考え、挙動を観察し、また歌人の方々に触れてもらうことで、「勝ち負け」にこだわら ない、「多様な付き合い方」の可能性が見えてきました。 それらを、この章でまとめてみ ようと思います。

壁打ち相手になってくれたら

180

これまで文化部とともに行った歌人への取材では、AIと結べるかもしれない新たな 「付き合い方」の可能性を、実作者の目線から考える機会を得ています。俵万智さんへの取 材では、短歌AIが高速に大量の短歌を生成できるという点に驚かれ、一つの「付き合い 方」を提示するような話題になりました。それは「壁打ち相手としてはいいかもしれない」 という言葉です。 永田和宏さんへの取材でも、「例えば上の句で筆が止まっている時に、 AIに提案してもらった言葉を発展させて下の句を付けるという使い方は、認めてもいい のかもしれない」と、俵さん同様、壁打ち相手としてのAIの可能性が指摘されました。 これはどういうことでしょうか。例えばあなたにはいま、どうしても完成しない書きか けの歌があって、悩んでいるとします。 そんな時に、AIにその書きかけの歌を入力し、 続く内容を大量に生成させます。AIですから、何度お願いしても、いつお願いしても、 嫌な顔をせず淡々と生成することが可能でしょう。 そこで得られる大量の歌をあなたは見 ながら、ああでもないこうでもないと考えて、「ほんとうに詠いたかった言葉」を探せるの ではないか、ということです。

うた

試しにやってみましょう。例えば私が、「言葉だけを学習している言語モデル」に関す る歌をつくってみようと考えているとします。 上の句......これがいい上の句かはよくわか りませんが、「文字だけを辿った先にみえたのは」 こんな上の句を考えました。何が見えた

187

第5章 うまく付き合う

ひまわり

生成(下の句)

のでしょうか。例えば「紫に咲く向日葵の庭」とか、現実世界にはあり得ないような風景 が続けば、言語モデルらしい気もします(あとで調べたところ、紫の向日葵というのは実際にある そうです)。しかし、この「見えたもの」はなんでもよい、といえば無責任ですが、ここに はとても自由な想像の幅があるでしょう。 そこで、言語モデルにたくさんの歌を生成させ ながら、壁打ち相手になってもらいましょう。

なお、ここで利用する言語モデルは、ウィキペディア日本語版から抽出した擬似短歌を 学習した短歌AIです。 第4章で見たように、さまざまにパラメータを変化させながらの 生成を試しています。

入力文字だけを辿った先にみえたのは (上の句)

文字だけを辿った先にみえたのは神秘の森の一部であった

文字だけを辿った先にみえたのは仮想世界のほんとうの城

文字だけを辿った先にみえたのは夢と不思議にうまれた都々逸

文字だけを辿った先にみえたのは銀河鉄道本線の上

文字だけを辿った先にみえたのは恐ろしい過去再生の淵

99

188

文字だけを辿った先にみえたのは魔術師らしき影が輝く 文字だけを辿った先にみえたのは神のごとくの神殿であり 文字だけを辿った先にみえたのは廃墟と化した駅ビルだった 文字だけを辿った先にみえたのは神秘の島が広がっていた 文字だけを辿った先にみえたのは魔術師ギルド秘密事務局 文字だけを辿った先にみえたのは惑星サイズの電子レンジ 文字だけを辿った先にみえたのは銀河の落下襲来だった 文字だけを辿った先にみえたのは深い森の色を染める草 文字だけを辿った先にみえたのは神秘の部屋の鏡であった 文字だけを辿った先にみえたのは夢のまっかな眠る黄海 文字だけを辿った先にみえたのは青っぽい土の中に白髪 文字だけを辿った先にみえたのは仮想世界エルパコだったが

いかがでしょうか。「銀河鉄道本線の上」 「魔術師ギルド秘密事務局」 「惑星サイズの電子 レンジ」「青っぽい土の中に白髪」 ••••••、 さまざまなイメージが一挙に提示されました。 こ れらこそ、「文字だけを辿った先にみえた」ものという気もしてきますが......さらに、生成

69

189

第5章 うまく付き合う

を続けてみましょう。

文字だけを辿った先にみえたのはもう限界の空間だった 文字だけを辿った先にみえたのは遠い過去への約束だった 文字だけを辿った先にみえたのは恐怖だったが現実だった 文字だけを辿った先にみえたのはもう今もなく雨のみの夜

文字だけを辿った先にみえたのはもう今のわたしたちではなく

「もう限界の空間」 「恐怖だったが現実」「もう今のわたしたちではなく」 ••••••、先ほどの ような具体的な「もの」ではなく、もう少し概念的な内容が出てきました。

「遠い過去への約束だった」 はなかでも目を引きます。確かに、言語モデルが学んでいる のは、私たちが過去に蓄積してきたテキストデータです。 その過去から導かれる内容は、 「過去への約束」という表現を用いても良いのかもしれません。

そこで、「文字だけを辿った先にみえたのは過去につくった」と続くようにしてみまし た。過去のテキストデータでつくった、私たちの世界そのもの、といった内容の短歌はあ りえるかも、と想像しながら、続きを考えていきましょう。 最初に頭の中にあった「紫に

190

咲く向日葵の庭」から、ずいぶん遠くへ来たように感じます。

ここからまた、言語モデルと壁打ちをしてみます。

文字だけを辿った先にみえたのは過去につくった安っぽい城 文字だけを辿った先にみえたのは過去につくった歴史であった 文字だけを辿った先にみえたのは過去につくった世界であった 文字だけを辿った先にみえたのは過去につくった架空の政府 文字だけを辿った先にみえたのは過去につくった罪や罰たち 文字だけを辿った先にみえたのは過去につくった過去の自分に 文字だけを辿った先にみえたのは過去につくったつくり笑顔や 文字だけを辿った先にみえたのは過去につくったダムの正体 文字だけを辿った先にみえたのは過去につくった罪の無い愛 文字だけを辿った先にみえたのは過去につくった自分の理想 文字だけを辿った先にみえたのは過去につくった最後の願い 文字だけを辿った先にみえたのは過去につくったゲームデザイン

文字だけを辿った先にみえたのは過去につくった自分の名前

191

161

第5章 うまく付き合う

文字だけを辿った先にみえたのは過去につくった自分の手と影

「つくり笑顔や」 「罪の無い愛」 「最後の願い」という表現は、生成する前に想像していた 「私たちの世界そのもの」と距離の遠い、私の頭になかった言葉です。

ここで私は「自分の手と影」という表現に引っかかりました。 「身体」について描写して いるのに意外な感じがしたからでしょうか。 しかしよく考えてみると、学習データとなる テキストデータは、そのほとんどが人の手によって書かれた入力された文字列であると 気づきます。そこから、たくさんの人の手の痕跡、といったイメージを結ぶのはどうかと 考えました。そしてできたのが、次の歌です。

文字だけを辿った先にみえたのは指紋の指紋 あなたのもある

私たちの残した言葉のあつまりが言語モデルをつくっていて、そのなかにはこの歌に触 れるあなたのものもある、ということを、体の残す跡=指紋と結びつけて表した歌になり ました。

最初につくった「文字だけを辿った先にみえたのは紫に咲く向日葵の庭」 とどちらがい

192

私をうつす鏡になったら

いか、についてはここでは問題にしません。 ここで重要となるのは、このようにして言語 モデルと「壁打ち相手」として付き合うことで、私の最初に想像していたものから、遠く 離れた印象を持つ歌に行き着くことができたという点です。

永田さんは取材で、「歌をつくる前はこう思っていたけど、歌をつくるプロセスでこう も思ったんだという自分の発見があって。これはすごく大事なことだと言い続けてきた。 そうした言葉をAIが見つけてくれようと自分で見つけようと、本質は変わらないのかも しれない」と発言しています。

これは、創作において手を動かす前に考えていたことと最終的な作品との間に生まれる 差異を許容することの重要性を語ったものだと思います。 頭だけではなく、手だけでもな く、別の知能との対話を通して、歌をつくる前の〈私〉とつくった後の〈私〉とで違いを 生んでいく、そんな「付き合い方」 の可能性を感じます。

「鏡」は、私たちが社会的な生活を送る上で欠かせない道具です。 毎朝、学校や会社へ行 く前に、鏡を覗くという人がほとんどでしょう。寝癖はないか、顔色は悪くないか、昨日 飲みすぎたので浮腫んでいるなと、他人と相対してやり取りをする前に、いまの自分

193

第5章 うまく付き合う

がどのような姿なのかを確認する作業が、 そこでは行われます。 そして、鏡は正直です。 例えば「寝癖があることを伝えたら、気分を悪くするかもしれない」といった気遣いや付 度といったものは当然なく、いつでもありのままのあなたをうつし出してくれるところに、 ほかには代え難い価値があると言えるでしょう。

一方で、自分の普段の言葉づかいがいったいどのように見えるのか、それを客観的に把 握するのは、そう簡単な作業とは言えません。私たちは毎日の生活の中で無意識のうちに たくさんの言葉を扱い、特に音声によるやり取りでは、それは口から発せられた側から消 えてしまいます。

自分でつくる短歌を考えれば、ある程度意識的に言葉を置いていて、それがどんなふう に見えるのか、伝わるのかを判断している瞬間は多いでしょう。しかしそれでも、ある歌 をつくった時の苦労や、 そこで扱っている気に入った言葉の使い方など、思い入れが邪魔 をして、なかなか客観的に自分の歌を見るのは難しいかもしれません。

先ほど、人間である自分が考えている上の句から、言語モデルに下の句を付けさせる、 といったことを試してみましたが、これは私の意図や人柄を知らない知性が続きを書いて いる、とも捉えることができます。 これを応用することで、私が書いた歌を客観的に眺め る鏡のような道具にする、そんな可能性もあるように思います。

194

私は以前、「バニラ・シークエンス」という30首からなる連作をつくりました。 この連 作ではウィキペディア日本語版を学習した短歌生成モデル―つまりは無個性で一般的な 言葉を用いて短歌を生成する装置を用意して、該当部分を明記した上で、一部そのモデル 生成によって得られた歌を収録するといったことをしています。

寂しさは言い澱みなくいっていい思い出すまで4人通過し 寂しさは言い澱みなくいっていい気持ちやましく飾られている

毒殺をはかられたことのない身体二つ並べて豆腐をつつく 毒殺をはかられたことのない身体余生を送ることを望んで

咳をする音の反射を聞くまでは水平だった駐車場の 2 咳をする音の反射を聞くまでは音楽的に注意を払う

それぞれ、最初にあるのが私自身がつくった歌で、後に続くのが下の句をAIによって 生成させた歌になっています。ここで私の歌とAIの歌を見比べてみると、なんだかシリ

195

第5章 うまく付き合う

アスになりすぎている格好つけている、と言ってもいいかもしれません) 私の歌に対して、AI の生成はそれを茶化している、はたまたツッコミを入れているようにも読めてきます。ま

〈私〉がなぜAIのような下の句ではなく、〈私〉が書いた下の句をつくったのか、と いったことを考えるきっかけを提供しているようです。つまり、AIの生成と自分の歌と を見比べることで、より〈私〉がどんな人間であるのか見えてくる、そんな連作になって います。

こだわ

〈私〉には私なりの拘りもあれば、また自分を狭い世界に縛る思い込みのようなものもき っとあるでしょう。それを解放させて、自分をより広い言葉の世界の中に位置づける。 A Iは、自分の歌、そしてそれをつくった〈私〉がいまどこにいてどのような姿をしている のかをうつす「鏡」の役割を果たすのではないかと考えます。

似ている歌を教えてくれたら

先ほども例に挙げましたが、短歌をつくっているときに「この歌、どこかで見たかもし れないな」と思うことがあるかもしれません。 いい歌ができた気がするが、どうもそれに しては簡単にできすぎた。そんな時、つい誰かの表現を借りてきてしまったのではないか と不安になるものです。

196

うごめ

これは第3章の最後で述べた「忘れられなさ」にも通じる内容ですが、私たちはいつか どこかで目にした歌の表現に刺激され、それが無意識的に頭に残っている、ということが きっとあるでしょう。そんな時、頭の中にこれまで目にした歌がすべて入っていれば、と まではいかなくとも、ひょっとしたらあの歌集に収められていた一首かもしれない、と、 付箋のついた本をすぐ手にとれれば良いですが、そう簡単にいかないこともあります。

むしろ、どこだったかわからない、というところまで「頭の中の短歌の海」が広ければ いいな、とさえ思えてもきます。この世界には私を掴んだ歌が大量に存在していて、そん な蠢きの中に自分があり、またそこへ一つの歌を足していく、そしてそれがどこかの誰か また新たに掴む…といった循環に身を置いているのが私たちではないでしょうか。 そんな渦中にいる私たちが、いつかどこかで出会った「あの歌」を見つけ出すのは、そ 容易ではありません。一方、第1章で紹介した 「朝日歌壇ライブラリ」では、文ベクト ルによって計算される文の類似度を使って、入力された言葉と近い意味を持つ短歌を見つ けることができます。このような文の類似による検索を用いることで、例えばいまあなた がつくっている短歌と似たものがないか探すことも可能でしょう。それは文字列の一致を 超えた意味の類似によって計算されるものなので、語彙的な表現を超えたアイデアの類似 をも、見つけることができるかもしれません。

197

第5章 うまく付き合う

そのためには、過去につくられた歌をすべて集めたデータベースのようなものが必要で す。例えば俳句では、現代俳句協会の運営する 「現代俳句データベース」が存在します。 これは「明治以降の広い意味での秀句、歴史的に価値のある俳句作品を網羅することを目 指してつくられたもので、現代俳句協会受賞作品全句、現代俳句協会歴代会長作品、歴 代俳句大賞作品、現・現代俳句協会役員作品、IT部員の推薦句などを収録しているのだ そうです。

しかし、短歌には現状そういったものはありません。また、この世の中に存在するあら ゆる歌を電子化して一元的に管理することは、技術的にもモラルの面でも課題がありそう です。それでも、例えば自分がこれまでに触れた歌や、過去につくった歌を記録してくれ るような仕組みがあれば、どこかで出会って忘れられずにいた歌が無意識に浮かんで、そ の歌と似た表現をうっかりしてしまう、といったことを避けることができるでしょう。こ こで言葉の意味を計算するAIが、その力を発揮してくれます。

例えばこれまでに触れて気になった歌をテキストデータ化するなどして、あなただけの 短歌データセットを持っておくのはいい方法でしょう。 「言葉が計算できる」 いまの世界に おいて、それはまるで歌集に付箋を貼るような、自然な行為になるかもしれません。

198

人ではないあたたかさ

人とAIを対比して考える際に、「人はあたたかいものである」と語られがちな気がし ます。しかしこれは、常に正しい命題でしょうか。 「冷たい態度」といった言葉があるよ うに、他者に冷たくできるのもまた人間です。さらには、あたたかさを超えて熱くなって しまうと、これもまた人間関係に悪い影響をもたらすきっかけになり得るでしょう。

翻って、「AIは人ではありません」。当たり前すぎる、つまらない文章です。 しかし、 「人ではありません。なのであたたかいのです」と続いたら、どうでしょうか。一般的には 人間は血の通ったあたたかいものとされているので、少しびっくりしませんか。しかし、 ここではAIの「人ではないあたたかさ」について考えたいと思います。

これは「AIは人が持っているような冷たさを持っていない」 ということです。 先ほど の「壁打ち相手」の例では、短歌AIにいわば案出しをお願いしながら自分の歌をつくる ことに取り組みました。AIは、こちらが何度お願いしても、疲れることなく、それがた とえ真夜中であろうと、嫌な顔せず、結果を返してくれます。人間の「短歌の友人」では、 なかなかそういう訳にはいかないでしょう。

また、AI相手なら、いくらでもダメ出しをすることができます。どんなに細かいとこ ろを指摘しようが、うんともすんとも言わず、淡々と生成を続けるのが言語モデルです。

ייד

第5章 うまく付き合う

はつなつ

はつなつ

ですので、例えば短歌の教室や創作の授業で、あえて「悪い例」を生成させる装置として、

教育的な利用が可能かもしれません。これは、AIならではの度量の広さ、 「あたたかさ」 があるからこそできる行為ではないでしょうか。

俵万智さんと開催した「恋の歌会」では、短歌AIの生成する歌を俵さんに添削しても らい、会場で共有するといったことをしました。

はつなつ

歌会は初夏に募集が始まったこともあって、「初夏の光とともにやってくる」という上の 句に対する下の句を、参加者から募るとともに、短歌AIでも生成させてみました。

初夏の光とともにやってくる午後の地下鉄ふくらんでゆく

これが、短歌AIの生成した下の句です。 「地下鉄がふくらんでゆく」 という表現は面 白いものがありますが、これを俵さんは次のように添削しました。

初夏の光とともにやってくる 山手線がふくらんでゆく

「地下鉄」を「山手線」と、具体的な路線名を与えながら地上に上げてあげることで、ま

「ぶしい「光」をより実感の伴うものにしています。

第1章でも見たように、歌会では「恋」というお題で題詠に対する生成も行いました。

あたらしい恋の思いによるとこの恋にはスマホが存在しない

これを俵さんは、次のように添削します。

あたらしい恋の定義によるとこの恋にはスマホが存在しない

「思い」というぼんやりとした言葉に、「定義」とはっきりした形を与えることで、この歌 がより明確に感じられます。

なお、このイベントは会場に加えてオンラインでも配信し、多くの人が見届ける中で開 かれた歌会でした。 一般的には、そんな大勢の前で添削を受けるというのは、する方もさ れる方も、少し躊躇してしまうかもしれません。でも、そこは器の大きいAIです。 いく でも、何を言っても動揺しないAIだからこそ、表現そのものに対する率直な指摘が可 能となり、そのさまを私たちは見ることで、より純粋に短歌をつくることについて考える

201

第5章 うまく付き合う

時間を過ごせたのかもしれません。

高度なAIが日常にある「いま」

本書ではなるべく流行にとらわれず普遍性のある話題を提供したい。そう思いつつも、 やはりこの本を書いている「いま」は、AIと人について考えるにはとても面白い時代だ と感じます。ChatGPTの登場によって、誰もが高度なAIを触れるようになりまし た。これは、過去を振り返ってみてもなかった出来事ではないでしょうか。 ここでは、c hatGPTを用いた私たちの最も新しい取り組みとして、歌人の木下龍也氏をお迎えし て開いたイベントについて書こうと思います。

2024年の4月に、朝日新聞社では「木下龍也さん×AI短歌 あなたのために詠む 短歌」というイベントを開催しました。 ゲストの木下龍也さんは、個人の想い ( お題)を受 けて短歌をつくる「あなたのための短歌」に取り組まれています。 イベントでも参加者か お題を募って、それに対する木下さん自身の歌、そして「あなたのための短歌」を学習 したAIの生成をみるということをしました。

AIは、ChatGPTでも使われているGPT-3・5という言語モデルに対して、 100個の「お題」と「それに応える短歌」のペアを追加で学習することで用意したもの

202

う。

木下さんの歌

です。その生成には木下さん自身も驚かれ、100件というとても少ないデータから「ら しい」結果を生成する、最近の言語モデルの性能の高さを改めて知ることとなりました。 さて、実際のお題と、それに対する木下さんの歌、それからAIの生成を見てみましょ

昨年の春、図鑑編集者になりました。 仕事は楽しく充実していますが、まだ何者にもな れていない自分が悔しくて、焦っています。

自分にしか世に出せない本とは何か、私らしい仕事とは何かを悩む日々を、少しだけ見 ていてくれる短歌を下さい。

青い実が赤く染まってゆくようにらしさはいずれきみに追いつく

あなたのための短歌」を学習したモデル)

何者も調べたことのない言葉とても素朴で遠くから来る

(神奈川県・20代)

203

第5章 うまく付き合う

生成「あなたのための短歌」を学習していないモデル)

未来を見つめ

自分を愛し

表現の道を

輝く星

その一つに

私もなろう

「何者にもなれていない自分への焦り」を寄せたお題に対して、木下さんはその人らしさ が現れることを実が熟するさまになぞらえて歌にしています。 「あなたのための短歌」を学 習したAIの生成も、お題に対する答えが時間をかけてやってくることを、 図鑑を連想さ せる「調べる」という行為で表しています。 木下さんのデータを学習することで、ただ綺 麗な言葉や正論を並べただけのアドバイスではなく、「一人の人へ向けた短歌」という形 で生成ができているように見えます。 データを学習していない素のモデルと比べてみても、

204

その違いは明白でしょう。

イベントでは、生成された歌と見比べながら木下さんの短歌や作歌の過程に迫るととも に、実際にお題をいただいた方からの感想もいただくことができました。AIが誰かに向 けた歌を生成して、その受け手が生の感想を伝えるという点でも、新しい取り組みとなり ました。

木下さんとは、イベント前の打ち合わせの段階でも短歌生成のデモンストレーションを お見せする機会がありました。 当初はその性能に 「怖い」と率直な感想を述べられました が、AIができること・できないことを知るにつれてその印象は変化し、イベント当日に は健気に短歌を生成するAIに「真面目でかわいい」というコメントをいただきました。 お題を送ってくださった参加者の方も同様に、AIの歌からは「実感を感じないもの」 かと当初は思っていたが、実際に学習して生成するさまを見て「愛らしさ」を感じ、「親近 「感も湧いた」との感想を寄せてくださいました。これは、AIに実際に触れその挙動を知 ることで、人とAIの関係性が変化するという例を示しているでしょう。

皆さんの手元にもAIが「ある」時代が訪れています。 ひとまず、手元のそれに触れて みる。いま、皆さんはAIに対して恐れや不安を感じているかもしれませんし、逆に大き な期待を抱いているかもしれません。しかし、それらの感情は実際のAIとのやり取りの

205

第5章 うまく付き合う

中で、変化していくでしょう。そこから新たな課題を見つけたり、また新たな関係性を構 築したり、あなただけのAI付き合いの可能性が広がっていくかもしれません。

付き合い方には気をつけて

AIと創作に関する話題には、議論がつきものです。 特に、著作権に対する考え方は、 AIをつくる人、AIを利用する人、そしてAIの学習データとなる内容を生み出した人、 つまりは創作に関わるほとんどすべての人に関係する、非常に大事な問題です。 これにつ いては今まさに議論と検討が進んでいるところで、この本が読まれている頃にいったいど んな状況にあるかはわかりませんが、ひとまず現状を整理します。

まず、AIを開発・学習する段階と、生成・利用する段階では著作物の利用行為が異な り、関係する著作権法の条文も異なります。さらに、AIが生成したものが著作物に当た るか、といったことも別の問題として考える必要があります。

著作物を収集・複製し、学習データを作成すること、またデータを学習に利用して、A Ⅰ(学習済みモデル)を開発することは、いわゆる柔軟な権利制限規定 (著作権法第30条の4) によって、原則として著作権者の許諾なく行うことが可能です。ただし、「著作権者の利益 を不当に害することとなる場合」などは原則通り許諾が必要となります。

206

また、AIを利用して生成する段階については、人がAIを利用せずに創作する場合と 同様に判断されます。 生成物に既存の著作物との類似性が認められる場合、その利用は避 ける、著作権者の許諾を取る、全く異なる著作物になるように大きく手を加える、といっ たことを考える必要が生じます。

AI生成物の著作権については、AIが自律的に生成したものは該当しないとする一方 で、AIを道具として人が創作的意図と創作的寄与を持ってつくったと認められるものに 関しては、該当すると考えられます。

これらの法とそれにまつわる議論については、AIと創作に関わる人間として、常に注 意していく必要があるでしょう。

そして、法律の話とは別に、例えば短歌の投稿欄には明確にAIの利用を禁じたものも あります。この本では「いい短歌をつくるAIを利用して自動的に作歌を行う」ことの推 そもそもしていませんが、それもまた一つの「付き合い方」でしょう。現在は短歌は ある一人の人間の手によってのみつくられたという前提のもと鑑賞されるのが普通ですか ら、例えばAIの利用について明示するなど(あえてしない、といった選択肢もありえるでしょ う)、どのようにして発表するか、ということについては意識的でありたいものです。

さらに、言語モデルは「学習に見たデータをもとに生成するモデルである」という点

207

第5章 うまく付き合う

「付き合い方」をつくる

も忘れてはなりません。もし、ある言語モデルがとてもいいと思える短歌を生成できてい るとしたら、その裏にはその表現を計算によって導き出すことを可能にした学習データが 存在しているといえます。 その生成結果をそのまま「いい短歌」 として世の中に放ち続け ていたとしたら、それはあくまで「これまでの歴史の中でいいとされている歌」のバリエ ーションにすぎない、という考え方もできそうです。 創作はこれまでにない、新たな表現 をつくる行為ですが、それとは反対の試みにとどまってしまいます。

むしろ、言語モデルが生成できない言葉を生み出すということが、今後の短歌の創作に おいて重要となるかもしれません。ただその一方で、「AIにはつくれない歌」ばかりを 志向していては、創作は「AIとの勝ち負け」という狭い対立構造のなかにとどまり続け ます。結局のところ、AIを利用しようがしまいが、これまでの歴史やいまある世界を理 解した上で、これまでにない新しいあなただけの歌をつくる、ということに尽きる気がし ます。

社交的という言葉があります。 「ほかの人と上手につきあう様子」(新明解国語辞典 第八 版)という意味だそうです。 一般的には、SS意味で使われる言葉でしょう。しかし、

「社交的」であるという性質を指す言葉が存在すれば、その性質を持たない人の存在も暗 に炙り出します。

世の中すべての人が、社交的というわけではありません。人それぞれ、他者と多様な人 間関係を結んでいて、心地よいと感じる人との付き合い方もさまざまに存在しているでし ょう。そしてこれは、AIとの付き合い方にも当てはまると思います。

私たちはこれまで、短歌AIを通じた多様な実験や、歌人への取材やイベントなどのあ ゆる実践を通して、短歌の創作を取り巻くAIと人の間には、たくさんのつくりうる関 係性があることを見てきました。

そこには一つに決まった「正解の付き合い方」があるわけではありません。これからの 未来には、あなたが「これまでになかったAIとの付き合い方」 を発見する余白が広がっ ているでしょう。 一方で、「よくない付き合い方」というものも、法律や倫理に照らすと 見えてきます。

最近では生成AIが注目を浴びていますが、言葉を取り巻くテクノロジーの進化は今後 もきっと続いていくでしょう。日常生活に、AIがつくった言葉がより浸透していくかも しれません。現代を生きる人間である私としては、短歌の創作が完全にAIのものになっ てしまうのは、やはり受け入れ難いところがあります。 そこで、「これはあなたや私のも

209

第5章 うまく付き合う

のだ」と思える短歌をつくるには、いったいどのようにAIと付き合えば良いのか。ぜひ とも、私たちで考え続けたい、実践を続けたい問題です。 そしてこの問題は、いかなる未 来にも開かれ続けている、私たち人間にとって非常に重要な問いではないでしょうか。

この章から学ぶ「短歌入門」

●あなただけのAIとの付き合い方をつくる。

その「付き合い方」について名前をつける。

どんな時にその関係が深まるのか終わりを迎えるのかについて考えながら、実践する。

210

おわりに

本書では、AIがどのようにして短歌を学び、またそれを生成するのかを見ながら、短 歌という文化創作、さらには人間との関係について考えました。コンピュータで言葉を 扱う自然言語処理について説明し(序章)、新聞社の取り組みである短歌AIの概要につい

第1章)、「型」を扱うAIの仕組みや挙動から短歌の定型について(第2章)、学習デー タによる言語モデルの生成の違いから作品に触れることの重要性について(第3章)、言語 モデルの生成手法から歌をつくるための語彙選択について(第4章)、そして最後にはAI との付き合い方について(第5章)触れました。

あお

その内容は朝日新聞社における研究開発とコンテンツ制作での実践を題材にし、いずれ もいま実際にできること/起きていること〉が起点となっています。生成AIについて 多く語られる昨今において、なるべく過度な期待や不安を煽ることなく、地に足のついた 話ができればと考えましたが、 実際そのようになっていればと思います。 その結果を振り 返ってみれば、「短歌入門」 としてはいずれも基本的かつ当たり前のことを書いてきたか もしれません。

211

おわりに

一方で、自然言語処理の専門的な知識については、その説明を簡潔にするため、少々大 雑把なところがあったのは否めません。 「言葉」を扱う技術そのものにご興味をもたれた 方がいれば、ぜひとも、より専門的な本を手に取ってみてください。 言語モデルの創作分 野における応用には、まだ明らかになっていない問題や、行われていない実践が多くあり ます。これに取り組む人が一人でも増えたら、それはまたうれしいことです。

〈短歌AI〉の研究は、現在も続いています。本書では取り上げることができませんでし たが、短歌の評価や鑑賞をテーマにした研究を、社内外の研究者と進めている最中です。 本書に書いた内容は決して一つの正解を示すものではなく、今後も形を変え続けていくこ とでしょう。

私たちは、有限の時間を生きています。限られた時間の中で、できることをやる。そん 毎日の連続です。 それはすべての生物にとって平等で、遠い過去から現在まで、おそら 例外はないでしょう。

一方、AIには私たちのような寿命はありません。 こんな「時間」に対する感覚もAI 人の大きな違いではないでしょうか・・・・・・と、書きかけていました。しかし、よくよく考 えてみれば、AIもいま現在に存在するコンピュータ上で動作するプログラムにすぎませ ん。例えば50年先に、いまあるAIがそのまま動き続けているかといえば、それは難しい

212

でしょう。

謝辞

私は序章で「春過ぎて 夏来るらし白たへの衣干したり天の香具山」という万葉集の短歌 について書きました。この歌は一千年以上の時間を生き、過去に存在した人間の一瞬を保 存して、遠い未来に生まれた子どもであった私に強い印象を残しました。その結果の一つ が、この本であると言うこともできるでしょう。私たちがつくる短歌は、私たちの言葉が 続く限り、 生き続けるものなのかもしれません。

短歌が生きる非常に長い時間の前では、人の命もAIの寿命も等しく短い。そんなふう に考えると、難しいことはさておき、とりあえず歌をつくってみようと思えてきます。 本 書では、AIが短歌を生成するさまを見ながら、人間が短歌をつくるということについて 考えてきました。ここから先にあるのは〈AI〉や〈人間〉ではなく〈あなた〉が短歌を つくる時間です。 そこで、本書の内容を思い出していただける瞬間があれば、著者として これ以上にうれしいことはありません。

短歌生成の研究にあたり、日頃から数々のご助言をいただいております、MBZUAI. 東北大学の乾健太郎教授並びに東京工業大学の岡崎直観教授に、感謝を申し上げます。 私

213

おわりに

たちの短歌生成AIが世の中に出るきっかけをつくり、 その後も一緒に短歌AIをつくっ 弊社文化部の佐々波幸子氏、佐藤卓史氏、 柏崎歓氏をはじめとする皆さん、また短 歌生成を含む研究開発業務はもちろんのこと、本書の内容にも助言をいただいた田森秀明 氏、田口雄哉氏、新妻巧朗氏らメディア研究開発センターの皆さんに感謝いたします。

そして、短歌AIに触れていただき、私たちもまだわからなかったその実像や未来像を 明らかなものとしてくださった俵万智氏、 永田和宏氏、木下龍也氏、イベントや記事をご 覧いただいた皆様に心より感謝申し上げます。

そのほか、ここに挙げきることのできない社内外の方々の協力によって〈短歌AI> は できています。皆様がいなければ、本書に書いた取り組みはいずれも実現せず、この本も 存在していませんでした。重ね重ね感謝いたします。

本書における短歌の専門的な記述について、助言をいただいた寺井龍哉氏に感謝いたし ます。最後に、書籍の執筆は初めてということもあり、あらゆる作業に慣れない私を励ま し、一冊の本にしてくださった講談社学芸第一出版部の井本麻紀氏に、厚く御礼申し上げ ます。

214

主要参考文献 (著者名五十音順、 アルファベット順)

朝日新聞社 「#この記事は実在しません: GPT - 2 Text

2020年 https://cl.asahi.com/api_data/gpt2-demo.html

Generation Demo」、

朝日新聞社 「PREMIUMA 俵万智×AI短歌 歌人と拓く言葉」

『朝日新聞デジタル」、 2022年7月6日

https://www.asahi.com/special/tawaramachi-aitanka/

朝日新聞社 「PREMIUMA 短歌でさがす “いまの気持ち"」

「朝日新聞デジタル』 2022年8月3日

https://www.asahi.com/special/asahikadan-library/

朝日新聞社 「自動要約生成 API TSUNA」、 2022年

https://cl.asahi.com/api_data/headlinegeneration.html

朝日新聞社 「朝日新聞社の文章校正AI Typoless (タイポレス)」、 2023年 https://typoless.asahi.com/

いなにわ せきしろ 『偶然短歌』 飛鳥新社、 2016年

浦川通 「AIが俵万智さんの歌集を学習したら 開発者が言語モデルを解 「説」 「朝日新聞デジタル』 2022年7月5日

https://digital.asahi.com/articles/ASQ744WG1Q71UCVL01Y.html 浦川通 「短歌 AIをつくる」 『文藝春秋』 2022年12月号 浦川通、 朝日新聞社メディア研究開発センター

年 「モーラを考慮した Fine-tuning による口語短歌生成」

「 [穴埋め式] 世界ことわざ辞典』 TRANS BOOKS DOWNLOADs、 2020浦川通、新妻巧朗、 田口雄哉、 田森秀明、 岡崎直観、 乾健太郎

「言語処理学会 第28回年次大会 発表論文集』、2022年3月 浦川 通、 新妻巧朗、 田口雄哉、 田森秀明、 岡崎直観、 乾健太郎 「短歌における言語モデルの実応用一歌人の視点を通した生成と作歌支 援の実践からー」

「言語処理学会 第29回年次大会 発表論文集』、2023年3月 浦川通 新妻巧朗、 田口雄哉、 田森秀明、 岡崎直観、 乾健太郎 「短歌における自然言語生成の受容と有用性の検討」

「研究報告自然言語処理 (NL)』2023年3月

岡井隆 (監修)、三枝昂之ほか (編)

『岩波 現代短歌辞典 普通版』 岩波書店、 1999年 岡崎直観、 荒瀬由紀、 鈴木潤、 鶴岡慶雅、 宮尾祐介

『IT Text 自然言語処理の基礎』 オーム社、2022年 川村秀憲 「人工知能が俳句を詠む: AI 一茶くんの挑戦」 「情報法制レポート」、 2022年第2号

主要参考文献、

295

川村秀憲、 山下倫央、 横山想一郎

『人工知能が俳句を詠む: AI一茶くんの挑戦』 オーム社、 2021年 窪薗晴夫 「特集 音節とモーラの理論 モーラと音節の普遍性」 『音声研究』、1998年第2巻第1号

現代俳句協会 「現代俳句データベース」 https://haiku-data.jp/index.php 佐々木あらら 「暴走するバーチャル歌人 星野しずるとは?」 『情報・知識&オピニオン imidas』 2012年10月12日

https://imidas.jp/jijikaitai/L-40-121-12-10-G379

佐佐木幸綱 (監修)、 「心の花」 編集部 (著) 『知識ゼロからの短歌入門」 幻冬舎、2020年

佐々波幸子 「A-stories AI と歌人が出会ったら 第4回 永田和宏さん、 短歌AIを語る 「やってることは同じかも。 でも...』」 『朝日新聞デジタル」、 2022年7月6日

https://www.asahi.com/articles/ASQ716V8VQ6QUCVL006.html 佐々波幸子 「俵万智さん還暦迎えて詠んだ60代の恋 親元で出現した「黒 「い娘』」 「朝日新聞デジタル」、 2023年12月2日

https://www.asahi.com/articles/ASRCZ5TLDRCXUCVL038.html

佐々波幸子、田中瞳子 「永田和宏さん、 AIは人のように歌を詠めますか できぬ部分に本質が」 「朝日新聞デジタル」、 2023年11月18日

https://www.asahi.com/articles/ASRCJ5QN7RCHUCVL006.html 谷知子 『和歌文学の基礎知識』 KADOKAWA (角川選書394) 2006年 中辻真 奥井颯平、 野口あや子、 加古陽

「特集 作品検証&修業秘話 歌歴1年半でここまで上達! 歌人AI(人 工知能歌人) の歌力: ついに歌壇デビューか! 筆名は 「恋するAI歌 人』!」 『短歌研究」、 2019年8月号

文化庁著作権課 「令和5年度 著作権セミナー AIと著作権」、 2023年6月 https://www.bunka.go.jp/seisaku/chosakuken/pdf/93903601_01.pdf

三林亮太、 山本岳洋、 大島裕明 「GPT-2とBERT を用いたバース生成によ るラップバトル体験システム」 第29回インタラクティブシステムとソ フトウェアに関するワークショップ (WISS2021)、2021年12月 https://www.wiss.org/WISS2021Proceedings/data/2-A10.pdf

山田育矢 (監修・著)、 鈴木正敏、 山田康輔、 李凌寒 (著)

『大規模言語モデル入門』 技術評論社、2023年

渡部泰明 『和歌史: なぜ千年を越えて続いたか」 KADOKAWA (角川選書 641)、2020年

渡部泰明 (編) 和歌文学会 (監修) 『和歌のルール」 笠間書院、2014年

216

Devlin, Jacob, Chang, Ming-Wei, Lee, Kenton, and Toutanova, Kristina, "Bert: Pre-training of Deep Bidirectional Transformers for Language Understanding" In North American Chapter of the Association for Computational Linguistics, 2019.

Harnad, Stevan, "The Symbol Grounding Problem", Physica D: Nonlinear Phenomena, 42(1-3): 335-346, 1990.

Holtzman, Ari, Buys, Jan, Du, Li, Forbes, Maxwell, and Choi, Yejin, "The Curious Case of Neural Text Degeneration", International Conference on Learning Representation, https://arxiv.org/abs/1904.09751, 2020.

Mikolov, Tomas, Chen, Kai, Corrado, Greg, and Dean, Jeffrey, "Efficient Estimation of Word Representations in Vector Space", In International Conference on Learning Representations, 2013.

Murray, Kenton, and Chiang, David, "Correcting Length Bias in Neural Machine Translation", In Conference on Machine Translation, 2018.

Platen, Patrick von, "How to generate text: using different decoding methods for language generation with Transformers", https://huggingface.co/blog/ how-to-generate, 2020.

Reimers, Nils, and Gurevych, Iryna, "Sentence-BERT: Sentence Embeddings using Siamese -BERT Networks", In Conference on Empirical Methods in Natural Language Processing, 2019.

Sheng, Emily, Chang, Kai-Wei, Natarajan, Premkumar, and Peng, Nanyun, "The Woman Worked as a Babysitter: On Biases in Language Generation", In Conference on Empirical Methods in Natural Language Processing, 2019.

Takeishi, Yuka, Niu, Mingxuan, Luo, Jing, Jin, Zhong, and Yang, Xinyu, "WakaVT: A Sequential Variational Transformer for Waka Generation", 2021.

Watanabe, Kento, Matsubayashi, Yuichiroh, Fukayama, Satoru, Goto, Masataka, Inui, Kentaro, and Nakano, Tomoyasu, "A Melody-Conditioned Lyrics Language Model", In North American Chapter of the Association for Computational Linguistics, 2018.

Watanabe, Kento, and Goto, Masataka, "Lyrics information processing: Analysis, generation, and applications", In NLP4MUSA, 2020.

主要参考文献

217

引用詳細

(『フリー百科事典 ウィキペディア日本語版』 https://ja.wikipedia.org/より引用した P110-112の項目について、 記事の2024年5月22日現在の最終更新日時を記す)

「粘液」:2024年2月20日(火) 07:10 UTC 「3次元ディスプレイ」 2022年10月12日 (水) 22:00 UTC Text Editor and Corrector : 2021417 B (E) 14:47 UTC 「チェリーボム (プロレスラー)」 2023年10月20日 (金) 09:13 UTC 「キュニョーの砲車 2023年2月5日 (日) 06:51 UTC 「Unicode 文字のマッピング」 2023年10月1日 (日) 04:39 UTC 「ヤーコブヨルダーンス」 : 2023年8月18日 (金) 12:43 UTC 「シーシャンティ」 2021年5月22日 (土) 16:31 UTC 「線スペクトル対 2018年8月4日 (土) 11:47 UTC 「室伏治」:2024年5月16日(木) 19:23 UTC 「外感星」:2023年2月16日(木) 19:40 UTC

〈短歌 AI> 以外の生成で使用した言語モデル

rinna/japanese-gpt2-small

https://huggingface.co/rinna/japanese-gpt2-small

tohoku-nlp/bert-large-japanese

https://huggingface.co/tohoku-nlp/bert-large-japanese

218

N.D.C.007 218p 18cm

ISBN978-4-06-536012-5

6.7.10

長崎県立

講談社現代新書 2748

エーティ

たんか

AIは短歌をどう詠むか

二〇二四年六月二〇日第一刷発行

かわとおる

著者 浦川通 © The Asahi Shimbun Company 2024

行者 森田浩章

発行所

株式会社講談社

東京都文京区音羽二丁目一二二一 郵便番号一一二一八〇〇一 電話 〇三五三九五三五二 編集 (現代新書)

〇三五三九五四四一五 販売

〇三五三九五十三六一五 業務

装幀者

中島英樹/中島デザイン

印刷所 株式会社KPSプロダクツ

製本所 株式会社国宝社

定価はカバーに表示してあります Printed in Japan

本書のコピー、スキャン、デジタル化等の無断複製は著作権法上での例外を除き禁じられていま す。本書を代行業者等の第三者に依頼してスキャンやデジタル化することは、たとえ個人や家庭内 の利用でも著作権法違反です。 〈日本複製権センター委託出版物〉

複写を希望される場合は、日本複製権センター(電話〇三六八〇九一二八一)にご連絡ください。 落丁本・乱丁本は購入書店名を明記のうえ、小社業務あてにお送りください。

送料小社負担にてお取り替えいたします。

なお、この本についてのお問い合わせは、「現代新書」 あてにお願いいたします。

「講談社現代新書」の刊行にあたって

教養は万人が身をもって養い創造すべきものであって、一部の専門家の占有物として、ただ一方的に人々の 手もとに配布され伝達されうるものではありません。

しかし、不幸にしてわが国の現状では、教養の重要な養いとなるべき書物は、ほとんど講壇からの天下りや 単なる解説に終始し、知識技術を真剣に希求する青少年・学生・一般民衆の根本的な疑問や興味は、けっして 十分に答えられ、解きほぐされ、手引きされることがありません。 万人の内奥から発した真正の教養への芽ば えが、こうして放置され、むなしく滅びる運命にゆだねられているのです。

このことは、中・高校だけて教育をおわる人々の成長をはばんでいるだけでなく、大学に進んだり、インテ リと目されたりする人々の精神力の健康さえもむしばみ、わが国の文化の実質をまことに脆弱なものにしてい ます。単なる博識以上の根強い思索力・判断力、および確かな技術にささえられた教養を必要とする日本の将 米にとって、これは真剣に憂慮されなければならない事態であるといわなければなりません。

わたしたちの「講談社現代新書」は、この事態の克服を意図して計画されたものです。 これによってわたし たちは、講壇からの天下りでもなく、単なる解説書でもない、もっぱら万人の魂に生ずる初発的かつ根本的な 問題をとらえ、掘り起こし、 手引きし、しかも最新の知識への展望を万人に確立させる書物を、新しく世の中 に送り出したいと念願しています。

わたしたちは、創業以来民衆を対象とする啓蒙の仕事に専心してきた講談社にとって、これこそもっともふ さわしい課題であり、伝統ある出版社としての義務でもあると考えているのです。

一九六四年四月 野間省一

自然科学・医学

〈勝負脳〉の鍛え方林成之 「生きている」を見つめる医療

宇宙はなぜ

このような宇宙なのか青木薫 宇宙生物学で読み解く吉田たかよし 「人体の不思議

吉田武

安楽死と尊厳死保阪正康 「複雑系」とは何か―吉永良正 カンブリア紀のサイモン・コンウェイ・モリス 怪物たち 松井孝典 監訳

呼の科学

科学の現在を問う 村上陽一郎 優生学と 一米本昌平 松原洋子 -粂和彦 時間の分子生物学 核兵器のしくみ 山田克哉 新しいリハビリテーション 大川弥生 25数学的思考法- -芳沢光雄 人類進化の700万年 三井誠 はじめての〈超ひも理論〉 川合光 算数・数学が得意になる本 芳沢光雄

生物と無生物のあいだ 福岡伸一 数学でつまずくのはなぜか 小島寛之 脳のなかの身体宮本省三 世界は分けてもわからない 福岡伸一 ロボットとは何か――石黒浩

生命誕生

中沢弘基

SFを実現する田中浩也 生命のからくり 中屋敷均 認知症を知る

飯島裕一

0円シャルブレインズ 藤井直敬

認知症の「真実」――

東田勉

〈麻薬〉のすべて――船山信次 量子力学の哲学- 森田邦久 96の分子生物学 -更科功 20DNA医学の最先端大野典也 森の力 -宮脇昭

ウイルスは生きている 中屋敷均 明日、機械がヒトになる 海猫沢めろん 3 ゲノム編集とは何か 小林雅一 25 不要なクスリ 無用な手術 富家孝 3生命に部分はない福岡伸一訳

A・キンブレル

知的生活のヒント

知の編集術

·松岡正剛

悪の対話術

-福田和也

4大学生のための

20 知的勉強術

5 〈わかりやすさ 勉強法

松野弘

池上彰

18大学でいかに学ぶか 増田四郎 66愛に生きる

鈴木鎮一

悪の恋愛術

-福田和也

人を動かす文章術齋藤孝 アイデアを形にして―原尻淳一 24伝える技術

生きることと考えること 森有正 本はどう読むか清水幾太郎 考える技術・書く技術板坂元 知的生活の方法 渡部昇一 創造の方法学・

-高根正昭

50 文章構成法

-樺島忠夫

686働くということ―――黒井千次

相手に「伝わる」 話し方 池上彰 インタビュー術!永江朗 60 子どもに教えたくなる算数 栗田哲也 老いるということ―黒井千次 調べる技術・書く技術 野村進 回復力 -畑村洋太郎 日本語論理トレーニング中井浩一 わかりやすく伝える〉技術―池上彰

デザインの教科書―柏木博 エンディングノートのすすめ 本田桂子 学び続ける力 ・池上彰

野心のすすめ

-林真理子

2試験に受かる「技術」 吉田たかよし

「超」集中法

野口悠紀雄

「知」のソフトウェアー立花隆

幸福の哲学

-岸見一郎

「からだ」と「ことば」―竹内敏晴

10のレッスン

国語のできる子どもを育てる―工藤順一

地アタマを鍛える 20 知的勉強法

24新版 大学生のための レポート・論文術

牙を研げ

小笠原喜康

24 会社を生き抜くための教養

佐藤優

齋藤孝

正しい本の読み方 橋爪大三郎

3

趣味・芸術・スポーツ

「天才」の育て方

五嶋節

2歌舞伎 家と血と藝 中川右介

時刻表ひとり旅

-宮脇俊三

15ベートーヴェンの交響曲

金聖響

「玉木正之

ロックの歴史

中山康樹

プロ野球の一流たち 二宮清純

酒の話

小泉武夫

ふしぎな国道

佐藤健太郎

J・S・バッハ

-磯山雅

ビートルズの謎

中山康樹 金聖響

950 ニッポンの音楽佐々木敦

写真美術館へようこそ飯沢耕太郎 踏みはずす美術史 森村泰昌 2演劇入門

ロマン派の交響曲 玉木正之 B00 落語論

3人が集まる建築-

-仙田満

堀井憲一郎

不屈の棋士

大川慎太郎

平田オリザ

33 138億年の音楽史 浦久俊彦

Vスポーツとは何か―玉木正之 500最強のプロ野球論―二宮清純

マイケル・ジャクソン西寺郷太 世界の野菜を旅する 玉村豊男 浮世絵は語る 浅野秀剛

38 ピアニストは語る

ヴァレリー・

アファナシエフ

現代美術コレクター 高橋龍太郎

13 なぜ僕はドキュメン

2タリーを撮るのか―想田和弘

358 ヒットの崩壊

-柴那典

これがビートルズだ 中山康樹 演技と演出 平田オリザ 16科学する麻雀とつげき東北

20マーラーの交響曲

金聖響

「玉木正之

本物の名湯ベスト100 石川理夫

2騎手の一分 |藤田伸二

タロットの秘密―鏡リュウジ

イリーナ・

ジャズの名盤入門―中山康樹

ツール・ド・フランス 山口和幸

ピアノの名曲

メジューエワ

O

ס

日本語・日本文化

16タテ社会の人間関係 中根千枝 日本人の意識構造会田雄次 出雲神話

「空気」と「世間」 -鴻上尚史 日本語という外国語 荒川洋平 日本料理の贅沢神田裕行 新書 沖縄読本 著・編 圳

10漢字の字源-

―松前健 -阿辻哲次

ラーメンと愛国

-速水健朗

13日本人のための 日本語文法入門 漢字雑談

原沢伊都夫

外国語としての日本語―佐々木瑞枝 1/43 武士道とエロス氏家幹人 「世間」とは何か――阿部謹也 江戸の性風俗- 氏家幹人 14日本人のしつけは衰退したか広田照幸

ユーミンの罪 アイヌ学入門―

-高島俊男

酒井順子 -瀬川拓郎

クール・ジャパン!!: 鴻上尚史 橋爪大三郎 げんきな日本論 【大澤真幸

10大人のための文章教室 清水義範 なぜ日本人は

1学ばなくなったのか

-齋藤孝

京都のおねだん――大野裕之

女装と日本人三橋順子

山本七平の思想 -東谷暁

まるで人のように短歌をつくるAIがある。確かにそれは、人と「似ている」わけですが、 AIの方が得意なこと、人間の方が得意なこと、AIにしかできないこと、人間にしかで きないこと、そして共通してもっていることが、短歌AIを通して見えてくるでしょ う。私はこれを、新たに短歌と私たち人間について考える、良い機会だと捉えています。 いま、この時代だからこそ生まれる、人が短歌をつくることへの新しい感覚を、この本の 中で表すことができたらと思います。 「はじめに」より